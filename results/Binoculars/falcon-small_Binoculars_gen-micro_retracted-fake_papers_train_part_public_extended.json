{
    "human_predictions": [
        {
            "abs": "A low-cost robot sensor system based on light sensitive tiles and an associated microcomputer has been developed to investigate the use of sensory feedback in the control of a robot manipulator. The construction of the sensor tile is described together with an outline of the microcomputer-system, which is based on the Hitachi 64180 microprocessor. Object location and recognition software has been written to enable the performance of the sensor tile to be assessed. The operation of this software is described to illustrate one possible approach to the analysis of the sensor surface images. Some results are presented which show the use of the sensor tile and image analysis software to locate and recognize conduit couplings.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Nowadays, employing the worst case analysis is the most common approach to provide unified static task mapping\u2013scheduling plans on MPSoCs. Since the whole design space nor a subset of design space are not explored in the worst case methods, these approaches may fail to achieve efficient performance yield. In this paper, we present a temperature-aware quasi-static task mapping\u2013scheduling framework under process variation for hard real-time and periodic systems on MPSoCs. By employing the stochastic optimization and scenario-based approaches, we explore a few representative scenarios in the whole design space of the chip using the probability density function of the problem random variables. Then, we obtain a compact set of near optimal mapping\u2013scheduling of real-time tasks which targets performance-yield maximization and minimization of the expected values of peak temperature. Consequently, considering different chip parameter configurations, we construct the plan set as the solutions that attain the best variation-aware task mapping\u2013scheduling that satisfy the deadline and minimize the temperature. This plan set can readily look up at run time by the system scheduler of the chip to find the proper plan of the tasks based on the run-time parameters. The experimental results demonstrate significant improvements in performance-yield and peak temperature for almost all of the test cases off homogenous and heterogeneous MPSoCs.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The transputer is useful not only as a parallel processing element, but also as an embedded controller. The paper describes a digital waveform generator based on the transputer. By executing a program written in a high-level language, a transputer aided by a single-chip counter generates complex digital signals with precise state times ranging from 200 ns to infinity in 50 ns increments. The duration of each output state is determined by data rather than by program execution speed: this simplifies programming. Repetition and concatenation of sequences of output states may also be encoded into data structures, which are interpreted by an invariant program. The transputer is controlled with a single serial link, and is easily integrated into a network of transputers or any system capable of communicating with a byte serial protocol. The control of focal plane arrays for astronomy is presented as a demonstration of the flexibility of the device. Fabrication cost, size and power consumption are greatly reduced relative to traditional bit-slice designs.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this paper we propose a low-error approximation of the sigmoid function and hyperbolic tangent, which are mainly used to activate the artificial neuron, based on the piecewise linear method. Here, the hyperbolic tangent is alternatively approximated by exploiting its mathematical relationship with the sigmoid function, showing better results. Special attention has been paid to study the minimum number of precision bits to achieve the convergence of a multi-layer perceptron network in finite arithmetic machine. All the approximation results show lower mean relative and absolute error than those reported in the state-of-the-art. Finally, the sigmoid digital implementation is discussed and assessed in terms of work frequency, complexity and error in comparison with the state-of-the-art.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "On-chip instruction cache is a potential power hungry component in embedded systems due to its large chip area and high access-frequency. Aiming at reducing power consumption of the on-chip cache, we propose a Reduced One-Bit Tag Instruction Cache ( ROBTIC ), where the cache size is judiciously reduced and the cache tag field only contains the least significant bit of the full-tag. We develop a cache operational control scheme for ROBTIC so that with the one-bit cache tag, the program locality can still be efficiently exploited. For applications where most of the memory accesses are localized, our cache can achieve similar performance as a traditional full-tag cache; however, the power consumption of the cache can be significantly reduced due to the much smaller cache size, narrower tag array (just one bit), and tinier tag comparison circuit being used. Experiments on a set of benchmarks implemented in CMOS 180 nm process technology demonstrate that our proposed design can reduce up to 27.3% dynamic power consumption and 30.9% area of the traditional cache when the cache size is fixed at 32 instructions, which outperforms the existing partial-tag based cache design. With the cache size customization, a further 47.8% power saving can be achieved. Our experimental results also show that when implemented in the deep sub-micron technologies where the leakage power is not ignorable, our design is still efficient \u2013 a coherent power saving trend (about 22%) has been observed for technologies from 130 nm down to 65 nm.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Studying and understanding human brain is one of the main challenges of 21st century scientists. The Human Brain Project was conceived for addressing this challenge in an innovative way, enabling collaborations between 112 partners spread in 24 European countries. The project is funded by the European Commission and will last until 2023. This paper describes the ongoing activity at one of the Italian units focused on innovative brain simulation through high performance computing technologies. Simulations concern realistic models of neurons belonging to the cerebellar cortex. Due to the level of biological realism, the computational complexity of this model is high, requiring suitable technologies. In this work, simulations have been conducted on high-end Graphical Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs). The first technology is used during model tuning and validation phases, while the latter allows to achieve real time elaboration, aiming at a possible development of embedded implantable systems. Simulations performance evaluations are discussed in the result section.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Over the years many efficient algorithms for the multiplierless design of multiple constant multiplications (MCMs) have been introduced. These algorithms primarily focus on finding the fewest number of addition/subtraction operations that generate the MCM. Although the complexity of an MCM design is decreased by reducing the number of operations, their solutions may not lead to an MCM design with optimal area at gate-level since they do not consider the implementation costs of the operations in hardware. This article introduces two approximate algorithms that aim to optimize the area of the MCM operation by taking into account the gate-level implementation of each addition and subtraction operation which realizes a constant multiplication. To find the optimal tradeoff between area and delay, the proposed algorithms are further extended to find an MCM design with optimal area under a delay constraint. Experimental results clearly indicate that the solutions of the proposed algorithms lead to significantly better MCM designs at gate-level when compared to those obtained by the solutions of algorithms designed for the optimization of the number of operations.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "As part of its continuing research into open systems and ISDN systems the Computer Science Department at University College London has built a network layer gateway between primary rate ISDN and Ethernet. The gateway is built from a 68000-based front-end, with a primary rate ISDN interface, installed in a Sun workstation; it is designed to have a minimal impact on the native Sun operating system software. The gatewaying task is shared between the Sun and the front-end, with the aim of relieving the front-end of the more complex gatewaying tasks such as fragmentation and the exchange of routing information with other gateways. The gateway operates as a connectionless network relay and thus reflects the dominant mode of working on LANs. The paper describes the design decisions that were taken in the construction of the gateway and outlines the eventual hardware and software design. Consideration is given to the overall system and protocol architecture, memory access, buffering strategies, circuit management, and the facilities and protocols used for network management.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper analyses the possibility to replace the hydraulic and mechanical parts of a hydraulic position servo with a real-time simulation model. The aim is to test the controller hardware against the simulation model that includes the dynamics of the servo system as well as the feedback sensors and amplifier card. The requirements caused by this hardware-in-the-loop (HIL) approach are analyzed. A special attention is paid to the correct modeling of incremental encoders that are widely used as a feedback sensor. Experimental results show that there is no remarkable difference between the responses of the real system and HIL model and so the HIL model can replace the real system.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The process of successfully creating an embedded system is highly challenging and complex; engineers typically operate under tight financial, technical and time-to-market constraints. To achieve the desired objective, the design team need to utilise effectively the most advanced software tools available, in order that the task may be completed to specification in a timely and cost-effective manner. This paper discusses the use of a CASE-tool in an embedded systems design, and reviews issues pertaining to the integration of such a tool into an embedded systems development environment. The paper focuses on the application of this high level approach in embedded systems design and concludes by describing the use of the CASE-tool in the design of a simple demonstrator.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a technique using a genetic algorithm to compute an efficient routing for an application-specific NoC (Network-on-Chip). The main goal of this paper is to introduce multi-objective optimization techniques to address the NoC routing. Thus, Pareto optimization has been used to determine non-dominated solutions according to two fixed objectives: (i) avoiding the reuse of same links as far as possible to reduce congestion; (ii) reducing the number of loops to limit the risk of deadlocks. The proposed method called MORGA (Multi-Objective Routing based on Genetic Algorithm) uses two steps: (i) an off-line process consisting at selecting a non-dominated solution among a pre-calculated population of solutions; (ii) an on-line process allowing the data transmission based on the built solution by the use of routing tables. MORGA is also applicable in the presence of permanent faulty links by calculating fault-free solutions. A reconfiguration of routing tables is performed when a new application is loaded on the system. Results show how a selection of the most appropriate solution can provide considerable improvement in performance.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Structural features of plastics such as orientation, degree of crystallinity and spherulite dimension are influenced by basic extrusion conditions of temperature, screw speed, haul off speed, mass outflow and the nature of casting. These induced structural features in turn influence the post-extrusion processes which are an essential part of film-fibre production. A correlation between structural features and mechanical properties of extruded film has previously been established. A sensor, based on small-angle light scattering, using a laser source and microprocessor-based pattern processing has been designed for online control. Principles involved are described and circuit details included.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In the last 15 years we have seen, as a response to power and thermal limits for current chip technologies, an explosion in the use of multiple and even many computer cores on a single chip. But now, to further improve performance and energy efficiency, when there are potentially hundreds of computing cores on a chip, we see a need for a specialization of individual cores and the development of heterogeneous manycore computer architectures. However, developing such heterogeneous architectures is a significant challenge. Therefore, we propose a design method to generate domain specific manycore architectures based on RISC-V instruction set architecture and automate the main steps of this method with software tools. The design method allows generation of manycore architectures with different configurations including core augmentation through instruction extensions and custom accelerators. The method starts from developing applications in a high-level dataflow language and ends by generating synthesizable Verilog code and cycle accurate emulator for the generated architecture. We evaluate the design method and the software tools by generating several architectures specialized for two different applications and measure their performance and hardware resource usages. Our results show that the design method can be used to generate specialized manycore architectures targeting applications from different domains. The specialized architectures show at least 3 to 4 times better performance than the general purpose counterparts. In certain cases, replacing general purpose components with specialized components saves hardware resources. Automating the method increases the speed of architecture development and facilitates the design space exploration of manycore architectures.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Processor vendors have been expanding Single Instruction Multiple Data (SIMD) extensions to exploit data-level-parallelism in their General Purpose Processors (GPPs). Each SIMD technology such as Streaming SIMD Extensions (SSE) and Advanced Vector eXtensions (AVX) has its own Instruction Set Architecture (ISA) which equipped with Special Purpose Instructions (SPIs). In order to exploit these features, many programming approaches have been developed. Intrinsic Programming Model (IPM) is a low-level concept for explicit SIMDization. Besides, Compiler\u2019s Automatic Vectorization (CAV) has been embedded in modern compilers such as Intel C++ compiler (ICC), GNU Compiler Collections (GCC) and LLVM for implicit vectorization. Each SIMDization shows different improvements because of different SIMD ISAs, vector register width, and programming approaches. Our goal in this paper is to evaluate the performance of explicit and implicit vectorization. Our experimental results show that the behavior of explicit vectorization on different compilers is almost the same compared to implicit vectorization. IPM improves the performance more than CAVs. In general, ICC and GCC compilers can more efficiently vectorize kernels and use SPI compared to LLVM. In addition, AVX2 technology is more useful for small matrices and compute-intensive kernels compared to large matrices and data-intensive kernels because of memory bottlenecks. Furthermore, CAVs fail to vectorize kernels which have overlapping and non-consecutive memory access patterns. The way of implementation of a kernel impacts the vectorization. In order to understand what kind of scalar implementations of an algorithm is suitable for vectorization, an approach based on code modification technique is proposed. Our experimental results show that scalar implementations that have either loop collapsing, loop unrolling, software pipelining, or loop exchange techniques can be efficiently vectorized compared to straightforward implementations.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We propose a new genetics-based approach to scheduling parallel program tasks on multiprocessors. In the presence of communication delays, it is shown that task duplication is a useful technique for shortening the length of schedules. Though some genetic algorithms (GAs) for multiprocessor scheduling have been proposed so far, none of them allows task duplication. To overcome this deficiency, we develop a new GA, incorporating new genetic operators to control the degree of replication of tasks. Through simulation studies, we show that the proposed GA works effectively, especially when communication delays are relatively small.",
            "prediction": "Most likely AI-generated",
            "source": "Human"
        },
        {
            "abs": "Some aspects of the PLEIADES project at the University of Kent are described. Work at many levels is involved in determining how effectively typical knowledge manipulation systems may be implemented on multimicroprocessor hardware. The background and motivations for this work are discussed together with descriptions of aspects of the hardware and software of the prototype Pleiades system.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper proposes an analog hardware solution for the implementation of two-dimensional gradient-based algorithm. The algorithm employs the discrete cosine transform and performs missing samples reconstruction by using the compressive sensing principles. Although there is a number of algorithms for solving two-dimensional compressive sensing problems, for many of them a real-time application is a challenging task. Therefore, this paper observes an algorithm whose real-time application has relatively low complexity. Also, the reconstruction accuracy is comparable to the commonly used compressive sensing algorithms. The algorithm is observed within the several parts. The implementation of each part is considered in details, with provided discussion on the computational complexity of each part.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Most existing wormhole networks do not provide support for prioritized traffic at the link level. Conventional demand multiplexing does not allow flexibility for fast movement of high priority messages such as for synchronization and control information. In this paper, an approach to prioritized physical channel scheduling is proposed. The motivation behind the proposed approach and its descripton are presented. The approach is evaluated and compared against the conventional demand multiplexing for a wide range of system parameters. The results demonstrate significant potential for designing high performance wormhole systems to support prioritized traffic.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The fast Fourier transform (FFT) algorithm is widely used in digital signal processing systems (DSPs); hence, the development of a high-performance and resource-efficient FFT processor that conforms to the processing and precision requirements of real-time signal processing is highly desirable. We propose an FFT processor for field programmable gate array (FPGA) devices, based on the radix-2-decimation-in-frequency (R2DIF) algorithm. An appropriately modified parallel double-path delay commutator (DDC) architecture for radix-2 with continuous dual-input and dual-output streams (CoDIDOS) is proposed to increase throughput and reduce latency in FFT computation. The chip-area of the proposed design is reduced by decreasing the memory footprint of the complex twiddle factor multipliers. A multiplication scheme based on a combination of the unrolled coordinate rotation digital computer (CORDIC) and the canonical signed digit-based binary expression (CSDBE) is used to multiply the complex twiddle factors without requiring memory blocks for their storage. The CSDBE technique is proposed to optimize the multiplication of constants in the architecture. The proposed FFT processor is implemented as an intellectual property (IP) core and tested on a Xilinx Virtex-7 FPGA. Experimental results confirm that the proposed design improves the speed, latency, throughput, accuracy, and resource utilization of computation on FPGA devices over existing designs.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The importance of microprocessor education when applied to physics students and the need for incorporation of software in new automated equipment is realized. Experience of developing and applying a programme, which is based on practical knowledge gained from lecture courses, for such an education is reported. Much of the programme has been directed towards the use of microprocessor-based equipment, since such a need is being realized with new equipment arriving in this part of the world. The programme facilities, course contents and laboratory experiments are also explained.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Many broadcast algorithms have been proposed for the mesh in the literature. However, most of these algorithms do not exhibit good scalability properties as the network size increases. As a consequence, most existing broadcast algorithms cannot support real-world parallel applications that require large-scale system sizes due to their high computational demands. Motivated by this observation, this paper makes two contributions. Firstly, in an effort to minimise the effects of network size on communication performance, this study proposes a new routing approach that enables the development of efficient broadcast algorithms that can maintain good performance levels for various mesh sizes. Secondly, based on the new routing approach, we propose a new adaptive broadcast algorithm for the mesh. The main feature of the proposed algorithm is its ability to handle broadcast operations with a fixed number of message-passing steps irrespective of the network size. Results from extensive comparative analysis reveal that our algorithm exhibits superior performance characteristics over those of the well-known Recursive Doubling and Extending Dominating Node algorithms.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This research discusses hardware architectures, script-based automation and software and hardware methodologies for developing customized System-on-Chip scalar/vector processors within the example application domain of telephony codes. The approaches researched include Register-Transfer-Level methodologies resulting in an SIMD-enhanced processor known as the ITU-VE1, and Electronic System Level methodologies resulting in a multi-parallel vector processor known as the SS_SPARC. The example applications were the ITU-T G.729A and G.723.1 speech codecs chosen for their abundant data-level parallelism and availability for research purposes. Results indicate the proposed scalar/vector accelerators achieve a maximum speed-up of 4.27 and 4.62 for the G729.A and G723.1 encoders respectively for 512-bit wide SIMD configurations. Both vector processors resulting from the proposed methodologies were implemented as VLSI macros and compared at the silicon level. Compared to the Register-Transfer-Level flow, the Electronic System Level flow implementing the same datapath results in increased power consumption of 3\u201315% however delivers an area reduction of 2\u201318% and substantially shortens design and verification time making it a viable alternative to established RTL methodologies.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The need for scalable and efficient on-chip communication in future many-core architecture has resulted in the network-on-chip (NoC) design emerging as a popular solution. It is a common belief that packet-based NoC can provide high efficiency, high throughput, and low latency for future applications instead of conventional transaction-based bus. However, these superior features of NoCs are only applied to unicast (one-to-one) latency non-critical traffic. Their multi-hop feature and inefficient multicast (one-to-many) or broadcast (one-to-all) support have made it awkward when performing some kinds of communications including cache coherence protocol, global timing and control signals, and some latency critical communications. This paper presents VBON, a new architecture of incorporating buses into NoCs in order to take advantage of both NOCs and buses in a hierarchical way. The point-to-point links of conventional NoC designs can be used as bus transaction link dynamically for bus request. This can achieve low latency while sustain high throughput for both unicast and multicast communications at low cost. To reduce the latency of physical layout for the bus organization, the hierarchical redundant buses are used. Detailed network latency simulation and hardware characterization demonstrate that VBON can provide the ideal interconnect for a broad spectrum of unicast and multicast scenarios and achieve these benefits with inexpensive extensions to current NoC router.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The benefits and deficiencies of shared and private caches have been identified by researchers. The performance impact of privatizing or sharing caches on homogeneous multi-core architectures is less understood. This paper investigates the performance impact of cache sharing on a homogeneous same-ISA 16-core processor with private first-level (L1) caches by considering 3 cache models which vary the sharing property of second-level (L2) and third-level (L3) cache banks. It is observed that across many scenarios, the cache privatization\u2019s average memory access time improved as the L1 cache miss rate increased and/or the cross-partition interconnect latencies increased. Under uniform memory address distribution, and when the L3 cache miss rate is close to 0, privatizing both L2s and L3s performs best among the 3 cache models. Furthermore, we mathematically demonstrate that when the interconnect\u2019s bridge latency is below 264 cycles, privatizing L2 caches beats privatizing both L2 and L3 caches, while the reverse is true for large bridge latencies representing high-traffic and heavy workload applications. For large interconnect delays, the private L2 and L3 model is best. For low to moderate interconnect latencies, and when the L3 miss rate is not close to 0, sharing both L2 and L3 banks among all cores performs best followed by privatizing L2s, while privatizing both L2s and L3s ranks last. Under worst case address distributions, cache privatizing benefits generally increase, and with large bridge latencies, privatizing L2 and L3 banks outperforms the other cache models. This reveals that as application workloads become heavier with time, resulting in large cache miss rates and long bridge and interconnect delays, privatizing L2 and L3 caches may prove beneficial. Under less stressful workloads, sharing both L2 and L3 caches have the upper hand. This study confirms the desired configurability and flexibility of the cache memory\u2019s sharing degree based on the running workload.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We answer the question on how much memory a packet switch/router needs; more specifically, we propose a systematic method that is simple, rigorous and general for determining the absolute lower bound of packet buffering required by practical switching systems. Accordingly, we introduce a deterministic traffic scenario that stresses the global stability property of finite output queues and demonstrate its usefulness by dimensioning the internal buffer capacity of two popular CIOQ switches.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Previous task mapping assumes that applications directly fetch data on remote nodes and build up their energy efficient mapping based on pattern of the NoC traffic. However, the data movement is actually managed by a cache coherence mechanism that executes a much more complicated protocol under application layer to guarantee data correction. Thus, we propose an energy efficient task mapping referring the protocol layer, rather than application layer, to precisely model protocol activities and energy dissipation. By a probabilistic description of cache accessing, we find a efficient method to convert application activities to energy consumption, generating an energy evaluation as a global optimization goal. We also propose a task mapping algorithm to minimize the energy consumption by referring activity intensity of the protocol. The experimental results show that the proposed energy model achieves a precision with less than 2% error and provides a credible quantitative criterion for energy optimization of cache coherence protocols. Comparing to application-layer optimization, our task mapping can obtain 20% energy saving and 15% latency reduction on average.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The performance analysis and comparison of 2 \u00d7 4 network on chip (NoC) topology are mainly presented in this paper. Firstly, three common 2 \u00d7 4 topologies, 2D Mesh topology, 2D Torus topology and hierarchical Mesh topology are designed. Secondly, the performances of three topologies are analyzed and compared in detail by using NoC performance evaluation standard. Finally, the occupying resources of three topologies are also compared. The result shows that 2D Torus topology can achieve higher throughput and lower average network latency in occupying fewer resources.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Recent embedded applications are widely used in several industrial domains such as automotive and multimedia systems. These applications are critical and complex, involving more computing resources and therefore increasing the power consumption of the system. Although performance still remains an important design metric, power consumption has become a critical factor for several systems, particularly after the increasing complexity of recent System-on-Chip (SoC) designs. Consequently, the whole computing domain is being forced to switch from a focus on high performance computation to energy-efficient computation. In addition to the time-to-market challenge, designers need to estimate, rapidly and accurately, both area occupation and power consumption of complex and diverse applications. High-Level Synthesis (HLS) has been emerged as an attractive solution for designers to address this challenge in order to explore a large number of design points at a high-level of abstraction. In this paper, we target FPGA-based accelerators. We propose HAPE, a high-level framework based on analytic models for area and power estimation without requiring register-transfer level (RTL) implementations. This technique allows to estimate the required FPGA resources and the power consumption at the source code level. The proposed models also enable a fast design space exploration (DSE) with different trade-offs through HLS optimization pragmas, including loop unrolling, pipelining, array partitioning, etc. The accuracy of our proposed models is evaluated by using a variety of synthetic benchmarks. Estimated power results are compared to real board measurements. The area and power estimation results are less than 5% of error compared to RTL implementations.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Asynchronous systems are attracting the interest of the designer community because of several useful features for sub-micron technologies: process-variation tolerant, low-power, removal of the clock tree generation, etc. One of the main problems for the simulation of these systems is the variable computation delays of their modules, that compute as fast as possible under the actual conditions of the system. This behavior complicates the high-level simulation of such systems and it is the main reason for the lack of simulation tools devoted to asynchronous microarchitectures. In this paper we present a modeling method useful for this kind of systems that describes the variable computation delay of an asynchronous circuit by using probability distribution functions. This method is deployed in an architectural simulator of a 64-bit superscalar asynchronous microarchitecture where the computation delay of each one of the modules of the microarchitecture was characterized through a probability distribution function. The experimental results show that the asynchronous behavior is successfully modeled, and the architectural simulations of standard benchmarks is affordable in terms of wall-clock simulation time.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper describes a Single Event Transient (SET) suppression design technique for hardening combinational circuits against SETs in non-volatile Field Programmable Gate Arrays (FPGAs). The proposed method adds a SET suppressor circuit that is insensitive to SETs, to each primary output of a combinational circuit. The SET suppressor circuit consists of three components; an AND gate to suppress an SET reaching the primary output, when the primary output is logic \u20180\u2019, and an OR gate when the primary output is logic \u20181\u2019. The third component is a simple two input multiplexer with its output connected to its own select line such that it will select the AND gate output when the combinational circuit primary output is logic \u20180\u2019 and the OR gate output when the primary output is logic \u20181\u2019. A delay element is used to split each primary output of the combinational circuit into two signals. The two signals, one being the original primary output and the other a delayed copy of it, is sent to input one and input two of the SET suppressor. An alternative embodiment of the SET suppressor circuit is to use Double Modular Redundancy (DMR) instead of the delay element implementation. The SET Suppressor method is thoroughly tested on MCNC\u201991 benchmarks using the ModelSim simulator. The SET Suppressor circuit provides total immunity against SETs, however it does so with an area savings of 11.6\u201362.2% with respect to TMR when the delay element technique is use. When the DMR SET Suppressor technique is used, the area savings with respect TMR is between 16.1% and 31.9%.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper presents a decomposition method dedicated for PAL based CPLDs. Non-standard usage of decomposition, which leads to the minimization of area in an implemented circuit and the reduction of used logic blocks in a programmable structure, is the aim of the proposed method. Each decomposition step (bound set selection, graph colouring, column pattern coding, etc.) is oriented for implementation in a PAL-based structure that is characterized by a PAL-based logic block. The proposed decomposition method is an extension of the classical approach, commonly thought to be adequately efficient. Experiments carried out on typical benchmarks show significant area reduction.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "An FPGA-based fully hardware Kalman filter has been designed and presented and a reconfigurable Kalman filter-based coprocessor in FPGAs has been proposed. High-speed arithmetic function implementations and pipelining have been used and a substantial improvement in performance has been gained. The cycle time (one iteration) for computing Kalman filter is reduced from 1.8274 \u03bcs in our previous design to 0.4013 \u03bcs. The performance gained in our approach includes two to four orders of magnitude higher speed than other implementations. The high-speed, recongifuration and easy-to-develop characteristics of the FPGA-based Kalman filter will largely broaden the real-time application area of Kalman filter.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "An effective development environment has been designed for single-board microprocessor products, providing many of the advantages of conventional development systems but without the high cost of special purpose development hardware, such as in-circuit emulation. The use of a low-cost personal computer combined with the poly FORTH programming language running on the single-board computer solves the problems of cheap access to mass storage and the wish to interact with the hardware during development.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The ignition control requirements of an internal combustion petrol engine are reviewed and the benefits of accurate ignition control are discussed. A design for a microprocessor-based open-loop ignition controller is described and the experimental results obtained with this controller presented. Various means of achieving further improvements are suggested, including a closed-loop controller for optimum ignition timing under all conditions of engine wear. This strategy uses peak cylinder pressure angle as the feedback signal on which the adaptive control is based.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Modern SoC architectures use NoCs for high-speed inter-IP communication. For NoC architectures, high-performance efficient routing algorithms with low power consumption are essential for real-time applications. NoCs with mesh and torus interconnection topologies are now popular due to their simple structures. A torus NoC is very similar to the mesh NoC, but has rather smaller diameter. For a routing algorithm to be deadlock-free in a torus, at least two virtual channels per physical channel must be used to avoid cyclic channel dependencies due to the warp-around links; however, in a mesh network deadlock freedom can be insured using only one virtual channel. The employed number of virtual channels is important since it has a direct effect on the power consumption of NoCs. In this paper, we propose a novel systematic approach for designing deadlock-free routing algorithms for torus NoCs. Using this method a new deterministic routing algorithm (called TRANC) is proposed that uses only one virtual channel per physical channel in torus NoCs. We also propose an algorithmic mapping that enables extracting TRANC-based routing algorithms from existing routing algorithms, which can be both deterministic and adaptive. The simulation results show power consumption and performance improvements when using the proposed algorithms.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Within this article an adaptive approach for parallel simulation of SystemC RTL models on future many-core architectures like the Single-chip Cloud Computer (SCC) from Intel is presented. It is based on a configurable parallel SystemC kernel that preserves the partial order defined by the SystemC delta cycles while avoiding global synchronization as far as possible. The underlying algorithm relies on a classification of existing communication relations between parallel processes. The type and topology of communication relations determines the type and number of causality conditions that need to be fulfilled during runtime. The parallel kernel is complemented by an automated tool flow that allows detecting relevant model-specific properties, performing a fine-grained model partitioning, classifying communication relations and configuring the kernel. Experiments by means of a MPSoC model show that pure local synchronization can provide significant performance gains compared to global synchronization. Furthermore, the combination of local synchronization with fine-grained partitioning provides additional degrees of freedom for optimization.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The GFLOPS project's aim is to develop a parallel architecture as well as its software environment to implement scientific applications efficiently. This goal can be achieved only with a real collaboration among the architecture, the compiler and the programming language. This paper investigates the C// Parallel language and the underlying programming model on a global address space architecture. The main advantage of our paradigm is that it allows a unique framework to express and optimize both data and control parallelism at user-level. The evaluation of C// has been conducted on a cluster of PCs.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper considers the design of a dynamic test bed for the master processor of a realtime, distributed, fault-tolerant computer system. Requirements for a response time of the order of 20 \u03bcs, for synchronized operation with the realtime system during mission time, for handling tasks of different periodicity, for storage and retrieval of large amounts of data, and for fault simulation and display, all add to system complexity. The system described uses a dedicated system approach and an I/O-intensive multi-processing architecture in the iRMX operating system environment. The choice of language, mode of communication, buffer size selection, synchronization scheme, etc. are important aspects considered in the realization of the system.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this work, we extend our previous manuscript regarding a systematic study of data remanence effects on an intrinsic Static Random Access Memory Physical Unclonable Function (SRAM PUF) implemented on a Commercial Off-The-Shelf (COTS) device in the temperature range between [formula omitted]C and [formula omitted]C. As the experimental results of our previous work show, an attack against intrinsic SRAM PUFs, which takes advantage of data remanence effects exhibited due to low temperatures, is possible, resulting in the attacker being able to know the PUF response, with high probability. As demonstrated in our previous work, this attack is highly resistant to memory erasure techniques and can be used to manipulate the cryptographic keys produced by the SRAM PUF. In this work, we examine and discuss potential countermeasures against this attack in more detail, and investigate whether this attack can be performed using an experimental setup that does not guarantee a high degree of thermal isolation. Additionally, we also examine and discuss whether very low temperatures can be used to perform another relevant type of attack against SRAM PUFs, based on whether very low temperature can prevent the SRAM from being overwritten. Finally, we also discuss related works and the generalisation of our results in more detail.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents an energy efficient architecture to provide on-demand fault tolerance to multiple traffic classes, running simultaneously on single network on chip (NoC) platform. Today, NoCs host multiple traffic classes with potentially different reliability needs. Providing platform-wide worst-case (maximum) protection to all the classes is neither optimal nor desirable. To reduce the overheads incurred by fault tolerance, various adaptive strategies have been proposed. The proposed techniques rely on individual packet fields and operating conditions to adjust the intensity and hence the overhead of fault tolerance. Presence of multiple traffic classes undermines the effectiveness of these methods. To complement the existing adaptive strategies, we propose on-demand fault tolerance, capable of providing required reliability, while significantly reducing the energy overhead. Our solution relies on a hierarchical agent based control layer and a reconfigurable fault tolerance data path. The control layer identifies the traffic class and directs the packet to the path providing the needed reliability. Simulation results using representative applications (matrix multiplication, FFT, wavefront, and HiperLAN) showed up to 95% decrease in energy consumption compared to traditional worst case methods. Synthesis results have confirmed a negligible additional overhead, for providing on-demand protection (up to 5.3% area), compared to the overall fault tolerance circuitry.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper reports on research conducted by Smiths Industries (SI) Aerospace within the Control Technology Programme (CTP), to ascertain the feasibility of hardware fault tolerance via dynamic software reconfiguration and to demonstrate its viability in the context of a typical real-time avionic application. Hardware fault-tolerant (FT) systems require the physical replication of hardware components, with the component being the smallest configurable unit. The research approach adopted here is to segregate fully the software (functionality) from the hardware, and regard the configurable units as the software functions themselves. Failure of a component within a computing module would therefore require dynamically reconfiguring the affected software functions elsewhere within the module. Furthermore, it would be possible to reconfigure individual functions not only over different processors but also to currently active processors if spare processing capacity was available in those processors. The computing platform for conducting the research comprised a message-based multiprocessor module, on which was developed a distributed Operating System layer to support both the initial configuration of the application functions and their reconfiguration as a result of user-instigated failure of the module hardware. Software reconfiguration from both module-local memory and module-external backing store was successfully demonstrated for critical and non-critical functions respectively. Based on the research/development system, a self-contained FT module variant was constructed for integration within the System Digital Control Laboratory (SDCL) at BAe Airbus. This module additionally demonstrated the periodic and aperiodic communication capability of the ARINC 629 Combined Mode Protocol (CP) Databus in supporting both the module's functional operation and configuration/reconfiguration process.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The development of front-end converters for power factor correction and DC link voltage control of power electronics converters such as, UPS, Inverters, and Switched Power Supplies, has been attracting great interest from the scientific community that works toward the achievements of cost reduction, high efficiency, and reliability. In this context, this paper proposes a microprocessed control technique for sinusoidal input line current imposition in front-end ac\u2013dc converters. This gave rise to an innovative sensorless boost converter, named in this work as PFC-Boost-CSL. The proposed method is based on experimental acquisition of gate-drive signal sequences for different load conditions. These signals correspond to a complete cycle of the AC input voltage and are recorded in the microcontroller memory in order to be reproduced when used in a boost converter without current sensor. In the operation of PFC-Boost-CSL, a suitable switching sequence is sent to drive the power switch in order to minimize output voltage error and maintain a sinusoidal input current. Aiming to prove the proposed control concept, a 600 W PFC-Boost-CSL prototype was built and analyzed in laboratory and the main experimental results are presented herein.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper summarizes the workplan of the COBRA project. Thereby it emphasizes the work concerning our prototyping environment with special benefit for hardware/software codesign which we use as target architecture in COBRA. This architecture is very flexible, easily extensible, and provides a high gate capacity. It supports standard processor integration as well as processor emulation.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a model-driven framework that provides a tool-supported design flow for fault-tolerant embedded systems. Its system models comprise abstract descriptions of the application and the underlying execution platform. They provide the input to our analysis and optimization techniques that enable the automated exploration of design alternatives for applications with reliability requirements. The automated generation of source code and platform configuration files speeds up the development process. Our contribution is to advance reliability-aware design further into practice by providing an integrated tool framework and removing unrealistic assumptions in the analyzes. The case studies demonstrate the effectiveness of our approach.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We describe the parallel implementation of fully recurrent neural networks (RRN) on a transputer-based multiprocessor system. To train the RNN, the real-time recurrent learning (RTRL) algorithm was used. The computationally intensive sequential RTRL algorithm has been transformed to an equivalent parallel algorithm, realized in a ring topology that can be matched to a variety of target architectures, ranging from application specific VLSI arrays to general purpose multiprocessor systems. A ring array of up to 19 T800 transputers was programmed to efficiently perform the parallel RTRL algorithm. The speedup of the transputer implementation was estimated both analytically and through simulations, and the effect of the communication overhead is discussed. It is shown that as more neuron units are allocated to the same processor the efficiency is increased.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This presentation covers mainly five sections of ARINC 629 physical layer technology. The first three will give an introduction with an historical overview, leading from aeronautical data bus systems in general to the ARINC 629 development. The impact of new avionic architectures such as IMA (integrated modular avionic), ACR (avionic computing resource) and RDC (remote data concentrator), which are creating new data bus requirements will be discussed\u2014considering the ARINC 629 solution in particular. European activities in this area are also mentioned here. In the fourth section, the current status of the B 777 technology is mentioned briefly and the European view on ARINC 629 CP technology is covered in more detail. The fifth section covers physical layer development with a special view on current mode coupling methods. Also, possible alternatives to the present solution will be investigated from technical and economical viewpoints, and the problem areas and advantages of individual solutions will be shown. This will lead to directions for probable solutions in the near future.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents the design and implementation of an RSA cryptosystem using multiple TMS320E15 DSP chips. The system consists of a stand-alone unit containing the DSP hardware and a high-level PC user interface. The system is flexible and allows for additional DSP chips to be inserted in allocated slots to improve its performance. It also allows for trade-off between speed of encryption and level of security. The system was found to be 70 times faster than the same RSA algorithm implemented using C-language at PC level.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper considers a microcomputer implementation of an algorithm for generating sine and cosine functions at high speed and with moderate precision. In essence, the trigonometric functions are derived by interpolating between function values held in a look-up table: the method uses simple integer arithmetic and it does not require the services of an arithmetic coprocessor device. From a detailed examination of interpolation errors, a design rule is established for determining the minimum size of table for a particular function magnitude, and for realizing errors below 1/2 LSB. For those applications requiring increased accuracy, a modification to the basic interpolation algorithm is offered to allow estimation and cancellation of the interpolation errors. As an illustration of the design method, a subroutine that produces sine and cosine function values to 13-bit 2's complement precision on an 80286 microprocessor system is listed. Testing the subroutine's accuracy confirms the validity of the error analysis, the design rule and the interpolation error correcting scheme. Further tests, performed on a range of IBM PC compatible machines, show that the subroutine calculates the function faster than one that relies on the PC's attendant coprocessor device.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper presents a new testing method applicable to VLSI arrays made up of microcomputers as processing elements. A system with single instruction multiple data (SIMD) processing is assumed. In this system, computing elements are connected by a regular interconnection network. A new fault model for the array is presented. Faults are defined at a functional level and allow a systematic test generation procedure to be derived. This procedure is independent of array implementation details and still retains a SIMD characterization. Testing is performed by sequences of instructions. Test sequences are defined by using two ordering criteria. The first criterion establishes the external observability and controllability of the instructions. The second criterion uses instruction cardinality as metric for evaluation of inspection complexity. Algorithms and procedures for a correct execution of functional testing are presented. An example of the application of the proposed technique to an existing parallel scheme made of complex microprocessors is described. The criteria for structuring the test procedure lead to an optimization of fault coverage and a reduction of ambiguity.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "ARINC 653 is currently one year from the completion of its first phase. Phase 1 is intended to meet the requirements of the most critical systems which require strictly deterministic periodic processing. The original hardware platform envisaged for software conforming to ARINC 653 was cabinet-based line replaceable modules communicating with each other over the ARINC 659 backplane databus. However, ARINC 653 conformant software must be compatible with other hardware configurations such as the proposed Avionics Computing Resource (RTCA SC-182) and LRMs with direct ARINC 629 connections and ARINC 429 based systems. This paper describes the challenges facing the ARINC 653 working group in defining a sufficiently rigorous specification of services without constraining the developer to a particular system architecture. The external communications mechanisms and configuration information necessary to realize the aims of portability and re-use are considered. The achievement of \u2018time partitioning\u2019 on a shared processor resource is discussed. The paper concludes with a discussion of future extensions to ARINC 653 to enable reconfiguration of applications both statically and dynamic- ally, and to accommodate aperiodic processes.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The ability to tolerate one failing link in communication networks is sufficient for many practical purposes. One-fault tolerance can also be achieved at much lower cost than methods that can guarantee tolerance of multiple faults. We consider wormhole-routed meshes with two different routing algorithms (dimension order arid positive first) arid for each of these we propose two simple methods that guarantee to tolerate one failing link. Then we study how well these methods work in the presence of multiple faults. Through extensive experiments, we demonstrate that even if these simple methods are not guaranteed to be able to handle more than one fault, there is a high probability of them successfully handling a modest number of faults.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The M3 backplane bus was designed at the beginning of the 1980s with the goal of providing the backbone for development of a new family of multiprocessor systems. Being used by companies which are interested in the system market rather than in selling just boards, M3 did not receive widespread publicity. It did, however, apply some design solutions later incorporated in other better known buses. The paper focusses on the bus design process, and presents the environment and constraints of M3, its key features, current status and position with respect to other standards.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper presents an actuator programming language IPL in brief. This elementary language is optimized to control independent actuators in a distributed environment, where actuators communicate with a machine controller via an intra-machine communication network. In this environment the role of the higher control level is to command independent actuators. The language IPL is found to be suitable for elementary machines, but it is clear that a higher-level programming language is needed for robotics.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The mechanism of multiprocessing (MMP) has been developed and implemented as an enhancement of a standard operating system (OS ES) to support efficient execution of fine-grained parallel activities. The MMP mechanism is presented through the description of its primitives, associated data structures and its interface with the OS ES. Further efficiency enhancement of the MMP mechanism has been achieved by the hardware implementation of the MMP primitives in the specially designed processor, named the MMP processor. The details of its architecture and organisation are given in the paper. Special emphasis is put on the design of the efficient pipelined control, which resulted from the precise timing analysis of the considered design choices.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper compares gallium arsenide and silicon technologies for high-speed digital applications. The bases of comparison are physics, engineering and economics. Gallium arsenide is shown to be limited by engineering and economic considerations; true like-for-like comparisons on speed are almost impossible to obtain. Where complexity is low and performance at a premium, gallium arsenide is probably the best choice, but for even modest complexity silicon bipolar will remain dominant.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "By exploring the scalability of memory controllers (MCs) and ranks in scalable memory systems, larger degrees of memory bandwidth are offered when scaling cores in traditional multicores and embedded systems, and the ratio computation versus memory width - expressed as ratio between the number of cores and MCs - favors the former in detriment to the latter. In scalable memory systems, this ratio tends to balance the number of cores and MCs. Furthermore, since each core has their Last Level Cache (LLC) strongly subject to the number of Miss Status Holding Registers (MSHRs) present, which retain information on all outstanding misses of a specific cache line, it is fundamental to evaluate the impact of these elements in scalable memory systems. Experimental results show that, as reducing the number of MSHRs, memory bandwidth levels are reduced by about 64% and rank energy-per-bit levels are increased of about 36% for different patterns.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a new design that implements the data-driven (i.e. dataflow) computation paradigm with intelligent memories. Also, a relevant prototype that employs FPGAs is presented for the support of intelligent memory structures. Instead of giving the CPU the privileged right to decide what instructions to fetch in each cycle (as is the case for control-flow CPUs), instructions in dataflow computers enter the execution unit on their own when they are ready to execute. This way, the application-knowledgeable algorithm, rather than the application-ignorant CPU, is in control. This approach could eventually result in outstanding performance and elimination of large numbers of redundant operations that plague current control-flow designs. Control-flow and dataflow machines are two extreme computation paradigms. In their pure form, the former machines follow an inherently sequential execution process while the latter are parallel in nature. The sequential nature of control-flow machines makes them relatively easy to implement compared to dataflow machines, which have to address a number of issues that are easily solved in the realm of the control-flow paradigm. Our dataflow design solves these issues at the intelligent memory level, separating the processor from dataflow maintenance tasks. It is shown that using intelligent memories with basic components similar to those of FPGAs produces a feasible approach. Expected improvements within the next few years in underlying intelligent memory and FPGA technologies will have the potential to make the effect of our approach even more dramatic.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We propose pixel pipeline architecture with a selective z-test scheme that focuses on reducing the data processed in the pixel pipeline by employing preprocessing. Reduction of data can reduce the data transmission between the 3D graphics processor and the memory and also reduce the power consumption of memory access, which is a critical point in the case of mobile devices. In 3D graphics processor, most of the memory transmissions are occurred in rasterization stage, especially in pixel pipelines. To reduce memory transmission, the proposed architecture exploits the coherency among pixel fragments to predict the visibility of each pixel fragment. Through this, the proposed architecture eliminates invisible fragments before texture mapping using a single z-test, which would require two z-tests in the mid-texturing architecture. According to the simulations, the proposed architecture reduces data transmission by 19.9\u201322.6% as compared to the mid-texturing architecture at the expense of a 5% reduction in performance. Further, the proposed architecture also reduces the cell area of the depth cache by 26.4% and the area of overall architecture by 6% as compared to that in the mid-texturing architecture.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In 2016, Renes et\u00a0al. were the first to propose complete addition formulas for Elliptic Curve Cryptography (ECC) on Weierstrass curves. With these formulas, the same set of equations can be used for point addition and point doubling, which makes software and hardware implementations less vulnerable to side-channel (SCA) attacks. Further, all inputs are valid, so there is no need for conditional statements handling special cases such as the point at infinity. This paper presents the first ASIC design of the complete addition formulas of Renes et\u00a0al. Each computation layer in the design is balanced, from the field arithmetic to the point multiplication. The design explores two datapaths: a full-width Montgomery Multiplier ALU (MMALU) with a built-in adder and a serialized version of the MMALU. The interface sizes of the MMALU are optimized through an exploration of the design parameters. The register file size is minimized through an optimal scheduling of the modular operations. The top-level point multiplication is implemented using the Montgomery ladder algorithm, with the additional option of randomizing the execution order of the point operations as a countermeasure against SCA attacks. The implementation results after synthesis are generated using the open source NANGATE45 library.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Energy reduction in embedded processors is a must since most embedded systems run on batteries and processor energy reduction helps increase usage time before needing a recharge. Register files are among the most power consuming parts of a processor core. Register file power consumption mainly depends on its size (height as well as width), especially in newer technologies where leakage power is increasing. We provide a register file architecture that, depending on the application behavior, dynamically (i) adapts the width of individual registers, and (ii) puts partitions of temporarily unused registers into low-power mode, so as to save both static and dynamic power. We show that our scheme increases register file area by 3.6% and imposes 2.85% performance overhead on average. Our experimental results on OpenRISC 1200 processor and with selected MiBench benchmark suite show up to 29%, and 54% (24% and 49% on average) reduction in dynamic and static energy consumption of the register file, respectively.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A food recording electronic device to simplify the collection of dietary data is described. The need for a subject to maintain a quantitative account of food intake, and for a dietitian to subsequently code this record prior to computer analysis, are both eliminated using this approach. In combination with an electronic kitchen balance, the recorder, which is based upon a single-board computer (SBC) and special keyboard, enables the weight, food type and time of consumption of each food to be recorded automatically in response to simple key entry. The resident program, transparent to the user, allows data from surveys lasting up to three weeks to be stored for subsequent serial downloading to a host computer.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper presents the results of investigations into techniques for automatically generating concurrent implementations of visual object recognition systems from high-level visual domain descriptions. Visual knowledge can be represented using \u2018schemata\u2019-object-centred recognition models that intentionally represent classes of related objects. Schemata form hierarchies based on relationships such as composition and function. Schema-based representations contain implicit concurrencies that can be exploited by a recognition system called a \u2018recognition network\u2019. The paper presents the design of a simple schema representation language, and shows how it can be automatically transformed into concurrent code. This is done by building a compiler that takes schemata as input and produces a recognition network, in occam , as output. The design of the compiler involves several novel features. The existence of large transputer arrays makes it possible to execute the resulting code with high physical, as well as conceptual, parallelism.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Traditional memory design aims to improve bandwidth and reduce power by trading off memory width and frequency scaling (FS). In this context, we propose [formula omitted] a hardware scheduling mechanism that, for the first time, performs FS on ranks in scalable memory systems which employ Double Data Rate (DDR) synchronous dynamic random access memories (SDRAM). [formula omitted] is able to utilize different rank frequencies via controlling FS intensity - defined as the ratio between the amount of time FS is applied and the total selected scheduled cycle. We propose a design space exploration of [formula omitted] with different FS intensities aiming to determine the behavior of system implications such as bandwidth, rank temperature, and power utilization. Our findings show that for 100% of FS intensity, bandwidth increases proportionally while rank temperature is increased of about +23.7\u00b0C%, and energy-per-bit magnitude is decreased in up to 67%.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Due to the current proliferation of GPU devices in HPC environments, scientist and engineers spend much of their time optimizing codes for these platforms. At the same time, manufactures produce new versions of their devices every few years, each one more powerful than the last. The question that arises is: is it optimization effort worthwhile? In this paper, we present a review of the different CUDA architectures, including Fermi, and optimize a set of algorithms for each using widely-known optimization techniques. This work would require a tremendous coding effort if done manually. However, using our fast prototyping tool, this is an effortless process. The result of our analysis will guide developers on the right path towards efficient code optimization. Preliminary results show that some optimizations recommended for older CUDA architectures may not be useful for the newer ones.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In the digitized world, there is an increased demand for high-speed Time to Digital converters (TDC) in many fields like Nuclear physics, Time of Flight measurements (TOF), Space sciences, medical diagnosis, and imaging. This paper majorly focuses on establishing a Field Programmable Gate Array (FPGA) based Area Efficient and high-performance TDC architectures using KINTEX-7(28\u00a0nm) FPGA. Here, we have proposed an area-efficient shift register-based TDC whose output is a thermometer code. Later, this code is passed to an encoder to produce the relative binary code as an output. We have also proposed two encoding techniques, namely Multiplexer (MUX) based encoder with fourth-order bubble error correction and Scalable encoder to generate the output binary code. Our test results using Vivado Design Suite Software have shown that single channel TDC consumes less logical resources with decreased critical path delay and it will be suitable for multichannel architectures. Kintex-7 FPGA has a maximum clock frequency of 450 MHZ, with which we can achieve a resolution of 2.2\u00a0ns. To obtain the picoseconds resolution, we can use our TDC in multiple stages, connected in a ring configuration, which can provide fine interpolation and wider dynamic range. In this paper, finally we implemented all the encoders in 180\u00a0nm CMOS technologies to estimate the chip layout\u00a0area and power.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The mechanical structure and control system architecture for pneumomechanical single-axis modular units are described. The units were designed as subsystems to allow the construction of robots with kinematics suitable for a wide range of workhandling tasks. The controls also demonstrate modularity with regard to both software and hardware. They have been designed to reduce the systems engineering required when user-defined manipulators are being constructed and to provide a user-friendly interface for operators.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Long-range dependence is a property of stochastic processes that has an important impact on network performance, especially on the buffer usage in routers. We analyze the presence of long-range dependence in on-chip processor traffic and we study the impact of long-range dependence on networks-on-chip. long-range dependence in communication traces of processor ip s at the cycle-accurate level . We also study the impact of long-range dependence on a real network-on-chip using the SocLib simulation environment and traffic generators of our own. Our experiments show that long-range dependence is not an ubiquitous property of on-chip processor traffic and that its impact on the network-on-chip is highly correlated with the low level communication protocol used.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this paper, an on-chip interconnection scheme called Heterogeneous IP Block Interconnection (HIBI) is presented. HIBI offers a scaleable and easy to use architecture for system-on-a-chip designs. Its most distinguishing feature is the lack of a central arbiter and specialized arbitration signals. The arbitration is distributed among the connected agents that are made aware of each other's communication requirements. This enables data transmissions with very low latencies and also minimizes the amount of needed signal lines. These features make the scheme a good fit to continuous-media systems transmitting large amounts of streaming data. With the presented interconnection scheme, bus efficiencies greater than 90% have been achieved in several test cases. With the streaming burst transfers and time slot based accesses of HIBI, throughputs of over one data transmission per clock cycle are possible.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Helmet Mounted Sight and Display systems are now in service in military aircraft. Although these systems share some common features with ground based `virtual reality' systems, the military cockpit environment and the application they are used for, dictate a different approach in the design, development and qualification for military use. The primary function of the Aircrew helmet is to protect the pilot. The advent of helmet mounted displays places additional constraints on the helmet which is now an important element of the cockpit displays system, providing weapon aiming, and other information to the pilot. The design of HMDs for the military cockpit environment is therefore a demanding task if the operational benefits are to be realised without affecting pilot safety. Many designs now use the helmet visor as the display surface rather than eyepieces in front of the pilots eyes. This has resulted in a family of visor projected displays which cater for a range of requirements from simple day helmet mounted sights to wide field of view, 24 h displays. This paper provides an overview of the visor projected HMD design and technology, discusses the building blocks within a typical HMD system and describes practical implementation for several different applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The merits of microprocessor development on a host mini-computer system are described, using crossassemblers and crosscompilers. Aspects of cost are developed particularly and a crossdevelopment system is proposed as being far lower in cost than stand-alone microprocessor development systems, providing that there is already a computer available. For multiple users, crossdevelopment systems may be more economical than individual systems, even if the host computer is purchased specifically for that purpose. The second section describes the author's development system. A PDP-11/60 is used for writing and generating object programs for the MC6800. A commercial crossassembler, a crossassembler written by the author and a crosscompiler written by the author are used. Construction details for the system are provided and examples of typical development sessions are given.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In recent years, Phase Shift Keying (PSK) has been often used for digital modulation of satellite link because of its good noise resistance. The PSK demodulation requires complex hardware which becomes a constraint for some applications. In this paper a new scheme is proposed for the demodulation. When compared to conventional schemes such as costas loop and square loop, the proposed scheme uses a very simple technique and requires very less hardware for the realization. But the scheme is more suitable for low noise environment applications such as the one discussed in the paper. Performance analysis of the proposed scheme is also briefly presented here.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A DS-link is a high-speed point-to-point serial interconnect, originally developed for interprocessor communication, which can also be applied in communication systems. Electrical (twisted pair cable) and fibre-optic technologies for link signal transmission have been studied and their performance in terms of link speed and length has been measured. In order to extend the reach of DS links, a fibre-optic interface employing a new line encoding scheme has been designed and characterized. The DS-link interconnect is specified in the IEEE standard 1355.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Industrial process control requires acquisition of data, calculation of the appropriate control action and output of a signal to effect that control action. The advent of microcomputers has resulted in a trend towards distributed, rather than centralized, control. This trend is in part due to the development of interfaces for industrial input and output. After, an introduction to the requirements for data acquisition and control, the development of microcomputer systems is traced, illustrated by consideration of particular units.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents an approach for incorporating the effect of various logic synthesis options and logic level implementations into the custom instruction (CI) selection for extensible processors. This effect translates into the availability of a piecewise continuous spectrum of delay versus area choices for each CI, which in turn influences the selection of the CI set that maximizes the speedup per area cost (SPA) metric. The effectiveness of the proposed approach is evaluated by applying it to several benchmarks and comparing the results with those of a conventional technique. We also apply the methodology to the existing serialization algorithms aimed at relaxing register file constraints in multi-cycle custom instruction design. The comparison shows considerable improvements in the speedup per area compared to the custom instruction selection algorithms under the same area-budget constraint.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Networks\u2212on\u2212chip (NoC) are an alternative to alleviate the problems of legacy interconnect fabrics. However, many emerging technology NoC are developed and are now seen as their potential substitutes. In this context, this work introduces how the NoC industry is involved in the NoC technology design\u2212trends and promotion. Secondly, an extensive discussion on the outstanding research problems and challenges for conventional and emerging technology NoC is developed. The related security concerns are particularly investigated.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Interconnection architectures for hierarchical monitoring communication in parallel System-on-Chip (SoC) platforms are explored. Hierarchical agent monitoring design paradigm is an efficient and scalable approach for the design of parallel embedded systems. Between distributed agents on different levels, monitoring communication is required to exchange information, which forms a prioritized traffic class over data traffic. The paper explains the common monitoring operations in SoCs, and categorizes them into different types of functionality and various granularities. Requirements for on-chip interconnections to support the monitoring communication are outlined. Baseline architecture with best-effort service, time division multiple access (TDMA) and two types of physically separate interconnections are discussed and compared, both theoretically and quantitatively on a Network-on-Chip (NoC)-based platform. The simulation uses power estimation of 65 nm technology and NoC microbenchmarks as traffic traces. The evaluation points out the benefits and issues of each interconnection alternative. In particular, hierarchical monitoring networks are the most suitable alternative, which decouple the monitoring communication from data traffic, provide the highest energy efficiency with simple switching, and enable flexible reconfiguration to tradeoff power and performance.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In comparing two signed operands, it may be shown theoretically that, if operand 1 is greater than operand 2, then flag bit X5 is reset; otherwise X5 is set. In this paper, JX5 and JNX5 instructions are used for checking the set and reset conditions, respectively, of X5 in proper branching within a program. The above criteria are verified experimentally using the SDK-85 design kit.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Wireless Sensor Network (WSN) requires Signal Processing and control applications in order to use technology effectively. Digital Signal Processing presents a wide range of applications in various fields with the exception of WSN due to the power constraint factor. The Spectrum holes can be effectively utilized by means of spectrum sensing technique in WSN. Multiply and Accumulate unit (MAC) is the computation Kernel in DSP Systems which in turn computes the overall speed of the system. Also, MAC is the major power consumption block due to its complex operation. Developing low power and high speed MAC and utilizing it in spectrum sensing for WSN is a challenging task. In this research, Low Latency Column Bit Compressed (LLCBC) MAC architecture is used for spectrum sensing by examining the hardware complexities. The Architecture is synthesized with 90\u202fnm standard CMOS library using cadence SoC encounter.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "According to the ITU-T, the quality of a multimedia service is defined by a set of user-related parameters: delay, delay variation, and information loss. To provide multimedia applications with end-to-end QoS guarantees, an efficient resource reservation and management strategy has to be adopted. This paper presents a schema for satisfying multimedia QoS parameters over a real-time operating system, which adopts the rate monotonic as a scheduling algorithm. Such a schema is implemented in a real-time based architecture for QoS multimedia provisioning. This architecture allows to define classes of services with different quality attributes concerning the multimedia data delivery.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A new generation of software-based protection systems for high-performance trains has been designed during the last 10 years. The first application is now in operation on the Paris heavy-rail RER, a line with a peak capacity of about 800 000 passengers per day. In this project, the new protection system performs a full overlay of all train protection functions, with the ability to reduce the headway between trains while permanently monitoring train speed. The software is wholly written in modula-2 and represents 20k source lines for the application. This software is safety critical and required (including the development of specific software tools) 1000 man-months for specification and implementation. The paper illustrates the use of modula-2 for the development of safety-critical applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Developing a safety critical real-time application raises high challenge: \u201cfailure is not an option\u201d. The code has to be readable, reliable and efficient. For doing so, VERILOG has developed an environment based on formal approach. This is the only way to be in a position to prove that the code is doing what it is supposed to do, always.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A range of commercially available processors is investigated to evaluate their potential in image processing systems. The examination covers a selection of the more important instructions in use in image processing algorithms and a selection of the algorithms themselves as a simple benchmark. It also includes a survey of multiprocessor systems implemented with some of these processors. It is concluded that digital signal processors (DSPs) are better suited to embedded systems but the transputer may offer advantages in a research environment, of general usefulness for supercomputing power.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper describes a form of content addressable memory based on a dynamically configured state machine. This device has particular application to serial data systems, such as local area networks. The system described provides a cost-effective solution to the problem of address recognition in packet based network technologies such as Ethernet, and has applications in network bridges, routers and ATM switching nodes. A particular feature is that address matching can be performed on the serial data stream with no additional time overhead.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The design and application of a DSP-based Parallel Image Processing system is presented. A scaleable system based around a TMS320C40 DSP Master\u2013Slave architecture is shown to be a suitable vehicle for industrial inspection problems. Custom vision bus and parallel communication channels are used to pass data between local and shared memory in the image processing system. The target application of SMT solder bond inspection required the fast processing of 2-D FFTs. Analysis of the system's suitability to this task is presented followed by actual results from a three-processor system. The target inspection rate of 100 SMT solder joints per second can be met.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Railway signalling systems are based on fault-tolerant and fail-safe techniques to provide high reliability and safety. Transputers offer multiple communication links and provide a high degree of parallelism and are being used in safety-critical and fault-tolerant applications. We propose a fault-tolerant and fail-safe node using transputers for a local area network with dual ring topology to be used in distributed railway signalling systems. The proposed scheme uses a new technique of leadership based on rotation amongst the transputers of the node. Aspects of safe shutdown, recovery, reconfiguration and clock synchronization of the fault-tolerant and fail-safe node are addressed. Formal specifications of the fail-safe node and the simulation of the proposed technique are also given.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper provides an overview of the concepts of \u2018risk\u2019 and \u2018safety integrity\u2019 in relation to safety-related electrical/electronic/programmable electronic systems. The paper is an abridged version of Annex A of the emerging International Electrotechnical Commission (IEC) Standard: \u2018Functional safety of electrical/electronic/programmable electronic systems\u2019. Although based on Annex A, the authors have deviated in a few instances from its strict wording in order to more properly represent their own views. Where this occurs, a note in the text has been added to alert the reader to the deviation. The concepts of risk, including tolerable risk, safety integrity, safety-related systems, system and software integrity levels, are discussed.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Many applications in mobile and embedded systems like signal processing, machine learning, kinematics, dynamics, and control depend on computationally expensive matrix operations. However, such systems underlie tight constraints regarding power consumption and physical space, which prohibits the usage of powerful multicore systems. In this paper, we propose a novel scalable and power-efficient architecture for matrix algebra in FPGA-based Systems-on-Chip. The architecture is based on a linear systolic array and has been developed with a focus on flexibility in order to be adapted to different applications. We evaluate the performance, resource utilization and power consumption of different configurations and show that it provides significant speed-ups over a mobile processor and is significantly more power efficient than a standard PC.",
            "prediction": "Most likely AI-generated",
            "source": "Human"
        },
        {
            "abs": "A microsequencer lies at the heart of any microprogrammed control unit, being responsible for stepping through the microinstructions of a microprogram. Until recently, microprogrammed control units were implemented either by large quantities of TTL logic and a ROM or by more modest amounts of TTL logic, a ROM and a few bit-slice devices. The Altera EPS444/448 standalone microsequencer contains all the logic needed to implement a microsequencer on a single chip. Inside the device there is a microprogram sequencer, branch control logic, a microprogram return address stack, a microprogram memory and a user programmable microcode EPROM that holds the microprogram to be executed. This single device, when programmed, provides the functionality of a custom IC without the time or expense of designing one. The EPS444 and EPS448 have relatively short microinstruction outputs (12 bit and 16 bit respectively) that are intended for high-performance controller designs, but they may also be used for simple microcoded control units. The EPS444/448 offers an ideal solution to the design of a synchronous state machine. Synchronous state machines are attractive alternatives to microprocessors where simplicity, speed, performance and economics are more important than the versatility of microprocessors. This application note, taken from the Altera EPS444/448 data sheet, describes the operation of this sequencer and its instruction set.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "There are two main ways in which aids are designed to allow those with impaired sight access to information technology. Adaptations of existing equipment for sighted users can be made. An alternative approach is to replace sight-oriented systems with systems designed specifically for sound and touch. Currently used techniques for this purpose are described.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Optical feedback or self-mixing interferometry technique has been widely used for sensing vibration, displacement, velocity, distance and flow applications. Such applications require an accurate and consistent output for real-time target measurements. Furthermore, array based sensing, as opposed to point sensing, is being increasingly pursued which requires multiple-input, parallel computing platform. In this article, we have proposed and developed a real-time interferometric sensor applications based multi-core system architecture and programming toolkit. To show that our system is useful in a variety of situations, we applied three algorithms of varying complexity and accuracy for displacement and vibration measurement. In order to prove the efficiency of proposed sensor processing system, we compared it performance and power consumption with a state of the art NXP LPCX54102 sensor processing and motion system architecture. When compared with the baseline multi-core system, the results show that our system improves the system performance upto 7.55 times, draws 15.6% less dynamic power and consumes 8.9 times less energy.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The introduction of SRAM-based field programmable gate arrays (FPGAs) has opened up a new dimension to parallel computing architectures. This paper describes an alternative approach to parallel computing \u2014 reconfigurable or virtual parallel processing (VPP). Rather than mapping an application onto a given parallel machine, the WP approach synthesizes the appropriate type and number of processing elements, as well as the interconnection topology, that is optimal for the application. For each application, configuration data is downloaded to the machine that personalizes the hardware for the task at hand. The paper provides a brief description of the authors reconfigurable computer, Archimedes . The benefits of the VPP approach are highlighted by two example applications \u2014 the 2-D FFT and a narrow-band digital filter. A novel parallel implementation of a polynomial transform based 2-D transform is described and compared with results for distributed memory parallel machines that have been reported in the literature. The comparison highlights the computational advantage provided by reconfigurable computing. The digital filter implementation employs sigma\u2013delta modulation encoding to reduce the arithmetic workload. The application of this technology to a communications receiver is explained.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In order to fulfill the ever-increasing demand for high-speed and high-bandwidth, wireless-based MCSoC is presented based on a NoC communication infrastructure. Inspiring the separation between the communication and the computation demands as well as providing the flexible topology configurations, makes wireless-based NoC a promising future MCSoC architecture. However, congestion occurrence in wireless routers reduces the benefit of high-speed wireless links and significantly increases the network latency. Therefore, in this paper, a congestion-aware platform, named CAP-W, is introduced for wireless-based NoC in order to reduce congestion in the network and especially over wireless routers. The triple-layer platform of CAP-W is composed of mapping, migration, and routing layers. In order to minimize the congestion probability, the mapping layer is responsible for selecting the suitable free core as the first candidate, finding the suitable first task to be mapped onto the selected core, and allocating other tasks with respect to contiguity. Considering dynamic variation of application behaviors, the migration layer modifies the primary task mapping to improve congestion situation. Furthermore, the routing layer balances utilization of wired and wireless networks by separating short-distance and long-distance communications. Experimental results show meaningful gain in congestion control of wireless-based NoC compared to state-of-the-art works.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The 8-bit microprocessor has not been rendered obsolete by newer and more powerful 16- and 32-bit microprocessors. Many applications are more than adequately served by 8-bit microprocessors, with their lower-cost address and data buses. However, there is a \u2018grey area\u2019 in which 8-bit chips are not sufficient but 16-bit chips represent an uneconomic \u2018overkill\u2019. A significant limitation of 8-bit microprocessors with 16-bit address buses is their inability to access more than 64 kbyte of data. This application shows how the SN54/74LS610-3 series of memory mapping units enables an 8-bit microprocessor to access memories much larger than 64 kbyte without significantly increasing the chip count of the system. Note that a memory mapping unit cannot simply be engineered into a microprocessor system without adding the appropriate software, as the 8-bit microprocessor can still address only 64 kbyte of logical address space at any instant. Software is usually included in the operating system to map 64 kbyte of the physical memory onto the logical address space.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper describes a programmable digital audio time delay system which uses the 6809 microprocessor to store and retrieve 12-bit samples in RAM. A/D and D/A conversions were accomplished by a 12-bit analogue I/O board for the Apple II microcomputer. A 6809 machine code time delay program, which was run on a 6809 coprocessor board for the Apple II, was able to attain an audio frequency response of over 14 kHz.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The unusual class of multiprocessors which employ a global memory and private process access environments presents intriguing possibilities for machines which retain high efficiency even when process interactions are relatively frequent. Because all writable data is private to a process, such machines are free from the cache consistency concerns of shared-variable architectures, while, in contrast to distributed memory machines, a global memory is available for code and data which is physically (not logically) shared. An example of this class of multiprocessors, the virtual port memory (VPM) architecture, is apparently scalable to at least 256 processors using only a simple bus-based interconnection network. A prototype VPM machine is discussed, including a comparison of its scalability with that of the Butterfly multiprocessor. VRAM global memory and second-generation RISC processors are discussed as enhancements for this architecture.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This article presents an integrated self-aware computing model in a Heterogeneous Multicore Architecture (HMA) to mitigate the power dissipation of an Orthogonal Frequency-Division Multiplexing (OFDM) receiver. The proposed platform consists of template-based Coarse-Grained Reconfigurable Array (CGRA) devices connected through a Network-on-Chip (NoC) around a few Reduced Instruction-Set Computing (RISC) cores. The self-aware computing model exploits Feedback Control System (FCS) which constantly monitors the execution-time of each core and dynamically scales the operating frequency of each node of the NoC depending on the worst execution-time. Therefore, the performance of the overall system is equalized towards a desired level besides mitigating the power dissipation. Measurement results obtained from Field-Programmable Gate Array (FPGA) synthesis show up to 20.2% dynamic power dissipation and 16.8% total power dissipation savings. Since FCS technique can be employed for scaling the frequency and the voltage and on the other hand, voltage supply cannot be scaled on the FPGA-based prototyped platform, the implementation is also estimated in 28nm Ultra-Thin Body and Buried oxide (UTBB) Fully-Depleted Silicon-On-Insulator (FD-SOI) Application-Specific Integrated Circuit (ASIC) technology to scale voltage in addition to frequency and get more benefits in terms of dynamic power dissipation reduction. Subsequent to synthesizing the whole platform on ASIC and scaling the voltage and frequency simultaneously as a Dynamic Voltage and Frequency Scaling (DVFS) method, significant dynamic power dissipation savings by 5.97X against Dynamic Frequency Scaling (DFS) method were obtained.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Cyber-physical systems (CPS) are expected to continuously monitor the physical components to autonomously calculate appropriate runtime reactions to deal with the uncertain environmental conditions. Self-adaptation, as a promising concept to fulfill a set of provable rules, majorly needs runtime quantitative verification (RQV). Taking a few probabilistic variables into account to represent the uncertainties, the system configuration will be extremely large. Thus, efficient approaches are needed to reduce the model state-space, preferably with certain bounds on the approximation error. In this paper, we propose an approximation framework to efficiently approximate the entire model of a self-adaptive system. We split up the large model into strongly-connected components (SCCs), apply the approximation algorithm separately on each SCC, and integrate the result of each part using a centralized algorithm. Due to a number of changes in probabilistic variables, it is not possible to use static models. Addressing this issue, we have deployed parametric Markov decision process. In order to apply approximation on the model, the notion of \u03b5-approximate probabilistic bisimulation is utilized that introduces the approximation level \u03b5. We show that our approximation framework offers a certain error bound on each level of approximation. Then, we denote that the approximation framework is appropriate to be applied in decision-making process of self-adaptive systems where the models are relatively large. The results reveal that we can achieve up to 50% size reduction in the approximate model while maintaining the accuracy about 95%. In addition, we discuss about the trade-off between efficiency and accuracy of our approximation framework.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A cost-effective design of an ultrasonic interface to a graphics tablet is accomplished by means of PIC microcontrollers. This paper analyses the design and implementation from requirements capture through high-level design to circuitry. Ultrasonic transducers enable direct placement of the tablet mechanism above an LCD so that the image is viewed as it is created. Results show that the prototype tablet has up to 0.8 mm resolution.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper describes a novel codesign tool for rapid prototyping FPGA's in hybrid systems (HW+SW+analog+RF+electromechanical+user interface). This tool uses Simulink\u2122 from The Mathworks as a high level description language, as well as a flexible simulation environment. After functional simulation and parameter tuning, the user partitions the system into digital HW, SW and analog HW. A performance/cost analysis of the partitioned system can then be made and architectural parameters can be optimized. After the simulation, the proposed codesign tool automatically compiles the digital HW (respectively, SW) subsystem for any user-defined FPGA (respectively, DSP/PC/microcontroller/softCore), in a rather transparent way. Analog subsystems can only be simulated but not yet compiled for analog FPGA's. The paper also shows the many advantages of the proposed codesign flow, among which, a short time-to-market, an improved flexibility and reusability, a more reliable design, a better final cost/performance ratio. The tool simulates and compiles all integer, fixed-point and floating-point data formats and all scalar, vector and matrix data which are supported by Simulink, both for HW and SW, therefore it is suited to virtually all Signal Processing algorithms. A few practical cases are described at the end of this paper.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The selection method of resource adjustment strategy is a key step of multi-VM (Virtual Machine) resource adjustment in a single physical machine (PM). The traditional genetic algorithm (GA) do not evaluate and filter the initial population, and not make full use of decision of historical data as to increase the optimal solution time either. Based on the conventional research, this paper establishes the relation model between the service performance and the amount of resources consumption (P-R model), which is used to evaluate and filter the initial population, and presents design method of the revenue function and the termination conditions. It also presents the way which turns the empirical data into historical decision and uses it in the next cycle. The experiment results indicate the method is able to maintain high resource utilization and meets the demands of response time.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In modern signal processing, there are increasing demands for large-volume and high-speed computations. At the same time, VLSI has had a noticeable effect on signal processing by offering almost unlimited computing hardware at low cost. These factors combined have affected markedly the rapid upgrading of current signal processors. We review the influence of the basic VLSI device technology and layout design on VLSI processor architectures. The array processors in which we take special interest are those for the common primitives needed in signal processing algorithms such as convolution, fast Fourier transforms and matrix operations. Regarding VLSI devices, special emphasis is placed on alleviating the burden of global interconnection and global synchronization. For cost-effective design, programmable processor modules are adopted. On the basis of these guidelines, we establish the algorithmic and architectural footing for the evolution of the design of VLSI array processors. We note that the systolic and wavefront arrays elegantly avoid global interconnection by effectively managing local data movements. Moreover, the asynchronous data-driven nature of the wavefront array offers a natural solution to get around the global synchronization problem. The wavefront notion lends itself to a wavefront language (matrix dataflow language (MDFL)) which simplifies the description of parallel algorithms.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Flash memory offers the same non-volatile storage as EPROM but also provides in-system write capability. Using Intel's 28F001BX for BIOS storage, code updates may be carried out quickly in the factory during test and debug, while allowing cost-effective field updates to end users via floppy discs or modem BBS. This application note describes various methods of implementing a flash memory BIOS using the 28F001BX. Design targets are both laptop and desktop systems. The primary emphasis is on application of flash memory for BIOS and ROM executable software applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The logic cell array (LCA) is a programmable logic circuit that can require a high level of design capability from digital systems designers intent on using it. System support is available in the form of CAE software, much of it PC based, which makes the task of logic design for the LCA device a relatively straightforward process. The OrCAD schematic capture program and interface conversion software allows the designer to use schematic entry on a PC-AT. This makes logic design within the LCA less product specific because the designer does not need to know much detail of the LCA architecture. This is especially useful to those designers who do not have a background in designing with programmable logic devices and are unfamiliar with software packages that support Boolean and state machine design entry. Also, the schematic capture package provides an output that can be used for documentation, giving a range of standard symbols for gates and register logic that varies in degrees of complexity up to counter and shift register circuits. The application note describes the design of a video controller circuit in the M2064 LCA device using the OrCAD SDT/111 schematic capture package, support libraries and interface software.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The primary goal of first generation RISC processors was to achieve an average execution rate of one instruction per clock cycle (CPI or clocks per instruction). Once this goal is achieved, the same architecture can be implemented in technologies that offer very high clock rate and achieve high performance. The paper discusses two basic aspects of implementing an architecture in ECL, using a case study of MIPS R3000 and R6000 processors. The first concerns the architectural elements that make R3000 easy to implement in ECL, and the second looks at how to resolve the problems raised by a wide gap between processor clock speed and main memory speed.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The goal of designing a special-purpose computer is to offer a highly efficient computer-aided environment for circuit simulation using hardware description languages. The suggestion is to have a machine that supports bitstring operations. A bitstring comprises a sequence of bits and must have at least one bit, and is found to be the predominant operation in hardware description languages, yet not a common operation in Pascal-like languages. A special-purpose machine is proposed and its hardware architecture reflects the characteristics of a hardware description language. The main part of this paper deals with the design concepts of the hardware machine, which is derived directly from the run-time requirements of hardware description programs. We start by examining examples of these programs and their operators, then identifying areas which can be improved through the use of hardware. Next, we present the architecture of the machine and bitstring operators that are supported. The instruction format is also presented and some comparisons are made to the reduced instruction set computers. Finally, we study the related works that have been conducted elsewhere.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Data processing on a continuously growing volume of data and the increasing power restrictions have become an ubiquitous challenge in our world today. Besides parallel computing, a promising approach to improve the energy efficiency of current systems is to integrate specialized hardware. This paper presents two application-specific architectures to accelerate basic database operators frequently used in modern database systems: an extended instruction set based on a given Cadence Tensilica processor\u00a0(ASIP) and a comparable application-specific integrated circuit\u00a0(ASIC). The ASIP is implemented in a system-on-chip and manufactured in a 28\u00a0nm CMOS technology to realize measurements of performance and power consumption. Furthermore, the comparison with the ASIC blocks allows to quantify the results with the ASIP approach in terms of throughput, area, and energy efficiency as well as to discuss the capabilities and limitations when accelerating selected database operators.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The problem of lifetime maximization of PCM has been well studied. The arrival of non-volatile memory devices has replaced the traditional DRAM. Still the DRAM has many limitations on endurance and high power write operations. Similarly, number of designs has been discussed earlier to maximize the lifetime of PCM by catching the main memory at available DRAM. Still they could not achieve the performance on power consumption reduction and increasing memory utilization. To improve the performance in power consumption reduction and lifetime maximization, and categorical model is presented in this paper. The proposed method categorizes the processes according to their memory access activity. The categorized process has been allocated to respective part of hybrid memory which encourages maximum read and minimum write in PCM. The proposed method increases the lifetime of PCM than other methods.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "With the growth of the embedded devices consumer market, power efficient hardware is needed. Therefore power-aware architectural exploration is one of the most crucial design steps. For such an exploration procedure, it is important to accurately model the power consumption of all main components of the embedded system. Registers and register files are one of the highest power consumers of any programmable processor, but there is a lack of accurate and publicly available models. This paper provides such a power model for standard cell based register files for 130 and 90 nm technologies. The proposed model provides dynamic power, leakage power, area and timing information for register files in terms of key parameters like width, depth, activity, ports, and capacitive loading. It is shown that current models capture neither correct absolute nor relative trends present in register files. It is shown that some key, but often neglected parameters like switching activity, load have a larger influence in some particular sizes of the register files than others. Therefore, using the Empire model, accurate architectural exploration is possible.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Correlation is a mathematical technique normally found in texts on analogue signal processing, control theory or pattern recognition. However, correlation is a technique that can be applied to digital signals just as well as to analogue signals. Indeed, it is now possible to obtain ready-made digital correlators. What then is correlation? In the simplest of terms, correlation involves \u2018sliding\u2019 two sequences of signals against each other and then attempting to determine how closely the sequences resemble each other as they move with respect to each other. This application note provides an overview of digital correlation and demonstrates how correlation techniques can be applied to the detection of particular patterns in a data stream, to the synchronization of detectors in demodulation processes and to the determination of the time delay between two digital sequences.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Mil-Std-1553B is a well established serial, digital, multiplex data bus standard used in military realtime system applications. The standard is now finding applications in the commercial and industrial sector because of its inherent flexibility and durability in harsh environments. The history and main features of the standard are presented, together with an indication of why it was developed and how it is applied in systems design. A brief comparison is made with three commercial counterparts, and possible future developments are discussed.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "HARP (the Hatfield RISC processor) is a reduced instruction set processor being developed at Hatfield Polytechnic, UK. The major aim of the HARP project is to develop a RISC processor capable of a sustained instruction execution rate in excess of one instruction per cycle. Investigations to date support the hypothesis that this goal can be achieved by the development of an integrated processor-compiler pair in which the processor is specifically designed to support low-level parallelism identified by the compiler. This paper describes the HARP architectural model and discusses those features which support parallel instruction execution. Parallelism is provided in the hardware by multiple instruction pipelines which execute independent RISC-like instructions simultaneously. The principal techniques employed to exploit the available parallelism are efficient pipelining, register bypassing, optional register writeback and conditional execution of instructions. Examples are given which illustrate the effectiveness of these techniques in increasing the performance of HARP.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A study has been carried out to specify the undefined flag bits, D3 and D5, of the Z80 microprocessor. The set-reset conditions for D3 and D5 were observed experimentally with 50 different data sets under various instructions. Conclusions are drawn from the results of these tests about the set-reset conditions of the unspecified flag bits.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper proposes techniques for face detection using Haar-like features as weak classifiers and gives the implementation details for an FPGA development board. We analyze and discuss the relation between the system computation cost and selection of the image scaling factor. Based on the empirical results of our previous work, we give a new method to select the stop threshold for the image reduction process, which reduces the total computation by half. We present and implement an improved integral image pipeline calculation design. We also provide a color image output mode to let our system enjoy more human-oriented design. Test results show that the system achieves real-time face detection speed (100 fps ) and a high face detection rate (87.2%) for an SVGA (600 \u00d7 800) video source. The low power consumption (3.5 W) is another advantage over previous work.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper aims for accurate diagnosis of arrhythmia beats in real time to enhance the health care service for cardiovascular diseases. The proposed methodology for the diagnosis involves the integration of the R-peak detection algorithm, FFT (fast fourier transform) based discrete wavelet transform for feature extraction and feedforward based Neural Network Architecture to classify generic cardiac beat classes into eight categories namely Right Bundled Block, Left Bundled Block, Preventricular Contraction (PVC), Atrial Premature Contraction (APC), Ventricular Flutter wave (VF), Paced Beat, Ventricular Escape (VE) and Normal beat. The paper contributes the development, prototyping and analysis of proposed methodology on ARM (Advanced RISC Machine) based SoC (System-on-Chip) in laboratory setup. This system is validated by generating real-time ECG signals using MIT-BIH database while the output of the system is monitored on the displaying device. The performance analysis of the proposed methodology implemented on the microcontroller based system is computed by performing the experiment which achieves a high overall accuracy of 97.4% with average sensitivity ([formula omitted]) of 97.57%, specificity ([formula omitted]) of 99.59% and positive predictivity ([formula omitted]) of 97.93%. The system provides an assistive diagnostic solution to the users to lead a healthy lifestyle. Moreover, the ARM-based system can be fabricated into a handheld device for reliable automatic monitoring of the condition of heart by patients.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Promoting energy efficiency to a first class system design goal is an important research challenge. Although more energy-efficient hardware can be designed, it is software that controls the hardware; for a given system the potential for energy savings is likely to be much greater at the higher levels of abstraction in the system stack. Thus the greatest savings are expected from energy-aware software development, which is the vision of the EU ENTRA project. This article presents the concept of energy transparency as a foundation for energy-aware software development. We show how energy modelling of hardware is combined with static analysis to allow the programmer to understand the energy consumption of a program without executing it, thus enabling exploration of the design space taking energy into consideration. The paper concludes by summarising the current and future challenges identified in the ENTRA project.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Estimation of circuit testability is an important issue when evaluating the circuit design. A testability measure indicates how easy or difficult it would be to generate tests for the circuit. STAFAN (Statistical Fault Analysis) is a well known gate-level testability analysis program which predicts the fault coverage of a digital circuit under the stuck-at fault model, without actually performing fault simulation. STAFAN offers speed advantage over other testability analysis programs such as SCOAP; further, it explicitly predicts the fault coverage for a given test set, unlike other testability measures which are harder to interpret. We show how a STAFAN-like testability analysis program can be constructed for circuits built out of register-level modules such as adders, multipliers, multiplexers, and busses. Our tool, which we call FSTAFAN, is useful in a testability-driven high-level synthesis environment. We have implemented FSTAFAN on a Sun/SPARC workstation and describe its performance on some register-level circuits.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Demand Side Management (DSM) is one of the most important parts of future smart power grid. With the rise in global energy awareness, smart grids enhance the potency and peak levelling of power systems. DSM is the controlling scheme in such grids and it aims to optimize several characteristics of load demand. This smart grids comprises energy storage (battery) and distributed solar photovoltaic generation storage. In this proposed methodology the combination of Glow-worm Swarm Optimization (GSO) and Support Vector Machine (SVM) is used for decision making process in battery storage to reduce the electricity tariff. GSO is a powerful technique to obtain near optimal solution which is used for this load rescheduling problem for a sample test system to minimize the cost of end user. Especially, the electricity expenditures of the end user can be reduced by responding to pricing which changes with different hours of a day.\u00a0 Then optimized range of the battery's energy storage is extracted from the GSO. Here, the SVM is trained based on the optimized data from the GSO. This combination is used for finding the amount of energy is transferred in/out the battery which aims the minimal electricity bill value. The electricity tariff of the proposed methodology of Average gosc is 2.27 for residential load, while considering it is less when compared to the existing method of 2.3 at the consumed load of 8.2\u202fkWh/day. The proposed GSO-SVM method reduces 11.2% of energy cost which helps decision makers to take best demand-side actions for balancing the stability.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Memory race recording is a key technology to replay multithreaded programming deterministically. Modern computers supply efficient communication mechanism and memory races occur frequently. So it is significant to develop an efficient memory race recording algorithm with low log growth rate and rapid replay speed. This paper proposes a new efficient point-to-point memory race recording algorithm, called CCTR, which writes a small race log with small hardware state, operates well as the number of cores per system scales, and can replay multithreaded programs at production run speed. CCTR uses a new relative indirect dependency to present each memory race instead of its precise dependency. In this dependency, CCTR need not store any timestamp for each memory block and detects memory races in chunks. Through simulation on 4-core chip multiprocessor (CMP), a good result is achieved which includes smallest log growth rate (\u223c5 bytes per thousand memory instructions), small hardware state (\u223c504 bytes per core), low runtime overhead (less than 2%), low bandwidth overhead (\u223c7%) and good scalability.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Designs targeted for FPGAs are becoming increasingly large and more complex. The need for I/O often surpasses the number of pads that can be provided at the perimeter of the FPGA chip. As a result, these designs have to be implemented in FPGAs the sizes of which are fixed by the number of I/O pads and not by the logic needed. This results in larger delays and more unused logic. Providing FPGA chips with I/O pads that are spread out across the whole chip area drastically reduces this problem. In this paper, an analytical model is derived to show the impact of area-I/O on FPGA delays. In contrast with the analysis in Ref. [1], we take the effect of the growing FPGA size\u2014due to the I/O limitations\u2014into account. Experimental data is provided to substantiate the theoretical claims.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This report describes the design of a modular, massive-parallel, neural-network (NN)-based vector quantizer for real-time video coding. The NN is a self-organizing map (SOM) that works only in the training phase for codebook generation, only at the recall phase for real-time image coding, or in both phases for adaptive applications. The neural net can be learned using batch or adaptive training and is controlled by an inside circuit, finite-state machine-based hard controller. The SOM is described in VHDL and implemented on electrically (FPGA) and mask (standard-cell) programmable devices.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Unmanned ground vehicles need accurate sensors to detect obstacles and map their surroundings. Laser-based distance sensors offers precise results, but 3D off-the-shelf sensors may be too expensive. This paper presents a 3D sensing system using a 2D laser sensor with a rotation system. Point cloud density analyses are presented in order to achieve the optimal rotation speed depending on the vehicle speed, distance to obstacles, etc. The proposed system is able to generate real-time point clouds, detect obstacles and produce maps, with high accuracy and a reasonable price (less than 5, 000 USD).",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Certification of avionics software is an increasingly important subject, since more and more avionics systems in future aircraft will be software equipped. The DO-17813 standard provides guidelines for software certification. Re-use of software is emerging, partly enabled by the integrated modular avionics concept, and imposed by a reduction of life-cycle costs. Re-use, however, requires re-certification or certification of software that was not developed according to DO-17813. The DO-178B standard is specially developed to provide a certification basis for avionics software, without going into details of the software development process. Other standards focus on software engineering aspects. We have used the DO-178B standard as a common basis for comparison with DOD-STD2167A (military), ESA PSS-05-0 (space), and IEC65A(Secretariat)122 (industry). Comparison topics include: &amp;#x02022; \u2022 life cycles; &amp;#x02022; \u2022 prescribed documentation; &amp;#x02022; \u2022 configuration management; &amp;#x02022; \u2022 verification and validation; &amp;#x02022; \u2022 quality assurance. All standards prescribe the software development process, emphasizing specific aspects in a certain area of interest. The results of our investigation will assist in understanding the rationale behind several standards, and can be used for: &amp;#x02022; \u2022 certification according to DO-17813 of software that was developed using another standard; &amp;#x02022; \u2022 certification of software using DO-17813, in concert with another standard.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The Motorola MC68020 is one of the first 32-bit microprocessors. The 68020 is part of the 68000 family, which has a register-based architecture. In the 68020 a number of instructions and addressing modes, and some data types, have been implemented, to increase input and to help in the implementation of modular high-level languages and their associated constructs and data structures. The 68020 is made with the HCMOS process.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Dynamic programming algorithms are widely used to find the optimal sequence alignment between any two DNA sequences. This manuscript presents a new, flexible and scalable hardware accelerator architecture to speedup the implementation of the frequently used Smith\u2013Waterman algorithm. When integrated with a general purpose processor, the developed accelerator significantly reduces the computation time and memory space requirements of alignment tasks. Such efficiency mainly comes from two innovative techniques that are proposed. First, the usage of the maximum score cell coordinates, gathered during the computation of the alignment scores in the matrix-fill phase, in order to significantly reduce the time and memory requirements of the traceback phase. Second, the exploitation of an additional level of parallelism in order to simultaneously align several query sequences with the same reference sequence, targeting the processing of short-read DNA sequences. The results obtained from the implementation of a complete alignment system based on the new accelerator architecture in a Virtex-4 FPGA showed that the proposed techniques are feasible and the developed accelerator is able to provide speedups as high as 16 for the considered test sequences. Moreover, it was also shown that the proposed approach allows the processing of larger DNA sequences in memory restricted environments.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We discuss VThreads, a novel VLIW CMP with hardware-assisted shared-memory Thread support. VThreads supports Instruction Level Parallelism via static multiple-issue and Thread Level Parallelism via hardware-assisted POSIX Threads along with extensive customization. It allows the instantiation of tightly-coupled streaming accelerators and supports up to 7-address Multiple-Input, Multiple-Output instruction extensions. VThreads is designed in technology-independent Register-Transfer-Level VHDL and prototyped on 40\u00a0 nm and 28\u00a0 nm Field-Programmable gate arrays. It was evaluated against a PThreads-based multiprocessor based on the Sparc-V8 ISA. On a 65\u00a0 nm ASIC implementation VThreads achieves up to x7.2 performance increase on synthetic benchmarks, x5 on a parallel Mandelbrot implementation, 66% better on a threaded JPEG implementation, 79% better on an edge-detection benchmark and \u223c13% improvement on DES compared to the Leon3MP CMP. In the range of 2 to 8 cores, VThreads demonstrates a post-route (statistical) power reduction between 65% and 57% at an area increase of 1.2%\u201310% for 1\u20138 cores, compared to a similarly-configured Leon3MP CMP. This combination of micro-architectural features, scalability, extensibility, hardware support for low-latency PThreads, power efficiency and area make the processor an attractive proposition for low-power, deeply-embedded applications requiring minimum OS support.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "High-level programming paradigms are examined to determine their appropriateness for describing systems, which are amenable to automated compilation onto a reconfigurable computing platform. We aim to find a set of language features to act as a basis for future language development which: provide a concise description of the system to be realised; provide clear and intuitive semantics; abstract the underlying technology and are appropriate to the underlying technology. Clearly language design is a subjective process, but we have adopted a systematic approach by assessing the efficacy of existing programming and hardware description languages. We examine the languages Java, VHDL, Standard ML and Circal. Our method also bases the comparison on a set of properties drawn from an archetypal example which we know maps well onto reconfigurable computing platforms. We conclude that none of these established languages has all the properties required for describing reconfigurable computation. This approach leads to insight into the capabilities of existing languages and allows us to determine the essential characteristics of future languages oriented to reconfigurable computing.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The genetic algorithm is a general purpose optimization metaheuristic for solving complex optimization problems. Because the algorithm usually requires a large number of iterations to evolve a population of solutions to good final solutions, it normally exhibits long execution times, especially if running on low-performance conventional processors. In this work, we present a scalable computing array to parallelize and accelerate the execution of cellular GAs (cGAs). This is a variant of genetic algorithms which can conveniently exploit the coarse-grain parallelism afforded by custom parallel processing. The proposed architecture targets Xilinx FPGAs and was implemented as an auxiliary processor of an embedded soft-core CPU (MicroBlaze). To facilitate the customization for different optimization problems, a high-level synthesis design flow is proposed where the problem-dependent operations are specified in C++ and synthesised to custom hardware, thus demanding of the programmer only minimal knowledge of low-level digital design for FPGAs. To demonstrate the efficiency of the array processor architecture and the effectiveness of the design methodology, the development of a hardware solver for the minimum energy broadcast problem in wireless ad hoc networks is employed as a use case. Implementation results for a Virtex-6 FPGA show significant speedups, especially when comparing to embedded processors used in current FPGA devices.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A SuperH\u2122 embedded processor core, SH-X2, implemented in a 90-nm CMOS process running at 800 MHz achieved 1440 Dhrystone MIPS, 5.6 GFLOPS, and 73M polygons/s. It has a dual-issue eight-stage pipeline architecture, but maintains the 1.8 MIPS/MHz of the previous seven-stage processor core SH-X. The processor meets the requirements of a wide range of applications, and is suitable for digital appliances aimed at the consumer market, such as cellular phones, digital still/video cameras, and car navigation systems. This paper focuses on the implementation of floating-point units in the SH-X2 and its resulting performance, and considers ways of enhancing this performance in future.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Programming multiprocessor systems is not a simple task and is often error-prone. In particular, programming a message-passing parallel computer usually demands large amounts of work in development and debugging to avoid deadlock. It is, therefore, essential to have software to support the task of parallel programming, or more desirably to have automatic parallel program generators to greatly reduce the labour. In this paper, we present a novel method of automatically generating Occam programs; or more precisely, we present an automatic FP-to-Occam translator called AFO. Occam is a parallel, message-passing programming language executed on a network of processors called transputers, but is basically a sequential language extended with primitive parallel and communication constructs. In contrast, FP is a functional language that contains no communication details and supports parallel thinking naturally with higher-level parallel constructs. FP has been used to derive many systolic algorithms. Systolic algorithms can be implemented in Occam as soft-systolic algorithms. With this knowledge, we developed AFO to automatically generate Occam programs from FP programs that have corresponding systolic algorithms, in the hope of generating parallel programs without needing to know the details of low-level communications, and thus greatly improving the productivity of parallel programming.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper details an implementation of a supervisor processor to monitor the performance of an adaptive signal processing system. The system is based on the use of the Inmos transputer. The supervisor is part of a threetransputer network which has been programmed as an adaptive smoothing filter. The system employs task-level parallelism with a transputer dedicated to parameter estimation, using the extended least squares algorithm, digital smoothing and system supervision. An example is considered of the adaptive smoother dealing with a random signal which is subject to various distortions. By performing a range of different checks on the adaptive signal processor the supervisor is able to ensure the stable operation of the smoother.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "As multi-core processors continue to scale, more and more multiple distributed applications with precedence-constrained tasks simultaneously and widely exist in multi-functional embedded systems. Scheduling multiple DAGs-based applications on heterogeneous multi-core processors faces conflicting high-performance and real-time requirements. This study presents a multiple DAGs-based applications scheduling optimization with respect to high performance and timing constraint. We first present the fairness and the whole priority scheduling algorithms from high performance and timing constraint perspectives, respectively. Thereafter, we mix these two algorithms to present the partial priority scheduling algorithm to meet the deadlines of more high-priority applications and reduce the overall makespan of the system. The partial priority scheduling is implemented by preferentially scheduling the partial tasks of high-priority applications, and then fairly scheduling their remaining tasks with all the tasks of low-priority applications. Both example and experimental evaluation demonstrate the significant optimization of the partial priority scheduling algorithm.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Most recent graphics workstations implement graphics accelerators based on dedicated VLSI chips. The paper proposes a modular architecture using transputers and flexible software routines. A set of transputers with a crossbar connection scheme prepares the drawing. Another set using video RAMs controls a high-resolution colour monitor, each transputer handling a strip on the screen and a colour. Performance using straightforward C routines is 900 trapezoids per second per transputer. The flexible architecture allows the number of transputers to be adapted to the performance required.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper analyses the impact of technology on the design and performance of small cache memories. Technology impacts are modelled through choice of optimal pipeline structures. Emphasis is placed on both silicon and gallium arsenide technologies and on variations thereof. Numerical results are presented for a number of relevant perfomance parameters, and for two representative benchmarks.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Despite the bandwidth limitations of a bus, a design is presented for a parallel computer (GRIP) based on Futurebus, which limits bus bandwidth requirements by using intelligent memories. Such a machine offers higher performance than a uniprocessor and lower cost than a more extensible multiprocessor, as well as serving as a vehicle for research into parallel architectures.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A PIC17C44 microcontroller development board and a real-time algorithm were developed with the capability of monitoring the fetal heart rate (FHR) as well as recording both the FHR and maternal heart rate for long-term. This paper describes the development of the microcontroller board and implementation of a real-time algorithm which were used to develop the portable recorder. Two set-up were developed. One setup was used to implement the algorithm in the PIC17C44 microcontroller board. Second set-up was developed for the assessment of the reliability of processed heart rates. A large number of clinical tests have shown the very good performance of the developed monitor in comparison with FHR curves simultaneously recorded with IFM-500 Doppler ultrasound fetal monitor. Statistical comparison was done and showed nonsignificant difference in mean ( p =0.05), correlation coefficient ( r =0.8\u20130.92) and low PRD (5\u201315).",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The Allied Standard Avionics Architecture Council (ASAAC) Phase II programme is sponsored by the Ministry of Defence of the UK, Germany and France through a Memorandum of Understanding (MOU), which provides for a two stage programme over five years to establish a complete set of standards for military core avionics for the end of this century. The standards will cover systems, software, networks, packaging and common functional modules, and will be validated by the construction of a set of demonstrators. The contract was let on 18th November 1997, and project teams were formed in the UK, France and Germany to perform the work. The current contract concerns Stage 1, i.e. the first 15 months of the ASAAC Phase II programme. Stage 1 is required to build on the results of the earlier ASAAC Phase I programme by firstly assessing and refining the architecture concepts and secondly by producing detailed specifications for Stage 2 demonstrations and outline standards for the architecture. The main objectives of this paper are, one year after the beginning of the ASAAC Phase II programme, to present as: \u2022 ASAAC Phase II programme objectives; \u2022 ASAAC Phase II contractual and industrial organisation; \u2022 Architecture concepts definition results of the Stage 1 work; \u2022 Demonstrations planned for Stage 2.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Geometric algorithms play an important role in computer graphics and digital image analysis. This paper makes an improvement of computing geometric properties of labelled images using arrays with reconfigurable optical buses (AROB). For an N \u00d7 N image, we first design two constant time algorithms for computing the leftmost one problem and for the component reallocation problem. Then, several geometric algorithms for the labelled images are derived. These include finding the border pixels, computing the perimeter and area, computing the convex hull, determining whether two figures are linearly separable, computing the smallest enclosing box, solving the nearest neighbor problems, and computing the width and diameter. The major contribution of this work is to design both time and cost optimal algorithms for these problems. To the best of our knowledge, the proposed algorithms are the first constant time algorithms for these problems on the labelled images.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The throughput of a string-matching engine can be multiplied up by inspecting multiple characters in parallel. However, the space that is required to implement a matching engine that can process multiple characters in every cycle grows dramatically with the number of characters to be processed in parallel. This paper presents a hybrid finite automaton (FA) that has deterministic and nondeterministic finite automaton (NFA and DFA) parts and is based on the Aho-Corasick algorithm, for inspecting multiple characters in parallel while maintaining favorable space utilization. In the presented approach, the number of multi-character transitions increases almost linearly with respect to the number of characters to be inspected in parallel. This paper also proposes a multi-stage architecture for implementing the hybrid FA. Since this multi-stage architecture has deterministic stages, configurable features can be introduced into it for processing various keyword sets by simply updating the configuration. The experimental results of the implementation of the multi-stage architecture on FPGAs for 8-character transitions reveal a 4.3 Gbps throughput with a 67 MHz clock, and the results obtained when the configurable architecture with two-stage pipelines was implemented in ASICs reveal a 7.9 Gbps throughput with a 123 MHz clock.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The on-line computation of special algorithms, such as those required for controlling multidetectors in heavy-ion nuclear physics experiments, is a fundamental problem. It requires real-time computational resources capable of satisfying the associated time constraints. The work presented describes general considerations on real-time architectures, and tests performed employing, as a benchmark, the computation of a power law, used for particle identification in nuclear physics experiments.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents an optimized fault diagnosing procedure applicable in Built-in Self-Test environments. Instead of the known approach based on a simple bisection of patterns in pseudorandom test sequences, we propose a novel bisection procedure where the diagnostic weight of test patterns is taken into account. Another novelty is the sequential nature of the procedure which allows pruning the search space. Opposite to the classical approach which targets all failing patterns, in the proposed method not all of such patterns are needed to be used for diagnosis. This allows to trade-off the speed of diagnosis with diagnostic resolution. To improve the diagnostic resolution multiple signature analyzers are used. A method is proposed to partition a single signature analyzer into a set of multiple independent analyzers, and the algorithms are given to synthesize an optimal interface between the outputs of the circuit under test and the analyzers. The proposed method is compared with three known fault diagnosis methods: classical Binary Search based on patterns bisection, Doubling and Jumping. Experimental results demonstrate the advantages of the proposed method compared to the previous ones.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The earth is bombarded by a nearly isotropic flux of energetic charged particles called cosmic rays which interact with air nuclei to generate a cascade of secondary particles building up to a maximum intensity at 60\u2008000 feet. At normal cruising altitudes, the radiation is still several hundred times the ground level intensity. These particles are sufficiently energetic and ionising that they can deposit enough charge in a small volume of semiconductor to change the state of a memory cell, while certain devices can be triggered into a state of high current drain, leading to burn-out and hardware failure. These deleterious interactions of individual particles are referred to as single event effects. The authors have flown Cosmic Radiation Effects detectors in a variety of spacecraft and aircraft and illustrative results will be presented together with a review of published instances of such phenomena in flight systems. In the future there is likely to be increased susceptibility due to growing reliance on high performance computers using smaller devices operated at lower voltages and flying at higher altitudes. The influence of cosmic rays will have to be properly considered in the assessment of reliability.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Matrix algorithms are an important part of many digital signal processing applications as they are core kernels that are usually required to be applied many times while computing different tasks. Hardware assisted implementations using FPGAs provide a good compromise between performance, cost and power consumption, specially when high level synthesis techniques are employed for deriving co-processors. In this paper a high level synthesis approach to generate embedded processor arrays for matrix algorithms based on the polytope model is presented. The proposed approach provides a solution for efficient data memory accesses and data transferring for feeding the processor array, as well as support for solving problems independently of their size and limited only by the FPGA available resources. The proposed approach has been validated by generating processor arrays for three different matrix algorithms used in digital signal processing applications; more precisely matrix\u2013matrix multiplication, Cholesky and LU decomposition algorithms. These algorithms were targeted for a Spartan-6 device and compared against their sequential implementations targeted for a MicroBlaze processor in order to provide a general view of the gain achieved by the processor arrays when the arrays and sequential processors are implemented in the same technology. Results show that the implemented arrays outperforms hardware and software implementations considering an embedded platforms scenario with a Spartan-6 device.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "With the aggressive scaling of the VLSI technology, Networks-on-Chip\u00a0(NoCs) are becoming more susceptible to faults. Therefore, designing reliable and efficient routing methods is of significant importance. Most of the existing fault-tolerant techniques rely on rerouting solutions which may degrade the network performance drastically not only by taking unnecessary longer paths, but also by creating hotspots around the faults. Moreover, such off-line techniques cannot adapt to the dynamic traffic distribution in the network. In this paper, a reconfigurable and deadlock-free routing method is proposed based on the Abacus Turn Model\u00a0(AbTM) to tolerate single and double switch or link failures. The required resources are kept to a minimum by avoiding to use virtual channels and routing tables. The proposed method is able to dynamically adjust the availability of the healthy paths according to the location of failures and congestion in the network to minimize rerouting. Moreover, it can grant a high degree of adaptiveness to the packets. This efficiency makes the proposed method a powerful asset for reliable routing in NoCs. The experimental results demonstrate that an 8\u202f\u00d7\u202f8 mesh network remains 100% reliable against single faults, and 99.8% and 99.94% reliable against double switch and link failures, respectively.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The second of a series of papers on modern high-level programming languages for microprocessors introduces PASCAL, which was the first language to implement strong data typing and support for structured programming. The major language constructs \u2014 program structures, control structures, simple and structured data types etc. \u2014 are discussed with respect to their support for good software engineering practice. The development of a program to simulate the behaviour of a simple computer is outlined as a programming example.",
            "prediction": "Most likely AI-generated",
            "source": "Human"
        },
        {
            "abs": "Multiple mobile robot systems working together to achieve a task have many advantages over single robot systems. However, the planning and execution of a task which is to be undertaken by multiple robots is extremely difficult. To date no tools exist which allow such systems to be engineered. One of the key questions that arises when developing such systems is: does communication between the robots aid the completion of the task, and if so what information should be communicated? This paper presents the results of an investigation undertaken to address the above question. The approach adopted is to utilize genetic programming (GP) with the aim of evolving a controller, and letting the evolution process determine what information should be communicated and how best to use this information. A number of experiments were performed with the aim of determining the communication requirements. The results of these experiments are presented in this paper. It is shown that the GP system evolved controllers whose performance benefitted as a result of the communication process.",
            "prediction": "Most likely AI-generated",
            "source": "Human"
        },
        {
            "abs": "An approach to the design of operating systems for multiple processor systems with shared memory is presented. It is based on the use of a commercial uniprocessor real-time kernel together with the development of a minimal global kernel, a minimal local and a remote I/O system. For a number of applications, this approach provides an optimal ratio between the cost of developing the operating system, on the one hand, and the real-time characteristics of the system, on the other hand. Predictability is supported by preallocation of low cost processors and memory, and by primitives that provide minimal queuing. A new implementation of interprocessor message passing, which provides satisfactory performance of the distributed operating system, is proposed. Also, an I/O system optimally structured for embedded real-time multiple processor systems with shared memory is suggested.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Sound field analysis is complicated and computationally intensive. In this paper, a two-dimensional sound field solver based on the Digital Huygens\u2019 Model (DHM) is designed and implemented by a Field Programmable Gate Array (FPGA). In this sound field solver, the original DHM and its boundary condition are extended to reduce operations and hardware resource consumption. The computation is completed locally, and external memory access is avoided. In a two-dimensional space with both length and width being 1.28 m, when boundaries are rigid walls, the FPGA-based analysis system enhances performance from 44 to 217 times, and from 37 to 179 times against the software simulations based on the original DHM and Standard Leapfrog Finite-difference Time-domain (SLF-FDTD), respectively. Compared with the General-purpose Graphic Processing Unit (GPGPU) Tesla C1060, it speeds up by 1223 times in computation and by 114 times in overall performance in the case of time steps being 20,000. When the node scales are different and the calculated time steps are 32,000, the FPGA-based sound field solver achieves about 1795 and 1190 times faster in computation, 218 and 179 times enhancement in final performance over the software simulations based on the original DHM and SLF-FDTD, respectively. Furthermore, the proposed system provides high data throughput, and is easily applied in real-time applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The security of cryptographic protocols depends on the security of key sequences consisting of random numbers. In this paper, we design a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), which consists of a hash based Deterministic Random Bit Generator (DRBG) and a Get Entropy module. SRAM Physical Unclonable Functions (PUFs) are regarded as entropy sources, providing entropy data with enough entropy for CSPRNG. The construction of Get Entropy module is proposed to verify the availability of SRAM PUFs and compress the entropy data into truly random seeds that are fed into DRBG. This CSPRNG can reseed itself dynamically and can monitor the entropy of entropy sources in real time. The system is implemented and tested on Altera DE2. The test results show that, the pseudo-random numbers generated by this system can pass all random tests of National Institute of Standards and Technology (NIST) SP800-22 Test Suite and the throughput is up to 598.1\u202fMbps. Through the security discussion, this CSPRNG is theoretically confirmed that it can be securely applied to cryptographic protocols.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The number of small embedded devices is constantly growing and it is expected that there will be 50 billion of Internet connected devices in the 2020. One of the open challenges is the way of powering these devices. At the beginning they were battery powered, but now the energy is usually harvested from the environment and then accumulated. At the same time various adaptation methods have been introduced to manage the power consumption and adaptation appropriately to the energy remaining in the batteries in order to extend battery lifetime. We think that in the future, the next generation of embedded devices will take advantage of the Internet connectivity and accessibility to the weather forecasting models in order to enhance adaptability methods by analyzing the forthcoming harvested power levels. Unfortunately, these devices will use low power and lossy network protocols which may influence the quality of adaptation. In the paper, we propose the concept of the two-stage predictive power adaptation method for embedded devices that uses the weather forecast services and is designed to handle unavailability of network connection.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "With the rapid development of semiconductor IC technology, particularly in the field of very large scale integration (VLSI), high-speed monolithic parallel multipliers are functional blocks that may one day find wide acceptance. The authors describe the implementation of an iterative division algorithm using a 16-bit monolithic multiplier. The basis of the division algorithm is the Newton-Raphson iterative method, which is slightly modified here in order to adapt to the multiplier performance characteristics and to further simplify the hardware complexity. The article also shows that by applying a suitably chosen initial iterate, the desired result is obtained in a single iteration.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "With each passing day, Internet of Things (IoT), has the potential to transform our society to a more digital way. In this paper, a cryptographic system is proposed, which has been designed and implemented, following the IoT optimized technologies. As the benefits of IoT are numerous, the need for a privacy platform is more than necessary to be developed. This work aims to demonstrate this by, firstly, implementing efficient and flexible, the fundamentals primitives of cryptography and privacy. Secondly, this is achieved, by introducing applied cryptography, in a more interactive and flexible approach. The proposed system and the incorporation of this platform is scrutinized. In the context of this work, an application of symmetric cryptography is introduced, based on the Advanced Encryption Standard (AES) in Electronic Code Book (ECB), Cipher Block Chaining (CBC) and Counter (CTR) modes of operation, for both encryption and decryption of texts, images and electronic data applications. In addition two other security schemes are supported by the proposed system: AES Galois/Counter Mode (GCM) and AES Galois Message Authentication Code (GMAC). The GCM proposed integration, in an authentication scheme, designed to provide authenticity and confidentiality, at the same time. On the other hand, GMAC, can be applied as message authentication code. Both operations, are optimized in sense of implementation resources, since the major cost is targeted to AES core. In addition, based on the integrated hardware modules, user registration and validation is proposed and implemented, with no additional cost, and with no performance penalty. Furthermore, two factor authentication has been designed and proposed, based on One Time Passwords (OTP), which can been produced with a random procedure. After these, a reference to the security levels, as regards to the communication between the IoT layers of the architecture, is presented. IoT hardware platforms are facing lack of security level and this brings the opportunity to use advanced security mechanisms. Implementation comparison results emphasize the importance of testing and measuring the performance of the alternative encryption algorithms, supported by hardware platforms.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Excessive test power utilization is one of the major obstacles which the chip industry is facing at present. In SOC plan, test data volume is reduced extensively by using Test data compression strategies. In this paper, a variable-to-variable length compression method in light of encoding with perfect examples is presented. Initially, the don't care bits in the test vector are loaded with a proposed X -filling algorithm which is then encoded using the proposed Modified Equal Run Length Coding (MERLC) based encoding scheme. In relationship with the proposed X-filling and encoding scheme, an efficient decoder is designed and implemented with low area overhead. To assess the effectiveness of the proposed approach, it is tested on the ISCAS89 benchmark circuits. The tests results demonstrate that the proposed algorithm gets a higher compression ratio, when compared with the existing schemes. The Percentage compression of this scheme is 4.28%, 8.72%, 2.19%, 14.42% and 1.15% higher than those of ERLC, FDR, EFDR, Golomb and 9C coding respectively.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper describes the architecture and hardware generation concept of a parameterized MAC unit for use in a scalable embedded DSP core. The MAC unit supports a broad set of instructions for integer and fractional datatypes. Its generation is controlled by architectural as well as implementation and placement parameters. Including structured physical placement in the generation process ensures fast and predictable performance estimation. Especially for modern technologies, where wire effects dominate the achievable performance of a circuit, tight control of cell placement makes a predictable quantitative analysis and optimization possible. In the context of early-stage design space exploration, which is used to determine an optimal DSP core architecture, the presented methodology allows a fast and consistent estimation of the MAC unit\u2019s performance characteristics for various \u201cwhat if\u201d scenarios. Also implementation bottlenecks can be identified in an early project phase. In the context of the subsequent implementation phase, it enables local, detailed, and predictable quantitative design optimizations.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Multithreading is a well known technique to hide latency in a non-blocking cache architecture. By switching execution from one thread to another, the CPU can perform useful work, while waiting for pending requests to be processed by the main memory. In this paper we examine the effects of varying the associativity and block size on cache performance in a reduced locality of reference environment, due to multithreading. We find that for associativity equal to the number of threads, the cache produces very low miss rate even for small sizes. Also by taking into account the increase in cycle time due to larger cache size or associativity we find that the optimum cache configuration for best processor performance is 16Kbytes direct mapped. Finally, with a constant main memory bandwidth, increasing the block size to more than 32 bytes, reduces the miss rate, but degrades processor performance.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Military system design poses few problems that cannot also be found in the civil field. Perhaps the only distinctly military problem is the need for many systems to adjust the trade-off between safety and performance according to circumstances. The paper (which represents the personal opinions of the author, and should not be taken as a statement of MoD policy) considers what the objective of a safe design actually is, and what technical and administrative steps need to be taken if the objective is to be met.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This article describes the implementation of a two-dimensional heat transfer simulation system using a Splash-2 configurable computing machine (CCM). This application was implemented as a proof-of-concept system illustrating the computational benefits of CCMs in simulating physical systems. Configurable computing machines are an emerging class of computing platform characterized by providing the computational performance of application-specific processors, yet retaining the flexibility and rapid reconfigurability attributed to general-purpose processors over a diversity of tasks. In addition, this paper discusses the process of discretizing the physical domain of such systems, along with the techniques used for mathematical simulation, to illustrate the development process for a CCM application. Also presented are the fundamental properties of CCMS and why they are well suited for the application class presented. A description of the approach and implementation is included, along with an analysis of the performance on the target system.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "An interconnection network with n nodes is four-pancyclic if it contains a cycle of length l for each integer l with 4\u2264 l \u2264 n . An interconnection network is fault-tolerant four-pancyclic if the surviving network is four-pancyclic in the presence of faults. The fault-tolerant four-pancyclicity of interconnection networks is a desired property because many classical parallel algorithms can be mapped onto such networks in a communication-efficient fashion, even in the presence of failing nodes or edges. Due to some attractive properties as compared with its hypercube counterpart of the same size, the M\u00f6bius cube has been proposed as a promising candidate for interconnection topology. Hsieh and Chen [S.Y. Hsieh, C.H. Chen, Pancyclicity on M\u00f6bius cubes with maximal edge faults, Parallel Computing, 30(3) (2004) 407\u2013421.] showed that an n -dimensional M\u00f6bius cube is four-pancyclic in the presence of up to n \u22122 faulty edges. In this paper, we show that an n -dimensional M\u00f6bius cube is four-pancyclic in the presence of up to n -2 faulty nodes. The obtained result is optimal in that, if n \u22121 nodes are removed, the surviving network may not be four-pancyclic.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "With the rapid growth of deep learning and neural network algorithms, various fields such as communication, Industrial automation, computer vision system and medical applications have seen the drastic improvements in recent years. However, deep learning and neural network models are increasing day by day, while model parameters are used for representing the models. Although the existing models use efficient GPU for accommodating these models, their implementation in the dedicated embedded devices needs more optimization which remains a real challenge for researchers. Thus paper, carries an investigation of deep learning frameworks, more particularly as review of adders implemented in the deep learning framework. A new pipelined hybrid merged adders (PHMAC) optimized for FPGA architecture which has more efficient in terms of area and power is presented. The proposed adders represent the integration of the principle of carry select and carry look ahead principle of adders in which LUT is re-used for the different inputs which consume less power and provide effective area utilization. The proposed adders were investigated on different FPGA architectures in which the power and area were analyzed. Comparison of the proposed adders with the other adders such as carry select adders (CSA), carry look ahead adder (CLA), Carry skip adders and Koggle Stone adders has been made and results have proved to be highly vital into a 50% reduction in the area, power and 45% when compared with above mentioned traditional adders.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A System-on-a-Chip (SoC) is the most successful example of how the evolution of the chip integration technology allows the manufacture of complex embedded systems. However, the bulk of the design effort, to efficiently combine the HW and SW components in a SoC, still resides in the HW/SW interfacing architecture. A good HW/SW integration strategy has a positive impact either in performance, efficiency, development times, productivity or reutilization of platforms for future designs. In this paper, we present an object-oriented approach to cope with the HW/SW integration problem in SoCs. The Object-Oriented Communication Engine (OOCE) is a system-level middleware particularly designed for SoCs which provides a high-level and homogeneous view of the system components based on the Distributed Object paradigm. Communication between components is abstracted by means of a HW implementation of the Remote Method Invocation semantics and all the SW and HW adapters are automatically generated from functional descriptions of the components interface. The resulting communication infrastructure simplifies the integration effort required and makes the embedded software more resilient to changes in the HW platform. To prove the viability and efficiency of our proposal a prototype implementation on the Xilinx ML505 evaluation platform has been performed.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a System on Programmable Chip (SoPC) design of a digitizer to determine particle features in nuclear physics covering arrival time and energy also for pileup events. The preamplified pulses from the radiation detector are digitized with a rate of 125\u00a0Ms/s. Pulse triggering and arrival time is measured by analysis of the pulse output after CR-RC filtering. Trapezoidal pulse shaping is applied for pulse-height energy measure and noise suppression. A new method is presented for trapezoidal flat top height analysis to ease calibration of the trapezoidal pulse shaping filter. The presented method also improves pulse analysis in terms of pileup identification and false pulse rejection. Experimental results obtain a repetitive pulse rate of 50\u202fkHz. The digitizer is able to detect pileup events with a delay between pulses down to few micro seconds.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The automotive industry has not been excepted from the rapid development of microcomputer applications. Since the advent of the trip computer some four or five years ago, the functional possibilities for automotive instruments have mushroomed. To clocks and trip computers have been added printers, security systems, cruise controls, environmental controls, vehicle condition monitoring and multiple displays for dashboards. The dashboard itself will host more functions than could once be imagined without filling the dash with gauges, and many that were once inconceivable such as speech synthesis. As well as increasing the information content of automotive instruments, it is believed at Smiths Industries these advances will provide new sales features which could prove to be invaluable in the marketplace.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Task assignment is one of the core steps to effectively exploit the capabilities of distributed or parallel computing systems. The task assignment problem is an NP-complete problem. In this paper, we present a new task assignment algorithm that is based on the principles of particle swarm optimization (PSO). PSO follows a collaborative population-based search, which models over the social behavior of bird flocking and fish schooling. PSO system combines local search methods (through self experience) with global search methods (through neighboring experience), attempting to balance exploration and exploitation. We discuss the adaptation and implementation of the PSO search strategy to the task assignment problem. The effectiveness of the proposed PSO-based algorithm is demonstrated by comparing it with the genetic algorithm, which is well-known population-based probabilistic heuristic, on randomly generated task interaction graphs. Simulation results indicate that PSO-based algorithm is a viable approach for the task assignment problem.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We define a model checking technique that applies to a finite state representation of sequential programs. This representation is built by means of an abstraction method which cuts the state explosion by introducing a special symbol, \u22a5, to model \u2018unknown\u2019 variable values. Program properties are expressed by means of a temporal logic, which allow a further abstraction on the basis of the structure of the formulae. The satisfaction of the formulae is checked through a sort of symbolic execution of the programs which may produce a number of false results depending on the number of \u22a5 values associated to the variables. Each abstraction produces a different level of incompleteness of the verification result.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A major obstacle in designing superscalar processors is the size and port requirement of the register file. Multiple register files of a scalar processor can be used in a superscalar processor if results are renamed when they are written to the register file. Consequently, a scalable register file architecture can be implemented without performance degradation. Another benefit is that the cycle time of the register file is significantly shortened, potentially producing an increase in the speed of the processor.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "As we enter the deep submicron era, the number of transistors integrated on die is exponentially increased. While the additional transistors largely boost the processor performance, a repugnant side effect caused by the evolution is the ever-rising power consumption and chip temperature. It is widely acknowledged that the shortage of power supplied to a processor will be a major hazard to sustain the generational performance scaling, if the processor design is to follow the conventional approach. To utilize the on-chip resources in an efficient manner, computer architects need to consider new design paradigms that effectively leverage the advantages of modern semiconductor technology. In this paper, we address this issue by exploiting the device-heterogeneity and two-fold asymmetry in the processor manufacturing. We conduct a thorough investigation on these design patterns from different evaluation perspectives including performance, energy-efficiency, and cost-efficiency. Our observations can provide insightful guidance to the design of future processors.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Due to their unique path property, Banyan multistage interconnection networks (MINs) can be self-routed using control tags. This paper introduces a number of routing control classes of MINs and studies their structure. These include the D-controllable networks where the control tags are the destination labels, the FD-controllable networks where the control tags are functions of the destination labels, and the doubly D- or FD-controllable networks which are D- or FD-controllable forward and backward. The paper shows that all D- and FD-controllable networks have a recursive structure, and that all doubly D-controllable (resp., FD-controllable) networks are strictly (resp., widely) functionally equivalent to the baseline network. The subclass of MINs where the interconnections are operations on bits or digits is also studied and shown to be doubly FD-controllable and hence equivalent to the baseline. Finally, the paper presents an efficient, parallel algorithm that relabels the terminals of the baseline to simulate any network in that subclass.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Use of the architectural features of transputers to provide realtime matching of speech recognition is considered. The dynamic time warping algorithm has been implemented in occam and tested initially for matching a single word against a single template. The implementation has been extended to the multitemplate case and preliminary results for this are given. Logical extension to a multitransputer system is also discussed. The single-transputer implementation has been undertaken using a T414 transputer resident in an IBM XT personal computer on an Inmos B004 evaluation board with 2 Mbyte of RAM.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents an optimal method for topology synthesis by taking into account factors related to power, performance, and contention in an application-specific Network-on-Chip (NoC) architecture. A Tabu search based approach is used for topology generation with an automated design technique, incorporating floorplan information to attain accurate values for power consumption of the routers and physical links. The Tabu search method incorporates multiple objectives and is able to generate optimal NoC topologies which account for both power and performance. The contention analysis technique assesses performance and relieves any potential bottlenecks using virtual channel insertion after considering its effect on power consumption and performance improvement within the NoC. The contention analyzer uses a Layered Queuing Network approach to model the rendezvous interactions among system components. Several experiments are conducted using various SoC benchmark applications to compare the power and performance outcomes of the proposed technique.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a microprocessor-based FPGA system for lossy image compression. The system implements a widely known wavelet-based compression method, i.e. the Set Partitioning In Hierarchical Trees algorithm (SPIHT). The computationally intensive 2D wavelet-transform is performed by means of custom circuits, whereas an embedded microprocessor is used to execute a purpose-build SPIHT encoding process. The aim of this work is to demonstrate and verify the feasibility of a compact and programmable image compression sub-system that uses just one low-cost FPGA device. The entire system consumes just 1637 slices of an XC2V chip, it runs at 100 MHz clock frequency and reaches a speed performance suitable for several real-time applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Concurrent and distributed processing systems based on multiple microprocessors are both feasible and desirable. Processes residing on different processors execute in parallel while processes allocated on the same processor execute in a multiprogramming environment. These processes normally have to communicate and synchronize in order to achieve a common goal. Communication and synchronization are usually achieved by calling primitives supplied by a kernel. The paper describes a model of implementation for message-passing primitives which must be added to a single-processor kernel for communication and synchronization purposes in multimicroprocessor systems.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Single-hop non-blocking networks have the advantage of providing uniform latency and throughput, which is important for cache-coherent network-on-chip systems. This paper focuses on high performance circuit designs of multi-stage non-blocking networks as alternatives to crossbars. Existing work shows that Benes networks have much lower transistor count and smaller circuit area but longer delay than crossbars. To reduce the timing delay, we propose to design the Clos network built with larger size switches. Using less than half number of stages than the Benes network, the Clos network with 4 \u00d7 4 switches can significantly reduce the timing delay. The circuit designs of both Benes and Clos networks in different sizes are conducted considering two types of implementation of the configurable switch: with N-type metal-oxide-semiconductor logic (NMOS) transistors only and full transmission gates (TGs). The layout and simulation results under 45 nm technology show that the TG-based implementation demonstrates much better signal integrity than its counterpart. Clos networks achieve average 60% lower timing delay than Benes networks with even smaller area and power consumption.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "MSDOS machines have always been the favourite host platforms for transputer networks. Unfortunately, it is hard for MSDOS-hosted transputers to be easily integrated within a network environment, due to the lack of native support for networking on the host. The availability, nowadays, of cheap hardware for Ethernet access has made it possible to use MSDOS machines as general purpose interfaces between TCP-IP networks and peripheral devices (modems, printers etc.). In this paper we show how to use the same approach to interface transputer networks to the Internet, with some advantages over solutions using dedicated hardware, or Unix workstations, as host machines. The result of our work is PCserver, public domain software that allows a single MSDOS machine to host several independent transputer networks which can be completely controlled from other machines on the Internet. Performance issues related to the implementation of PCserver and in general to the network interfacing of transputers are also discussed in some detail.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Refresh power of dynamic random-access memory (DRAM) has become a critical problem due to the large memory capacity of servers and mobile devices. It is imperative to reduce refresh rate in order to reduce refresh power consumption. However, current methods of refresh rate improvement have limitations such as large area/performance overhead, low system availability, and lack of support at the memory controller. We propose a novel scheme which comprises three essential functions: (1) an adaptive refresh method that adjusts refresh period on each DRAM chip, (2) a runtime method of retention-time profiling that operates inside DRAM chips during idle time thereby improving availability, and (3) a dual-row activation method which improves weak cell retention time at a very small area cost. The proposed scheme allows each DRAM chip to refresh with its own refresh period without requiring the external support. Experiments based on real DRAM chip measurements show that the proposed methods can increase refresh period by 4.5 times at 58\u00a0\u00b0C by adjusting refresh period in a temperature-aware manner while incurring only a small overhead of 1.05% and 0.02% in DRAM chip area and power consumption, respectively. Below 58\u00a0\u00b0C, our method improves the refresh period by 12.5% compared with two state-of-the-art methods, AVATAR and in-DRAM ECC. In various memory configurations with SPEC benchmarks, our method outperforms the existing ones in terms of energy-delay product by 19.7% compared with the baseline, and by 15.4% and 12.4%, with respect to AVATAR and in-DRAM ECC, respectively.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The paper describes how some commercial VLSI microprocessors have been designed: first the Motorola MC68000, then the MC68010 and 68020, and finally the IBM Micro/370. Design and verification methods are described and the software tools used are noted. The evolution of chips, methods and tools is described and some future trends are projected. At present, logic design for standard microprocessors is performed manually then verified on a computer. In the author's opinion this level of automation will not increase in the forseeable future, although the design tools will run faster due to advancing computer technology.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Recent years have seen an increasing number of scientists employing data parallel computing frameworks, such as Hadoop, in order to run data-intensive applications. Research on data-grouping-aware data placement for Hadoop has become increasingly popular. However, we observe that many data-grouping-aware data placement schemes are static, without taking MapReduce job execution frequency into consideration. Such data placements scheme will lead to severe performance degradation that is way below the potential efficiency of optimal data distribution when executing MapReduce jobs that are executed frequency. In this paper, we propose a new data-grouping-aware dynamic (DGAD) data placement method based on the job execution frequency. Firstly, we build a job access correlation relation model among the data blocks according to the relationships provided by the records about historical data block access. Then we use a clustering algorithm to divide data blocks into clusters according to the job access correlation relation model among the data blocks and propose a data placement algorithm based on data block clusters in order to put correlated data blocks within a cluster on the different nodes. Finally, a series of experiments are carried out in order to verify the method proposed in this paper. Experimental results show that the proposed method can effectively deal with the mass data and can obviously improve the execution efficiency of MapReduce.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Many cryptographic primitives that are used in cryptographic schemes and security protocols such as SET, PKI, IPSec and VPN's utilize hash functions - a special family of cryptographic algorithms. Hardware implementations of cryptographic hash functions provide high performance and increased security. However, potential faults during their normal operation cause significant problems in the authentication procedure. Hence, the on-time detection of errors is of great importance, especially when they are used in security-critical applications, such as military or space. In this paper, two Totally Self-Checking (TSC) designs are introduced for the two most-widely used hash functions: SHA-1 and SHA-256. To the best of authors\u2019 knowledge, there is no previously published work presenting TSC hashing cores. The achieved fault coverage is 100% in the case of odd erroneous bits. The same coverage is achieved for even erroneous bits, if they are appropriately spread. Additionally, experimental results in terms of frequency, area, throughput, and power consumption are provided. Compared to the corresponding Duplicated with Checking (DWC) architectures, the proposed TSC-based designs are more efficient in terms of area, throughput/area, and power consumption. Specifically, the introduced TSC SHA-1 and SHA-256 cores are more efficient by 16.1% and 20.8% in terms of area and by 17.7% and 23.3% in terms of throughput/area, respectively. Also, compared to the corresponding DWC architectures, the proposed TSC-based designs are on average almost 20% more efficient in terms of power consumption.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Voting algorithms are used to arbitrate between variant results in a wide range of highly dependable real-time control applications. These applications include N-Modular Redundant hardware systems and diversely designed software systems based on N-Version Programming. The most sophisticated and complex voting algorithms can even tolerate malicious (or Byzantine) variant errors. Voting algorithms can be implemented in either hardware or software depending on the characteristics of the application and the type of voter selected. The behaviour of voting algorithms in multiple error scenarios is considered in this article. Complete disagreement is defined as those cases where no two variant results are the same. A novel algorithm for real-time control applications, the smoothing voter, is introduced and its behaviour compared with three previously published voters. Software implemented error-injection tests, reported here, show that the smoothing voter achieves a compromise between the result selection capabilities of the median voter and the safety features of the majority voter. The smoothing voter is an appropriate voter for applications in which maximising the number of correct outputs and minimising the number of benign errors of the system is the main concern, and a slight degradation in safety can be tolerated.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this article we introduce the use of field programmable gate array (FPGA) into the central processing unit (CPU) as part of an arithmetic-logic unit (ALU). As the concept of an in-system configurable FPGA inside the CPU is becoming more and more popular, it is now used mainly for the purpose of testing and evaluating. We suggest that the use of FPGA as an extension to the ALU with its functions that are implemented in the logic circuit (which we call logic-ware) can greatly increase the performance of the CPU.",
            "prediction": "Most likely AI-generated",
            "source": "Human"
        },
        {
            "abs": "The recent spectacular progress in the microelectronic, information, communication, material and sensor technologies created a big stimulus towards development of smart communicating cyber-physical systems (CPS) and Internet of Things (IoT). CPS and IoT are undergoing an explosive growth to a large degree related to advanced mobile systems like smart automotive and avionic systems, mobile robots and wearable devices. The huge and rapidly developing markets of sophisticated mobile cyber-physical systems represent great opportunities, but these opportunities come with a price of unusual system complexity, as well as, stringent and difficult to satisfy requirements of many modern applications. Specifically, smart cars and various wearable systems to a growing degree involve big instant data from multiple complex sensors or other systems, and are required to provide continuous autonomous service in a long time. In consequence, they demand a guaranteed (ultra-)high performance and/or (ultra-)low energy consumption, while requiring a high reliability, safety and security. To adequately address these demands, sophisticated embedded computing and embedded design technologies are needed. After an introduction to modern mobile systems, this paper discusses the huge heterogeneous area of these systems, and considers serious issues and challenges in their design. Subsequently, it discusses the embedded computing and design technologies needed to adequately address the issues and overcome the challenges in order to satisfy the stringent requirements of the modern mobile systems.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The HypErspectraL Imaging Cancer Detection (HELICoiD) European project aims at developing a methodology for tumor tissue classification through hyperspectral imaging (HSI) techniques. This paper describes the development of a parallel implementation of the Support Vector Machines (SVMs) algorithm employed for the classification of hyperspectral (HS) images of in vivo human brain tissue. SVM has demonstrated high accuracy in the supervised classification of biological tissues, and especially in the classification of human brain tumor. In this work, both the training and the classification stages of the SVMs were accelerated using Graphics Processing Units (GPUs). The acceleration of the training stage allows incorporating new samples during the surgical procedures to create new mathematical models of the classifier. Results show that the developed system is capable to perform efficient training and real-time compliant classification.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Imprecising the arithmetic hardware blocks is well known as one of the brilliant approaches that increase the performance of digital signal processors (DSP) at the cost of imposing some acceptable errors. Making a trade-off between the performance and the enormous results of a given system is a challenge which has attracted the interest of many researchers in recent years. In this paper, we focus on the design of an imprecise 4:2 compressor which lies at the heart of inexact multipliers. The proposed imprecise 4:2 compressor by utilizing only one majority gate brings significant efficiency in implementation of today's technologies like FinFET and future majority based emerging technologies such as QCA. The evaluation results in both of aforesaid technologies demonstrate the remarkable improvement of the proposed design compared to related works. In addition, employing the proposed imprecise 4:2 compressor in an image processing application confirms the qualitative acceptability of the proposed design.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In order to solve poor fine searching capacity of artificial fish swarm algorithm and artificial bee colony swarm algorithm in late state to result in insufficient local optimization, hybrid swarm intelligent parallel algorithm research based on multi-core clusters is proposed; Then, reverse learning mechanism is introduced in early stage of algorithm, initialized swarms are evenly distributed, and swarms are randomly divided into two groups to make interactive learning strategy accelerates rate of convergence, and basic artificial fish swarm algorithm and artificial bee colony swarm algorithm are used to make global searching. In late stage of algorithm, niches artificial fish swarm algorithm and Random Perturbation Artificial Bee Colony are used to make local fine searching to the solution obtained in early stage; On this basis, MPI+OpenMP+STM parallel programming model based on multi-core clusters is established for parallel design and analysis. Finally, stimulation experiment indicates optimizing efficiency of this algorithm is higher than single artificial fish swarm algorithm and artificial bee colony swarm algorithm.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this paper, we discuss a parallel processor design using eight DSP microprocessors (TMS320C25) and dual-port RAMs for image processing applications. The application of image processing algorithms on this architecture, hardware details, performance analysis, simulation of image processing algorithms and comparison with architectures reported in the literature are also discussed.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "To conserve space and power as well as to harness high performance in embedded systems, high utilization of the hardware is required. This can be facilitated through dynamic adaptation of the silicon resources in reconfigurable systems in order to realize various customized kernels as execution proceeds. Fortunately, the encountered reconfiguration overheads can be estimated. Therefore, if the scheduling of time-consuming kernels considers also the reconfiguration overheads, an overall performance gain can be obtained. We present our policy, experiments, and performance results of customizing and reconfiguring Field-Programmable Gate Arrays (FPGAs) for embedded kernels. Experiments involving EEMBC (EDN Embedded Microprocessor Benchmarking Consortium) and MiBench embedded benchmark kernels show high performance using our main policy, when considering reconfiguration overheads. Our policy reduces the required reconfigurations by more than 50% as compared to brute-force solutions, and performs within 25% of the ideal execution time while conserving 60% of the FPGA resources. Alternative strategies to reduce the reconfiguration overhead are also presented and evaluated.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The task of an Internet router is to scan the IP headers for the destination address and make a routing decision based on the information. If the processing capability of a router is enhanced to support computation on a datagram, some of the host computation may be delegated to the intermediate routers. The instructions about how to do the processing may be provided by the end hosts. We propose a reliable transport layer protocol, Intermediate Processing Protocol (IPP) for processing within the Internet. The protocol design makes provisions for connection set up handshake, router reservation, intermediate processing, data acknowledgement, buffering and retransmission, flow and congestion control, ordered delivery and security issues.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "It has been more than a decade since general porous applications targeted GPUs to benefit from the enormous processing power they offer. However, not all applications gain speedup running on GPUs. If an application does not have enough parallel computation to hide memory latency, running it on a GPU will degrade the performance compared to what it could achieve on a CPU. On the other hand, the efficiency that an application with high level of parallelism can achieve running on a GPU depends on how well the application\u2019s memory and computational demands are balanced with a GPU\u2019s resources. In this work we tackle the problem of finding a GPU configuration that performs well on a set of GPGPU applications. To achieve this, we propose two models as follows. First, we study the design space of 20 GPGPU applications and show that the relationship between the architectural parameters of the GPU and the power and performance of the application it runs can be learned by a Neural Network (NN). We propose application-specific NN-based predictors that train with 5% of the design space and predict the power and performance of the remaining 95% configurations (blind set). Although the models make accurate predictions, there exist few configurations that their power and performance are mispredicted. We propose a filtering heuristic that captures most of the predictions with large errors by marking only 5% of the configurations in the blind set as outliers. Using the models and the filtering heuristic, one will have the power and performance values for all configurations in the design space of an application. Searching the design space for a set of configurations that meet certain restrictions on the power and performance can be a tedious task as some applications have large design spaces. In the Second model, we propose to employ the Pareto Front multiobjective optimization technique to obtain a subset of the design space that run the application optimally in terms of power and performance. We show that the optimum configurations predicted by our model is very close to the actual optimum configurations. While this method gives the optimum configurations for each application, having a set of GPGPU applications, one may look for a configuration that performs well over all the applications. Therefore, we propose a method to find such a configuration with respect to different performance objectives.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Commercial multimedia computing applications have recently become a driving force in the development of simple, robust methods to provide real-time transfer of video and audio data while minimising the impact to concurrent data processing tasks. The emergence of these technologies offers an opportunity to reduce the cost of fourth-generation avionics by applying commercial techniques to these systems as well. Evolving standards and technology trends and their application to military avionics are described.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The performance of software executed on a microprocessor is adversely affected by the basic fetch\u2013execute cycle. A further performance penalty results from the load\u2013execute\u2013store paradigm associated with the use of local variables in most high-level languages. Implementing the software algorithm directly in hardware such as on an FPGA can alleviate these performance penalties. Such implementations are normally developed in a hardware description language such as VHDL or Verilog. More recently, several methods for using C as a hardware description language and for compiling C programs to hardware have been researched. Several software-programming languages compile to an intermediate representation (IR) that is stack based such as Java to Java bytecodes. Forth is a programming language that minimizes the use of local variables by exchanging the load\u2013execute\u2013store paradigm for stack manipulation instructions. This paper introduces a new systems architecture for FPGAs, called flowpaths, which can implement Java bytecodes or software programs written in Forth directly in an FPGA without the need for a microprocessor core. In the flowpath implementation of Forth programs all stack manipulation instructions are represented as simple wire connections that take zero time to execute. In the flowpath implementation of Java bytecodes the normal load\u2013execute\u2013store paradigm is represented as a single sequential operation and stack-manipulation operations become combinational thus executing faster. This paper compares the use of flowpaths in an FPGA generated from Java bytecodes and a high-level Forth program for the Sieve of Eratosthenes with C, Java, and Forth executed on microprocessors and microprocessor cores on FPGAs. The results show that flowpaths perform within a factor of two of a minimal hand-crafted direct hardware implementation of the Sieve and orders of magnitude better than compiling the program to a microprocessor.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Commercial workloads, such as transaction processing, stress the memory hierarchies of current computers. TPC-B is a transaction processing benchmark that generates significant operating system and database activity, and a TPC-B instruction trace is analyzed for the Motorola 88110 microprocessor. Instruction set usage reveals one branch in every four to five instructions, and instruction cache performance indicates that this branching behavior causes a large number of words to be brought in by cache refills but never used. Code reorganization optimizations to reduce unused words and avoid cache misses are simulated and found to reduce misses in the on-chip instruction cache by almost one fifth.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Aiming at the requirement of random cross business generated by mass data cryptosystems in security field, in this paper, a pipeline data processing architecture which includes four stages (i.e., dispatch, pretreatment, operation and synchronous reorganization) is proposed to accelerate data stream processing. In our work, attribute such as business id and algorithm identification of job package is used to distinguish different business requests. Hierarchical processing based on data identification is used to implement the mapping between job packages and algorithm IP cores. KSM memory access control logic is used to access association job package\u2019s intermediate state data. And the synchronization module is used to track the operation state to implement the synchronization between the input and output data. These ensure the correctness of cross access on parallel or serial mode. This architecture realizes the high concurrent processing of multiple algorithms and multiple IP cores on one single chip, and solves the problem of random cross encryption and decryption of multiple cryptographic algorithms, multiple keys, multiple IP cores and multiple data streams in many-to-many communication. The prototype system, developed on the XC7K325t FPGA, demonstrates the correctness of cryptographic processing during multi-threads cross data access. Experiments show the system throughput in our approach is higher than existing schemes.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Debugging of distributed software is approached in this paper by defining specific classes of program events to be monitored by the user while execution is in progress. An elementary event is defined in terms of a range condition and an access mode for a memory location. The concept of a compound event is introduced, expressed in terms of either an accumulated event, a sequential event conjunction, a logical event disjunction or an instantaneous event conjunction. On the occurrence of an event, the actions connected with that event will be performed. Possible actions are trace and break traps, event counting and measurement of time intervals. A specific debugger designed for a realtime multimicroprocessor system and based on the event-action model is presented.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Corner-case analysis is a well-known technique to cope with occasional deviations occurring during the manufacturing process of semiconductors. However, the increasing amount of process variation in nanometer technologies has made it inevitable to move toward statistical analysis methods, instead of deterministic worst-case-based techniques, at all design levels. We show that by statically considering statistical effects of random and systematic process variation on performance and power consumption of a Multiprocessor System-on-Chip (MPSoC), significant power improvement can be achieved by static software-level optimizations such as task and communication scheduling. Moreover, we analyze and show how the changes in the amount of process variability as well as values of other system constraints affect the achieved power improvement in such system-level optimizations. We employ a mixed-level model of MPSoC critical components so as to obtain the statistical distribution of frequency and power consumption of MPSoCs in presence of both within-die and die-to-die process variations. Using this model, we show that our proposed statistical task scheduling algorithm can achieve substantial power reduction under different values of system constraints. Furthermore, the effectiveness of our proposed statistical task scheduling approach will even increase with the increasing amount of process variation expected to occur in future technologies.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The implementation of the forward kinematics algorithm to position control robot manipulators is discussed. The objective is to control the manipulator in real time by dividing the task between a network of transputers. The underlying strategy is the fine-grain distribution of tasks as opposed to allocating one processor per joint. The network topology used is taken through diagnostic tests for analysis leading to performance maximization.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A microprocessor-based data acquisition system with a high-speed A/D and D/A interface is described. The system is connected to an HP9000 computer using the IEEE 488 general-purpose interface bus (GPIB), but is treated as a separate working system. Assembly-language programs have been written to communicate with the standard IEEE 488 commands sent by the HP9000. All the commands sent by the HP9000 are written in basic , allowing powerful data handling. The rate of data transmission to the HP9000 is about 33k samples s\u22121.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper introduces a multi-layer MIMD system for computer vision applications. The system is provided with three hierarchical processing layers, each of which is dedicated to one level of processing to create a pipelining effect. Unlike the traditional approach, where a 2D mesh connected array is used, layers in this system are linear arrays. Simplicity and expandability are the main advantages. A prototype of the system is implemented using off-the-shelf components and the performance of the various vision operations is analyzed.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A dual robot manufacturing cell which performs the stripping operation in garment manufacture is described. The mechanical structure of the robots, together with short programming cycle times mean that traditional robot programming techniques are not applicable. The paper describes the novel mechanical design and details the associated computer control system. Executing on standard computer and microprocessor hardware components, details of the software system which automatically generates robot motion programs from Computer Aided Design data are presented.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper proposes an efficient and high performance rectification architecture to be used as a preprocessing module in a complete stereo vision system before the matching correspondence calculus. A complete rectification process is implemented in order to remove the radial and tangential distortion effects due to lenses and to align the left and right raw images acquired by a stereo camera for the epipolar constraining. Thus, the epipolar lines are made collinear with each other and with the image scanning lines in order to reduce the complexity of the matching problem to a one-dimension correspondence search. The image transformation operations required by the rectification process are computed as matrix calculus through a pipelined and efficient hardware design. Unlike the memory mapped rectification function implementations, the proposed solution does not require any external memory block for the storage of pre-computed rectification maps. Moreover, conforming to the camera model adopted by the Stereo MATLAB Calibration Toolbox which is renowned as the most widely used software toolset for estimating the calibration parameters of a stereo camera, the proposed rectification architecture is a ready-to-use hardware solution to be used in stereo vision real-time embedded systems after calibrating the employed stereo camera following the MATLAB Calibration Toolbox procedure. When implemented in a Xilinx XC4VLX60-12ff1148 FPGA chip, the proposed circuit rectifies 640 \u00d7 480 and 1280 \u00d7 720 stereo images at a frame rate of 367 fps and 120 fps, respectively. The proposed fully pipelined solution uses an efficient raw image buffer system which is opportunely sized in order to store the minimum number of image rows able to guarantee the synchronization between the image buffering and the rectification elaboration without any interruption of the pipelined processing flow. When the proposed rectification system was used for processing the stereo images acquired by the Point Grey Research Bumblebee BB2-03S2 stereo camera, just 32 BRAM blocks were necessary to implement the raw image buffer; thus, after a latency of 136 us (15,387 clock cycles), a continuous flow of left and right rectified image pixels is guaranteed in output, for each inputted left and right couple of raw image pixels, at each clock cycle. When compared to the other implementations present in literature, the proposed solution offers the advantage of not using any external memory with respect to the memory-mapped rectification solutions while offering a more efficient and complete solution reaching the highest speed performance with respect to the on-the-fly computed rectification implementations present in literature.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Elliptic Curve Cryptography (ECC) is a multilayer system with increased hardware implementation complexity. A wide range of parameters and design choices affect the overall implementation of ECC systems. A variety of hardware implementations of ECC system that vary in parameters are proposed in the literature. Implementation target, underlying finite fields, coordinate system and modular arithmetic algorithms are key design elements that impact the overall implementation outcome. In this paper, we survey the various implementation approaches with the aim of providing a useful reference for hardware designers for building efficient ECC processors. Our literature review consists of four components. First, we list the design options and discuss their impact on ECC implementation. Second, we summarize different approaches and algorithms used in the literature for implementing modular arithmetic operations. Third, we review best practices in the literature for data paths and overall architectures. Fourth, we review the existing parallelism and performance enhancement techniques. In addition, this paper provides comparison of the different binary extension, prime and dual 8 hardware implementations of ECC.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "For 8-bit microprocessors, there is no immediate software solution to the problem raised by block-structured procedures, ROM implanted and called from a program located in a memory area. What happens with the debugging and evaluation of application software intended for a single-board system is that the modules have to be tested one by one through the target system before they are gradually implemented into ROM. The use of an incircuit emulator prevents this difficulty from occurring but, as most of the time only one emulator is available for a few teams, its use seems to be restricted to integration into the hardware. This paper describes a software interface which allows the ROM-implemented code and the RAM-implemented code to communicate. It is thus possible to allocate the code obtained using a high-level language at two noncontiguous locations, the first in ROM for the procedures already checked and the second in RAM for the procedures to be debugged. The use of a monitor allows the debugging of the critical parts and the evaluation of all the software before burning it permanently into ROM.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A synchronous mode as well as a scan mode of operation are added to a large class of asynchronous circuits, in compliance with LSSD design rules. This enables the application of mainstream tools for design-for-testability and test-pattern generation to asynchronous circuits. The approach is based on a systematic transformation of all single-output sequential gates into synchronous and scannable versions. By exploiting dynamic circuit operation in scan mode, the overhead of this transformation in terms of both circuit cost and circuit delay is kept minimal.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A large multi-ported rename register file (RRF) is indispensable for simultaneous multithreaded (SMT) processors to hold more intermediate results of in-flight instructions from multiple threads running simultaneously. However, enlarging the RRF incurs longer access delays and more power consumption, both of which are critical to the overall performance and are becoming a bottleneck due to the ever-increasing pipeline depth and issue width in future SMT processors. We propose a novel register renaming scheme called Multi-usable Rename Register with 2-Level renaming and allocating ( 2L-MuRR ), which focuses on more efficient utilization of a fewer number of rename registers. Based on the fact that the effective bit-width of most operands is narrower than the full-bit width of a register entry, 2L-MuRR partitions each rename register into several fields of different widths. Either a single field or a field combination can hold an operand, thus making each rename register multi-usable. In addition, 2L-MuRR postpones the register allocation to the write-back stage, which is similar to the formerly proposed virtual\u2013physical-register (VPR) scheme, further reducing the meaningless RRF occupancy. The simulations show that 2L-MuRR improves the efficiency of the RRF significantly, achieving higher performance with much fewer rename registers. For example, when the RRF size is 60, 2L-MuRR outperforms Trad (traditional register renaming approach) and VPR in terms of IPC by 38% and 11%, respectively, while decreases the RRF occupancy by 37% and 15%, respectively.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Traditionally, FPGA designers make use of CAD tools for evaluating architectures in terms of the area, delay and power. Recently, analytical methods have been proposed to optimize the architectures faster and easier. A complete analytical power, area and delay model have received little attention to date. In addition, previous works use analytical methods to optimize general-purpose FPGA architectures. Using analytical models for optimizing application-specific FPGA architectures are interesting subjects in the reconfigurable computing field. In this way, designers can investigate the optimized architecture for a set of application circuits and the consumers can find their best architecture among a variety of devices which is optimal for their specific work. In this paper, we complete an analytical FPGA performance model by presenting an analytical model to estimate the dynamic and leakage power and by integrating it into the geometric programming framework. This way, we are able to rapidly analyze various FPGA architectures and select the best one in terms of power consumption as well as area and delay. In the next step, we extend the model for optimizing FPGA architectures for a set of applications. A case of the best architecture for two specific circuits has been investigated in this paper.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "It is common practice that, during the development of a system, the hardware and software subsystems are designed independently and subsequently integrated during the testing phase of the design cycle. Lately, there has been an increasing interest in the design and implementation of embedded systems where the two subsystems are developed concurrently in order to meet performance and cost constraints - a process known as \u2018hardware/software codesign\u2019. In our approach to codesign, we are concerned with accelerating the performance of time critical regions of programs which are executed on a conventional microcontroller. A critical region is implemented not in software but in a programmable hardware device to improve performance. This paper presents a general overview of our development environment for the cosynthesis and performance evaluation of general-purpose hardware/software systems. In particular, we highlight the design of the hardware architecture which supports software acceleration.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Pneumatic drives are the most widely used form of industrial actuation system. However, research in relevant areas is very limited, often carried out, if at all, in isolated environments. There is a lack of strategic thinking and tools, which can enable developments to go forward in an efficient manner. In recognising the advancements in PC-technology, fieldbus systems, microprocessors and computing technologies, the authors advocate the concept of smart components-based servo pneumatic actuation systems. The paper expands on the components-based nature of pneumatic drive systems to identify design templates for smart valves, smart sensors, smart actuators, etc. The development of components-based pneumatic drive systems is considered in the context of a recently completed UK EPSRC funded research project on high speed servo-pneumatic actuation, addressing issues such as simulation tools, algorithm development, sizing, tuning, installation and commissioning. A high speed pneumatically-driven gantry pick-and-place handling system with novel design features is presented to demonstrate the capability and attributes of pneumatic drives for more sophisticated applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Parametric loudspeaker system enables sound to be projected and directed to a specific listening area just like a beam of light. The advancement of Field Programmable Gate Array (FPGA) technology opens up a very interesting option for rapid implementation and easy configurable signal processing platform for parametric loudspeaker system. In this paper, the digital signal processing subsystem of the parametric loudspeaker system has been designed and implemented in FPGA platform using the Altera 1S10 device.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Manufacturers of peripherals are inconsistent in their use of male or female connectors on their equipment. Combined with the increasingly common practice of producing data terminal equipment that in some respects is like data communication equipment (to cut the costs of extra null modem cables), this means that it can be very difficult to make two devices communicate over an RS232C serial link. The paper addresses the problems of incompatible male-female D-type connectors and reversed transmit-receive lines for three-wire communication. These ideas could be expanded for the problems associated with incompatible handshake lines.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In the Advent of the Internet of Things (IoT), embedded architecture takes an important dimension in terms of energy and accomplishment. The embedded system needs more and more intelligent algorithms for better performance and energy efficiency to fit into an IoT scenario. Moreover, with the existence of high-performance multi-core embedded architectures, achievements of energy efficiency remains in the dark side of the research. Several algorithms such as dynamic frequency scaling, thread mapping, starvation methodologies were proposed in embedded architectures for efficient usages of clock frequencies and these features were used as the energy saving modes in which the consumption of energy in the embedded architectures are being controlled. But these methods have several backlogs which permits the use of consumption in the embedded architectures. Considering the above features, this paper proposes a new methodology PODS(Predictors for Optimized Dynamic Scaling) which integrates a powerful machine learning algorithm for scaling the clock frequencies by the input workloads and allocation of the core depending based on the workload. The proposed framework PODS has different phases of working namely workload extraction, characterization, and optimization using BAT algorithms and prediction extreme Machine - Learning. The algorithm was tested on ARM/Cortex architectures (Raspberry Pi 3 Model B+), an evaluated algorithm using the IoMT benchmarks and various parameters that include energy consumption, accuracy of detection/prediction was determined and analyzed. It is found that the implementation of the proposed framework in the test is seen resulting between 35 and 40% reduction in the consumption of the power.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper describes the development of a prototype speech-controlled cloud-based wheelchair platform. The control of the platform is implemented using a low-cost WebKit Speech API in the cloud. The description of the cloud-based wheelchair control system is provided. In addition to the voice control, a GUI is implemented, which works in a web browser as well as on mobile devices providing live video streaming. Development was done in two phases: first, a small, initial prototype was developed and, second, a full size prototype was build. The accuracy of the speech recognition system was estimated as ranging from approximately 60% to up to 97%, dependent on the speaker. The speech-controlled system latency was measured as well as the latency when the control is provided via touch on a so-called smart device. Measured latencies ranged from 0.4 s to 1.3 s. The platform was also clinically tested, providing promising results of cloud-based speech recognition for further implementation. The developed platform is based on a Quad Core ARM Mini PC GK802 running Ubuntu Linux and an Arduino UNO Microcontroller. Software development was done in JavaScript/ECMA Script, applying node.js.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The advent of the Internet of Things has motivated the use of Field Programmable Gate Array \u00a0(FPGA) devices with Dynamic Partial Reconfiguration \u00a0(DPR) capabilities for dynamic non-invasive modifications to circuits implemented on the FPGA. In particular, the ability to perform DPR over the network is essential in the context of a growing number of Internet of Things \u00a0(IoT)-based and embedded security applications. However, the use of remote DPR brings with it a number of security threats that could lead to potentially catastrophic consequences in practical scenarios. In this paper, we demonstrate four examples where the remote DPR capability of the FPGA may be exploited by an adversary to launch Hardware Trojan Horse \u00a0(HTH) attacks on commonly used security applications. We substantiate the threat by demonstrating remotely-launched attacks on Xilinx FPGA-based hardware implementations of a cryptographic algorithm, a true random number generator, and two processor based security applications - namely, a software implementation of a cryptographic algorithm and a cash dispensing scheme. The attacks are launched by on-the-fly transfer of malicious FPGA configuration bitstreams over an Ethernet connection to perform DPR and leak sensitive information. Finally, we comment on plausible countermeasures to prevent such attacks.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a methodology for the system-level dependability analysis of multiprocessor embedded systems. The methodology is based on fault injection and features an error analysis approach offering to the designer the possibility to specify custom monitoring and classification actions at both application and architecture levels. In particular, a debug-like mechanism offers the possibility to interpret architectural raw data observed during the simulation at application level with a function call/return granularity, thus offering the possibility to analyze the propagation of the errors in the various functionalities of the executed application. A framework for automating the proposed methodology has been implemented within a state-of-the-art SystemC/TLM simulation platform for multiprocessor specifications provided with a fault injection engine. The effectiveness of the methodology has been demonstrated in two different case studies, showing how the proposed approach is able to produce an accurate dependability report highlighting the criticalities in both the architecture and the application of the system under design.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "MPSoC platforms offer solutions to deal with communication limitations for multiple cores on single chip, but many new issues arise within the context. The SegBus platform is one of the solutions for application deployment on multi-core applications. There are many applications where identical data is transferred from the same source towards different destinations. Multicast services may come as a performance improving factor for the interconnection platform, together with interrupt service. In this paper, the task is to analyze, how different services can be designed for the SegBus platform and observe the improvement in system performance. The designer can select the services according to the requirements. The running example is represented by the H.264 encoder. The SegBus platform architecture, the communication mechanism, the allocation of processing elements on the platform, the communication services and their implementation are the main topics elaborated here.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Nowadays, firmware in low-cost microcontrollers (MCUs) must implement cryptographic primitives in order to support practical applications. Effective protections of such implementations against side-channel attacks, especially the differential power analysis (DPA) attack, are still active topic in embedded device security. Low-cost MCUs lack many features, e.g. true random number generators typically used in modern DPA countermeasures. On the other hand, currently even the low-cost MCUs contain several dozens of kilobytes (kB) of program Flash memory not always completely used by a target firmware. In this paper we propose a new countermeasure against the DPA attack. We use randomly assigned general constant-weight codes ( m -of- n codes) for every intermediate value in a secure embedded device. In an ideal hardware, the equal Hamming weight of the data ensures balanced power consumption for any values in the device and thus it complicates the DPA attack. We demonstrate this method on a table based AES cipher and we propose several implementation enhancements to reduce the size of tables to 24 kB/12 kB that are more suitable for practical MCU implementations. We evaluate the performance of the proposed method in terms of speed, memory usage and we test possible side-channel leakages on a system implemented on ARM Cortex-M3 MCU.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a novel and optimized embedded architecture based FPGA for an efficient and fast computation of grey level co-occurrence matrices (GLCM) and Haralick textures features for use in high throughput image analysis applications where time performance is critical. The originality of this architecture allows for a scalable and a totally embedded on Chip FPGA for the processing of large images. The architecture was implemented on Xilinx Virtex-FPGAs without the use of external memory and/or host machine. The implementations demonstrate that our proposed architecture can deliver a high reduction of the memory and FPGA logic requirements when compared with the state of the art counterparts and it also achieves much improved processing times when compared against optimized software implementation running on a conventional general purpose processor.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The proliferation of embedded vision in today\u2019s life has necessitated the development of System-on-Chips to perform utmost processing in a single chip rather than discrete components. Embedded vision is bounded by stringent requirements, namely real-time performance, limited energy, and adaptivity to cope with the standards evolution. In this article, an energy-aware self-adaptive System-on-Chip for real-time corner detection is realized on Zynq All Programmable System-on-Chip using Dynamic Partial Reconfiguration. A careful analysis of algorithm and efficient utilization of Zynq resources results in highly parallelized and pipelined architecture outperforms the state-of-the-art. A context-aware configuration scheduler application is developed to adhere to operating context and trades off between video resolution and energy consumption to sustain the uttermost operation time for battery-powered devices while delivering real-time performance. The experiments show that the self-adaptive method achieves 1.77 times longer operation time than a parametrized IP core, with negligible reconfiguration energy overhead. A marginal effect of partial reconfiguration overhead on performance is observed, for instance, only two video frames are dropped for HD1080p60 during the reconfiguration time.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Partial Runtime Reconfigurable (PRTR) FPGAs allow HW tasks to be placed and removed dynamically at runtime. We make two contributions in this paper. First, we present an efficient algorithm for finding the complete set of Maximal Empty Rectangles on a 2D PRTR FPGA. We also present a HW implementation of the algorithm with negligible runtime overhead. Second, we present an efficient online deadline-constrained task placement algorithm for minimizing area fragmentation on the FPGA by using an area fragmentation metric that takes into account probability distribution of sizes of future task arrivals as well as the time axis. The techniques presented in this paper are useful in an operating system for runtime reconfigurable FPGAs to manage the HW resources on the FPGA when HW tasks that arrive and finish dynamically at runtime.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A novel median filter has been implemented by using a bit-level systolic array. The filter saves more than 23% of transistors when compared with conventional designs. The median filter may be clocked to a maximum 100 MHz for real-time applications. The bit-level systolic array is designed for unlimited word length and extension to larger window sizes.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The reducing of the width of quantum reversible circuits makes multiple-valued reversible logic a very promising research area. Ternary logic is one of the most popular types of multiple-valued reversible logic, along with the Subtractor, which is among the major components of the ALU of a classical computer and complex hardware. In this paper the authors will be presenting an improved design of a ternary reversible half subtractor circuit. The authors shall compare the improved design with the existing designs and shall highlight the improvements made after which the authors will propose a new ternary reversible full subtractor circuit. Ternary Shift gates and ternary Muthukrishnan\u2013Stroud gates were used to build such newly designed complex circuits and it is believed that the proposed designs can be used in ternary quantum computers. The minimization of the number of constant inputs and garbage outputs, hardware complexity, quantum cost and delay time is an important issue in reversible logic design. In this study a significant improvement as compared to the existing designs has been achieved in as such that with the reduction in the number of ternary shift and Muthukrishnan-Stroud gates used the authors have produced ternary subtractor circuits.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The design of a transputer link to an RS232 serial interface tram (transputer module) is presented. This enables a transputer to communicate with serial peripherals via a standard Inmos transputer link. The tram uses the Motorola MC68HC805C4 8-bit microcontroller to interface between the transputer link and the RS232 serial line. This solution allows a high level of programming flexibility and can be used in any transputer motherboard which has a spare size one slot. The results of performance measurements are also shown. These show how a shortcoming in the design was detected and rectified.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a microprocessor adapter for ATM networks. Its transmission functions, which are related to the upstream direction, include cell buffering, header error control, cell assembling, rate coupling, and information insertion. The reception functions, which are related to the downstream direction, include information extraction, rate decoupling, cell buffering, header error detection and correction, cell delineation, connection identity fields extraction and identification, cell disassembling and classification, and idle cell discarding. The transmission direction can be supported optionally by a traffic shaper, which is responsible for adapting emitted traffic to ATM network. The microprocessor adapter, which can be used in terminals or in interworking units and switches, implements basic functions of the lower layers of the ATM protocol reference model. It uses three applications specific integrated circuit (ASIC) chips. The three chip-set and other logic can been used to develop a personal computer (PC) adapter for ATM networks. This PC adapter offers bulk data transfer across the ATM network, internet applications over TCP/IP, interactive applications, LAN\u2013ATM interworking facilities using a PC as a router, multimedia and other services.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Functionality of electronic components in space is strongly influenced by the impact of radiation induced errors which may interfere with the proper operation of the equipment. In space missions, FPGA implementations are generally protected using computationally expensive radiation-error mitigation techniques such as error co rrecting codes (ECC) and triple modular redundancy (TMR). For high-performance systems, such fault tolerance techniques can prove problematic due to both the added computational requirements and their resulting power overhead. As such it is important to make a proper assessment of the expected error rates to make a proper selection of mitigation techniques. This paper provides an extensive overview of the techniques used for determining the necessity of such mitigation techniques in space missions and other situations where a large radiation dose will be encountered. Given the presented study and radiation analysis, in this paper an experimental example is presented in the form of a case study on the Digital Receiver System (DRS) in the Netherlands\u2013China Low-frequency Explorer (NCLE) mission, which is implemented using a Xilinx Kintex-7 SRAM FPGA. Fault rates are estimated for a five-year mission to the second Earth-Moon Lagrange point (L2) and the chosen fault mitigation strategy as implemented in NCLE\u2013DRS is presented. The effect of potential upsets on the functionality of DRS has been taken into account in order to make error estimations more precise. Thus, two test-benches are developed and presented to experimentally evaluate the effect of upsets in FPGA configuration memory and the data on the DRS final outputs. The approach provided in this paper should generalize well to other space missions, as long as a general estimate of the expected radiation environment is available.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents the considerations, design and implementation of a DSP-based acoustic feedback canceller system using the TMS320C25 chip. The system consists of a stand-alone unit containing the DSP hardware and built-in firmware in EPROM. The algorithm employs the use of a 256-point DIF FFT for time-to-frequency conversion; subsequently, a potential frequency is identified and a series of tests performed on it to distinguish it from speech. Once identified, a second-order IIR notch filter is invoked, cancelling the acoustic feedback (pure tone) signal, restoring normal operations to the PA system. The system \u2018tracks\u2019 any potential acoustic feedback signal, and a notch filter is invoked where necessary thus eliminating the need for manual equalization. The system's functionality has been proven, and represents an achievement in a DSP application to PA systems.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Superscalar and VLIW processors can both execute multiple instructions each cycle. Each employs a different instruction scheduling method to achieve multiple instruction execution. Superscalar processors schedule instructions dynamically, and VLIW processors execute statically scheduled instructions. This paper quantitatively compares various superscalar processor architectures with a very long instruction word (VLIW) architecture developed at the University of California, Irvine. An architectural overview and performance analysis of the superscalar processor models and VIPER, a VLIW processor designed to take advantage of the parallelizing capabilities of percolation scheduling, are presented. The motivation for this comparison is to study the capability of a dynamically scheduled processor to obtain the same performance achieved by a statically scheduled processor, and examine the hardware resources required by each.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this paper, a 6.7-kbps vector sum excited linear prediction (VSELP) coder with less computational complexity is presented. A very efficient VSELP codebook with nine basis vectors and a heuristic K -selection method (to reduce the search space and complexity) is constructed to obtain the stochastic codebook vector. The nine basis vectors are obtained by optimizing a set of randomly generated basis vectors. During the optimization process, we have trained the basis vectors to give the system apriori knowledge of the characteristics of the input. The coder is implemented on a TMS320C541 digital signal processor. The performance is evaluated by testing the 6.7-kbps VSELP coder with different test speech data taken from different speakers. The quality of the coder is estimated by comparing the performance of the 6.7-kbps VSELP coder with an 8-kbps VSELP speech coder based on the IS-54 standards.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "On-chip multiprocessor can be an alternative to the wide-issue superscalar processor approach which is currently the mainstream to exploit the increasing number of transistors on a silicon chip. Utilization of the cache, especially for the remote data is important in the system using such on-chip multiprocessors since the ratio of the off-chip and the on-chip memory access latencies is higher than traditional board-level implementation of the cache coherent non-uniform memory access (CC-NUMA) multiprocessors. We examine two options to utilize the cache resource of the on-chip multiprocessors whose size is restrained by the die area: (1) the instruction and/or private data are only cached at the L1 cache to leave more space on the L2 cache for the shared data; (2) divide cache area into the L2 and the remote victim caches or use all the area for the L2 cache. Results of execution-driven simulations show that the first option improved the performance up to 15%. For the second option, a remote victim cache with 1/8 of the L2 cache size improved three out of four benchmark programs by 4\u20138%. However, the combination of L2 and victim caches that divide the cache area into two halves of the same size was outperformed by the L2 cache occupying the entire cache area in three out of four benchmark programs.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The integration of Multi-Processors System-on-Chip (MPSoCs) into the Internet-of-Things (IoT) context brings new opportunities, but also represent risks. Tight real-time constraints and security requirements should be considered simultaneously when designing MPSoCs. Network-on-Chip (NoCs) are specially critical when meeting these two conflicting characteristics. For instance the NoC design has a huge influence in the security of the system. A vital threat to system security are so-called side-channel attacks based on the NoC communication observations. To this end, we propose a NoC security mechanism suitable for hard real-time systems, in which schedulability is a vital design requirement. We present three contributions. First, we show the impact of the NoC routing in the security of the system. Second, we propose a packet route randomisation mechanism to increase NoC resilience against side-channel attacks. Third, using an evolutionary optimisation approach, we effectively apply route randomisation while controlling its impact on hard real-time performance guarantees. Extensive experimental evidence based on analytical and simulation models supports our findings.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "PUFs (Physical Unclonable Function) are increasingly used in proposals of security architectures for device identification and cryptographic key generation. Many PUF designs for FPGAs proposed up to this day are based on ring oscillators (RO). The classical approach is to compare frequencies of ROs and produce a single output bit from each pair of ROs based on the result of comparison of their frequencies. This ROPUF design requires all ROs to be mutually symmetric and also the number of pairs of ROs is limited in order to preserve the independence of bits in the PUF response. This led us to design a new ROPUF on FPGA which is capable of generating multiple output bits from each pair of ROs and is also allowing to create higher number of pairs of ROs, thereby making the use of ROs more efficient than the classical approach. Our PUF design is based on selecting a particular part of a counter value and using it for the PUF output. By applying Gray code on the counter values, we have considerably improved the PUF\u2019s statistical properties. In principle, this PUF design does not need the ROs to be mutually symmetric, however, it is shown that this ROPUF design has significantly better properties with varying supply voltage when symmetric ROs are used. All of the presented measurements were performed on Digilent Basys 2 FPGA Boards (Xilinx Spartan3E-100 CP132). In this work, we provide a more detailed description of the PUF design on FPGA and the behaviour of ROs with varying supply voltage. Our proposed PUF architecture offers more output bits with required statistical properties from each RO pair than the classical approach, where frequencies of ROs are compared. The presented improvements significantly reduce the dependence on fluctuation of supply voltage.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Current avionics fiber-optic networks utilize light-emitting diode (LED)-based transmitter optical sources owing to their established high reliability over the commercial and military avionics temperature regimes. One shortcoming of LED-based transmitters is the limited modulation speed and low output power of the LED devices. Recently published high temperature reliability data on commercial-off-the-shelf (COTS) diode lasers appears promising for realizing higher speed (i.e. &gt;1 Gb/s) optical interconnects in avionics systems. Although ruggedized hermetic packaging has been developed for avionics optoelectronic modules, the application of newer generation commercial sector packaging to reduce optoelectronic module production costs is under examination. `Glob-top' sealed chip-on-board, passive alignment silicon micro-optical bench, and non-hennetic laser and detector packaging technologies offer potential cost-reductions in avionics optoelectronic modules. However, the reliability of these new laser sources and packaging options has yet to be thoroughly evaluated for the harsh commercial and military avionics environment.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Existing algorithms can be automatically translated from software to hardware using High-Level Synthesis (HLS), allowing for quick prototyping or deployment of embedded designs. High-level software is written with a single main memory in mind, whereas hardware designs can take advantage of many parallel memories. The translation and optimization of memory usage, and the generation of resulting architectures, is important for high-performance designs. Tools provide optimizations on memory structures targeting data reuse and partitioning, but generally these are applied separately for a given object in memory. Memory access that cannot be effectively optimized is serialized to the memory, hindering any further parallelization of the surrounding generated hardware. In this work, we present an automated optimization method for creating custom cache memory architectures for HLS generated designs. Our optimization uses runtime profiling data, and is performed at a localized scope. This method combines data reuse savings and memory partitioning to further increase the potential parallelism and alleviate the serialized memory access, increasing performance. Comparisons are made against architectures without this optimization, and against other HLS caching approaches. Results are presented showing this method requires 72% of the number of execution cycles compared to a single-cache design, and 31% compared to designs with no caches.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents a new fully reconfigurable 2D convolver designed for FPGA-based image and video processors. The proposed architecture operates on image pixels coded with different bit resolutions and varying kernel weights avoiding power and time-consuming reconfiguration. This is made possible by using new SIMD arithmetic modules purposely designed for the new circuit. When optimized for the XILINX VIRTEX device family, the convolver presented in this work requires just 18.4 ms to perform a 5\u00d75 convolution on a 1024\u00d71024 8-bit pixels image and dissipates only 102.1 mW/MHz. The new circuit can be exploited in all the real-time applications in which adaptive convolutions are required and it can be realized also in many other FPGA device families.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Implementing a function using a programmable logic array (PLA) can often be very expensive in terms of area. Folding rows and/or columns of a PLA usually leads to a reduction in area. In this paper the problem of fault detection in folded PLAs is considered. A new fault, the \u2018cutpoint\u2019 fault, is described and universal test sets for the detection of this fault are presented. Modifications to existing built-in universally testable design techniques for nonfolded PLAs are presented; the new designs are now applicable to folded PLAs.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "An 8088 development system is described which combines the advantages of a personal computer (IBM PC), with high-level language support in the form of a c compiler, and a rack-based system. A suite of programs has been developed to enable the c compiler output to be converted into a form suitable for execution on the rack-based target as either ROM- or RAM-resident applications.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper studies the performance of a DRAM component as a function of its structure and the locality of the memory stream. We present a method and a tool for retrieving scalar values for temporal and spatial locality and discuss caches as locality filters. Combinations of cache systems and DRAM configurations having varying number of banks are simulated, and the locality of the DRAM input memory stream is analyzed. The results show that there is a usable amount of locality in the post-cache memory stream, but it is poorly utilized by the current DRAM structures. The developed scalar metrics are found to be suitable for outlining and understanding the DRAM performance. Analyzing locality and considering possibilities to utilize it by DRAMs will become essential in the future, as the DRAM row access time becomes increasingly dominant.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "We present a self-reconfigurable embedded system for a switched beam smart antenna that can steer the beam pattern into a desired direction, handle arithmetic overflow, and respond to user-specified constraints on accuracy and resources. The main component (adaptive beamforming) is implemented as a fully customized hardware in fixed-point arithmetic. By varying the numerical formats and desired beam patterns, we generate a set of hardware configurations, which can then be selected at run-time via a dynamic manager implemented in software. The self-reconfigurable embedded system is implemented and tested on a Programmable System-on-Chip (PSoC). Results are presented in terms of resources, accuracy, and run-time hardware adaptation. This work illustrates the benefits of run-time reconfiguration technology on PSoCs for the implementation of switched-beam smart antennas.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Power management is an important part of handheld systems such as PDAs, smartphones, and other battery operated digital devices. A handheld system can transition the nodes of a DRAM to low power state to reduce energy consumption. We propose an efficient method for dynamic power management (DPM) of DRAM based on accessed physical addresses. The proposed method also reduces the number of times resynchronization is done. There is no need to collect scattered pages, as in conventional page clustering mechanisms that focus on virtual memory (VM). Simulation result shows that the proposed method reduces Energy \u2217 Delay Product by as much as 75% when compared to DRAMs with no DPM.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This Paper describes the Low Power Non linear Feedback Shift Register (NFSR) for Radio Frequency Identification (RFID) System. RFID systems are widely used in many places for product tracking, monitoring the objects and more. The RFID tag stores its distinctive Electronic Product Code (EPC) with related product information within the tag's memory and encrypts this information before its send to the reader . The RFID tags encrypt the data using Pseudo random numbers. Mostly Linear Feedback Shift Register (LFSR) are used to generating pseudo-random sequences which is less security. Nonlinear Feedback Shift Registers (NFSR) is getting to be more famous in recent years because of the insecurity of LFSR. The output sequence of the LFSR is a linear function of the previous stage, it is easily predictable by intruders. Because of this, NFSR is used in many security systems for generating Pseudo-random numbers. The output sequence of NFSR is irrelevant to the previous stage. In this paper, we proposed a new architecture for NFSR, in this model NFSR is controlled by an LFSR with irregular clocking to generate maximal length sequences. The proposed model is designed using 16\u00a0nm CMOS technology and operated in the sub-threshold region. The examination is done using Tanner EDA-Industry Standard design environment. The simulation results demonstrate that the irregular clocking architecture reduces the total power consumption by 30 percent.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper presents an overall view of the architecture and design of a programmable logic controller (PLC). The main objectives of the work are to design, develop, and implement a versatile PLC processor module (PLCPM) based on an industrial open bus architecture called VMEbus (IEEE 1014 Versa Module Euro-standard). The controller is inserted inside the VME crate and controls the industrial process via input and output modules that reside in the crate. The PLCPM is designed to be an intelligent module through the use of a Motorola MC68000 CPU. A method of distributed arbitration protocol, based on an algorithmic state-machine design approach, is added to the design of this module. This facility makes PLCPM suitable to work inside a VMEbus environment. The PLCPM therefore becomes adequate for use in multiprocessing PLC systems. The controller uses a host personal computer (IBM-PC) as a versatile and indispensable system component for process development, monitoring, control and supervision. Software and firmware programs are developed and written for both host-PC and PLCPM using standard C-language and 68000 assembly language, respectively. This results in a sequential control algorithm for the PLCPM and windowing user interface for the host-PC. Ladder diagram programming language is supported by this user interface.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The Wireless Sensor Network research field has been growing and becoming more mature during the last decade since novel technologies and research lines have emerged targeting its usability under different real scenarios. One of the key topics to assure the efficiency and effectiveness of these technologies in final applications is the quality of the service and the reliability of the whole system, which strongly depends on the communication/topology capabilities as well as routing strategies within the WSN. In this context, it is essential to evaluate the implementation of routing algorithms and network connectivity in actual deployments, as a support to theoretical simulation models that cannot predict certain constraints and limitations in the system behavior. These are the main reasons why a real implementation of a flexible AODV-based routing protocol using a modular HW-SW node platform is proposed in this work, in addition to its practical assessment under real conditions by using a novel in-situ WSN performance evaluation tool. This tool has been created as a support for users during the in-field deployment analysis and diagnosis in real environments, in order to correlate theoretical results with the operation of the network beyond the typical study of routing performance with WSN simulators.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Task assignment in a heterogeneous multiprocessor is a NP-hard problem, so approximate methods are used to solve the problem. In this paper the Modified Binary Particle Swarm Optimization (Modified BPSO) algorithm and Novel Binary Particle Swarm (Novel BPSO) Optimization are applied to solve the real-time task assignment in heterogeneous multiprocessor. The problem consists of a set of independent periodic task, which has to be assigned to a heterogeneous multiprocessor without exceeding the utilization bound. The objective is to schedule maximum number of tasks with minimum energy consumption. The execution times and deadlines of the tasks are assumed to be known. Here Modified BPSO performance is compared with Novel BPSO and Ant Colony Optimization algorithm (ACO). Experimental results show that Modified BPSO performs better than Novel BPSO and ACO for consistent utilization matrix and ACO performs better than Modified BPSO and Novel BPSO for inconsistent utilization matrix.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The 80386 is a high-performance third-generation microprocessor that is now standard in most top-of-the-range PCs. Like all similar processors operating at clock rates above 30 MHz, the 80386 must use cache memory if it is to operate efficiently. Without cache memory, the user must either pay a very high price for very fast RAM or employ slower memory by introducing wait states. This application note describes the 80386 bus interface and demonstrates how it can be interfaced to IDT cache tag RAMs to create a cache system. Although the report describes a relatively basic cache system, it covers all design considerations ranging from system timing to the programming of the PALs needed to implement the interface. A.C.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "NCR 52832 (Figure 1) and 52864 5-V-only E2PROMS can be used in applications where occasional insystem programmability and long-term data retention without power (non-volatility) are needed. Applications include the storage of programmable character fonts in intelligent terminals, storage of data or firmware in remote systems that need periodic updating, user-programmable video games, and RAM backup.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Tomorrow\u2019s Micro-Air-Vehicles (MAVs) could be used as scouts in many civil and military missions without any risk to human life. MAVs have to be equipped with sensors of several kinds for stabilization and guidance purposes. Many recent findings have shown, for example, that complex tasks such as 3-D navigation can be performed by insects using optic flow (OF) sensors although insects\u2019 eyes have a rather poor spatial resolution. At our Laboratory, we have been performing electrophysiological, micro-optical, neuroanatomical and behavioral studies for several decades on the housefly\u2019s visual system, with a view to understanding the neural principles underlying OF detection and establishing how OF sensors might contribute to performing basic navigational tasks. Based on these studies, we developed a functional model for an Elementary Motion Detector (EMD), which we first transcribed into electronic terms in 1986 and subsequently used onboard several terrestrial and aerial robots. Here we present a Field Programmable Gate Array (FPGA) implementation of an EMD array , which was designed for estimating the OF in various parts of the visual field of a MAV. FPGA technology is particularly suitable for applications of this kind, where a single Integrated Circuit (IC) can receive inputs from several photoreceptors of similar (or different) shapes and sizes located in various parts of the visual field. In addition, the remarkable characteristics of present-day FPGA applications (their high clock frequency, large number of system gates, embedded RAM blocks and Intellectual Property (IP) functions, small size, light weight, low cost, etc.) make for the flexible design of a multi-EMD visual system and its installation onboard MAVs with extremely low permissible avionic payloads.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper proposes a cost-effective solution to the virtual cache synonym problem. In the proposed solution, a minimal hardware addition guarantees correct handling of the synonym problem whereas a simple modification to the virtual-to-physical address mapping in the operating system optimizes the performance. The key to the proposed solution is a small, physically-indexed cache called a U-cache . The U-cache maintains the reverse translation information of cache blocks that belong to unaligned virtual pages, where unaligned means that the lower bits of the virtual page number that are used to index the virtual cache do not match those of the corresponding physical page number. The biggest advantage of the U-cache approach is that it leaves room for software optimization in the form of mapping alignment. Performance evaluation based on memory reference traces from a real system shows that the U-cache, with only a few entries, performs almost as well as (in some cases outperforms) a fully-configured hardware-based solution when more than 95% of mappings are aligned.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "This paper deals with the idea of implementing a complete network service on a chip. Herein, we propose an original design together with an efficient implementation of an authoritative domain name system (DNS) server on a Virtex 5 FPGA circuit. The proposed approach exploits the use of a hardware accelerator, MicroBlaze soft-processor cores and an adequate mapping between the DNS specifications and the hardware architecture leading to a Multi-Processor System on Chip (MPSoC). We propose new architectures by translating the DNS specifications to hardware form through the \u201cSpecification and Description Language\u201d (SDL) tool. The proposed implementation allows significant reduction in power consumption together with significant performance and security improvement. The proposed architectures have been successfully implemented and tested on an actual network. The obtained results show a query performance improvement of around 200% with respect to the \u201cBerkeley Internet Name Domain\u201d (BIND) 9 server.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Design and reuse has become a very common practice in the electronics design industry. IP cores are easily sold by designers to system integrators. However, several cases of counterfeiting and illegal copying have been reported and design protection techniques have been developed in response. Among these techniques, we focus on modifications at logic level aimed at active design protection. This is the first paper to provide a formal description and definition of the following techniques used to protect integrated circuits and IP cores against theft, counterfeiting, cloning and illegal copy: logic encryption, logic obfuscation, logic masking, and logic locking. In the second part of the paper, we present a new technique to insert gates in the data path of a logic circuit in order to lock it. Based on graph analysis, this method involves low overhead implementation and is more than ten thousand times faster than former fault analysis-based logic masking techniques when it comes to selecting the nodes to modify. Finally, we discuss the design requirements of a strong design protection scheme.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "An efficient VLSI architecture for minimized sorting network (Vasanth sorting) in rank ordering application to remove salt and pepper noise is proposed. The basic operation in salt and pepper noise removal is rank ordering. In this work, a novel 2D sorting technique referred to as Vasanth sorting is proposed for a fixed 3\u202f\u00d7\u202f3 window. Vasanth sorting requires only 25 comparators to sort 9 elements of the window. A parallel architecture is developed for Vasanth sorting with 25 comparators. The processing element of the parallel architecture is an 8-bit data comparator (Two cell comparator). The performance of the proposed sorting technique is compared with the different sorting technique which is targeted for XCV1000-5bg560 on XILINX 7.1i and xc7v2000t-2flg1925 Xilinx 14.7 project manager respectively with Modelsim 10.4a for simulation and XST compiler tool for synthesis using VHDL. It was found that the parallel architecture developed for Vasanth sorting requires the only \u00bc of the area in FPGA when compared to existing sorting techniques. The combinational delay of the proposed architecture was also twice as less like their counterparts. The power consumption of the logic was 7mw. Hence the above performances make Vasanth sorting a better choice compared to existing techniques for rank ordering.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "In this paper, we investigate the feasibility of a 2-Dimensional Optical Code Division Multiple Access (2D-OCDMA) system, with electronic coding and decoding functions. We develop a modified construction method of Multi-Wavelength Optical Orthogonal Codes (MWOOC) that permits high flexibility in the code parameters choice. The 2D code performance is calculated for a Conventional Correlation Receiver (CCR) and a more complex one, named Parallel Interference Cancellation (PIC) receiver. For example, for a Bit Error Rate (BER) \u2a7d10\u22129, and 30 simultaneous users, we show that contrary to the CCR, the use of a PIC receiver leads to workable 2D electric coding solutions.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "Personal computers are becoming almost as common as pocket calculators. In particular, their use in laboratories for measurement and control is growing. The next step after computer-controlled instruments is the development of a personal computer with an instrument as a component part. An automatic pH titrator has been designed. The system presented is based on an Apple Ile. Two plug-in cards are used. One card integrates analogue measurement and analogue-to-digital conversion. The other card controls a syringe driven by a stepper motor. The software control system for the personal pH meter is also described.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The promising advent of Fully Electric Vehicles (FEVs) also means a shift towards fully electrical control of the existing and new vehicle functions. In particular, critical X-by-wire functions require sophisticated redundancy solutions. As a result, the overall Electric/Electronic (E/E) architecture of a vehicle is becoming even more complex and costly. The SafeAdapt project provides an integrated approach for engineering such adaptive, complex and safe systems, ranging from tool chain support, reference architectures, system modeling and networking, up to early validation and verification. In this paper, we give an overview of the SafeAdapt project methodology. We also describe a particular aspect of the project which is the validation of the system adaptive behavior. To validate the adaptive behavior of a vehicle system, an architecture description language for automotive embedded systems (i.e. EAST-ADL) is used for designing the system. The system design model is then used for generating the embedded software. To ensure that the system behaves correctly at runtime, its adaptive behavior is analyzed using fault injection and monitoring techniques on a virtual platform.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "A personal computer based static fault detection system for digital integrated circuits (IC) is described. The system detects functional as well as logical faults and declares a \u2018go/no go\u2019 condition for ICs. The process of developing a database containing test vectors and control vectors for testing various ICs is illustrated by examples. The system interface hardware is simple to implement and its Microsoft C based software is flexible to accomodate expansion of the database for new ICs. The application of the testing scheme can be extended to test digital circuits constructed on printed circuit boards.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        },
        {
            "abs": "The VMS bus was conceived as a high-speed serial bus for passing short, urgent messages within a VME backplane. It has been extended to allow for communication between two or more VME backplanes or \u2018crates\u2019, but it can also be used to link computers with dissimilar buses. The paper compares VMS with other serial bus standards, and shows how transmission errors on the bus can be detected. A method for linking the STEbus to VME systems using the VMS bus is described; this method can be extended to link other buses such as the IBM PC bus.",
            "prediction": "Most likely human-generated",
            "source": "Human"
        }
    ],
    "ai_predictions": [
        {
            "abs": "The time scale of the ultra-short-term can strengthen, and diverse variations of the high-resolution radiation data are severe\u201a\u00c4\u00eeultra-short-term prediction model for high-resolution solar radiation data. Self-Organizing Map (SOM) is applied to realize the clustering and labels predictions topological structure data of the irradiation sequence. The deep learning algorithm establishes a label classification prediction model corresponding to the predicted it applies to [19].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The development of information technology has the transparency of the spirit in the free, Internet penetration and education to equality and the continuous updating of education Law and educational equipment. Business performance it to be a creative activity, to gather information for the dissemination of planning and information in the preoperative planning process, it can be used for parties. Rotation of these operations, which can be optimized by traditional productivity analysis and improvement techniques, is repeated. When using the technique, it is a technology that can perform various overall tasks recorded in the study, including the necessary foundation and reconstruction cycle, data visually controlled by two of the principle that relies on. Data limited viewer or camera, and analysis work starts the moment and stops prompt visual information decisions.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "There are many solutions to Regularization Approaches being an under determination problem. Unspeakable HR resource past knowledge to solve the SR problem. There are two different ways to implement detection and universal method relevance. The deterministic method usually introduces the term conversion check for the worst configuration problems. Various checks were used to resolve this misconfigured. The smoothness and regularity of the minimum-class validation method of constraints do not guarantee a unique solution. This is the estimated use of the least-squares approximation. A quick and assertive colleague describes leverage's diminution by respecting alternatives approaching powerful outsiders' accounts. Adaptive Estimate General SR is a family of mixtures proposed linear inverse estimates",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Mechanical and quick development in the advanced advancement of transport, giving adequate thought to the air quality observing; notwithstanding, customary air quality checking strategy, an adequate air quality data with adequate spatial and worldly goal wasteful is the rate through practical and process duration refining to produce. The undeniable method to actualize a checking the air quality is to utilize this mist registering based Internet (IoT) organization of things. By microchip-based IoT detecting, information assortment doesn't appear to prompt the way toward setting off to the cloud worker. Ideally, they are shipped off the fast securing administration through the fog of the neighboring hubs, including a high-rate administration [4].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "However, due to the various sentence structures that cannot be captured due to this method, the language does not achieve good results. This transition process is very time-consuming. It is essential for those who are proficient in both languages. Next, use a visual introduction to correct statistical machine translation errors and translation euro machine corpus-based translation methods, rule-based methods: translators, linguists and computer scientists around the world work on machine translation technology. Machine translation is a hot cake in today's fast-changing global agenda. However, these experts from different fields follow different methods and concepts to achieve the dream goal of machine translation, or Fully Automatic High-Quality General Purpose Machine Translation (FAHQGPMT).",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "As mentioned above, the system's psychological processing is primarily influenced by the brands' emotional experience and products that make a lasting impression on consumers in the past. Statistically, significant differences in the buying decision making consumer segment. Considering the number of customers who visit the dealer, the customer decides in advance that it is a search before going to the dealer every time. Before making a purchase decision, purchase behavior model. Rather than work hours outside the dealer. FPGA (Field Programmable Gate Array) based decision-making process; Visit the number of dealers in the model for all shopping customers. And with the purchase decision, purchase behavior customer satisfaction.(3)E\u201a\u00e0\u00f9j=\u201a\u00e0\u00f9E\u201a\u00e0\u00f9xj=\u0152\u00a5E\u0153\u00dcxj+dxjdnetj=EAjXj(1\u201a\u00e0\u00edXj)",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "According to the cutting edge versatile organization Alliance, to empower the general public. 5G, which is associated with the complete cell phones, in the environment of start to finish, through existing and rising, client and empowers the accomplices of significant worth creation. Use case, to manageable plan of action, it will be conveyed in a steady encounter. An open-source library and a programmable remote stage for remote open-access research stage reference plan that incorporates elite equipment along that side.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Table 2 shows that let us consider a large city, the information to be recorded cells, each unit, and the map area is gigabytes. There are many ways to spread the map, such as advance download maps from the server or other nodes in the streets. The theme is out of range.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "This snowy paper describes these two tasks. Check the number of turns and identifies four main swimming way: crawling, flat beach, and after swimming butterfly. Therefore, the use of knowledge has been established to gather information. In order to collect information under the wise, we work together with a group of individuals from around the world together with the nearby ace. To varying degrees, these swimmers swim and have different strategies. In any case, the conditions were a public swimming pool is the same as 10 swimmers always shared a lonely road. Apparently ready to allow swimmers to follow the standards, but the main difference is that they are wearing. The information collected for direct coarse sensor information processing, and creates a frame from start to finish may benefit from the large amount of information. For this reason, we trained Convolutional Neural Network (CNN), with woolen sensors, accelerometers, magnetometers, gauges, and four optical swim way to get from the rotation, accelerometers, magnetometers, gauges and integrated optical sensor a rough window sensor information, as the data source. Produce distribution possibilities. Progress classes. As an example of real progress brilliant NULL class, which integrates the turn and rest. By then, please use the expected number of changes suggestive turns to divide the whole meeting to swim properly. For example, such a division should follow the swim schedule determined in advance. Deep learning techniques typically require large amounts of information, in order to give an accurate expectations and in perfect order. To ensure that meet this requirement, we will be authorized to collect a large data set that contains the sensor information from 17 hours of the 40 swimmers were involved in four main swimming styles and variations. Clearly, this shows there is a better understanding of the main purposes of approval and lap swimming style inspection methods. A claim from the completion of the completion strategy is best implemented in the class implementation, specifically, swimmers achieve adequate execution can really receive it. Unfortunately, previous work has no direct examination of publicly accessible data set. Allow free access to code and data sets to facilitate research and promote future directly associated with the work.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20202 shows the model, buyers approach numerous business association sites that show explicit administrations. The buyer will give a gage of the sum he/she needs to spend on a specific help. For instance, look at the financing costs of individual advances/vehicle credits by different banks using the site. A business association that meets the necessities of shoppers inside the predefined financial plan approaches clients and offers assistance for them expanding the pattern of online clients purchasing on the web; the danger of extortion follows intently behind. Clients are as yet suspicious. Regarding purchasing items on the web, individuals have questions, particularly concerning the security of his financial balance subtleties and other individual information. The primary danger factors influencing online business are the protected utilization of MasterCard's on the Internet and the sheltered stockpiling and utilization of delicate information on the Internet to forestall data fraud (name, address, and so on), Secret phrase access among clients and web-based shopping, which is optionally ensured by programmers and phishing",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 3 capture the original Image when the image area is both the result of the Image and the super-resolution. Two real tests are a concern. Series images have a size of pixels a good comparison of the look of gifts like most works. This PSF and low hand distribution are thought to be an operation.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Near the dam's area, reconnaissance is to send live video to the base station, the dam is useful and use it to distinguish the existence of possible close individuals be guaranteed. The camera on the line at the same time it should be a possibility to help. The focus of Internet innovation of things on the network has been established in connection with the network to create a more and more sensor environment. Be collected in connection with this information in the bombing sensor is, let us improve the dam's unwavering quality for that, can create more robust hardware. Combining the internet with an enormous amount of information, distributed computing and wireless sensor networks upgrade the dam's ability to real information. The entire process, and extensive recovery and order delivery of information, will be completed cloud to ensure that it can be carried out quickly. Development of infrastructure and nerve tissue of the area one of the gifts of 5\u00ac\u2020G and AI",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In this experiment, a campus violence frame of 12448, including the skeleton of daily life activities of 9963, and the 2485 single still image, captured a total of 24,896 times of activity. After feature selection, which is used for the SVM classification 10 Function: the maximum width, the change of the full width, full height, maximum height variation of the top area, the difference in the head area, the maximum aspect ratio, circumscribed growth of the entire distance to the center of gravity of the rectangular frame, and, the detection target regions and countries of the sum.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A module is a pure function that can be considered using the domain defined by module input and program global parameters. A function parallel domain is more complex, as it has zero or more sequences [13], plus zero or addition behavior (target accumulator name and accumulated value). Function mapping from flow expressions GTC: both defined data, and flow intrinsically controlled by the statement.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Cooperative sifting innovation, in the network factorization strategy, it is the most famous. Like this, every client in the leading transporter is moved to possible transporters, the client of the task, and the undertaking's likely capacity and can speak to an expected capacity and ventures. Subsequently, the task's client association can be approximated by the internal result of inert vectors. A community-oriented separating technique as a shut model, such as consolidating the grid disintegration strategy for different endeavors to improve the overall model, is equivalent to falling the gadget. A network content theme model engineered lattice corruption and field coefficient.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Rural social security systems are not only an important tool for ensuring people's livelihoods and rural finance is not only an important part of building conditions. At this time, the focus of innovation in rural social security systems should be to increase the scope of rural social security systems and improve security. The government should increase financial investment and improve the quality of care to improve the rural pension insurance system and the system for relief of serious diseases in rural areas. It reduces funding moral hazard and improves the rural financial, ecological environment.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Examination results, and blend as is substance of the accompanying, uniform, educator after the perspective and the class of the term, need to assign the past instructive substance sanely. While in principle in this showing practice, educators, checking is important to adjust the proportion of denoting this segment Massive Open Online Courses (MOOC) the interest and last trial of the homeroom. Again, this investigation is legitimate. There, propose the assessment model info and assess understudies' exhibition regarding cycle and item [5].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Is there a time-series detection interaction or the observed nonlinearity It is currently applied to various predictions of linear and nonlinear time series models wind data. But the first question to answer before the building is whether the information needs to be studied or the type of needs that carry the first question's needs. If there is no white noise difference, it is a waste of pertaining-data model relationships. There is no need for an advanced nonlinear estimation model if there is no data and a nonlinear structure. andthe nonlinear source wind speed time series and white noise exist. The differential wind speed time series is used to test the data method used in this method.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "New computer vision and depth of learning techniques have been applied to sports video intelligence analysis. Deep learning Fine-Grained Action Recognition (FGAR) methods have been proposed to analyze the football training video. The technique used in indoor training equipment to assess the players is expected, stop the football\u201a\u00c4\u00eefirst, the FGAR problem for human modeling the interaction of objects (a player's ball). Object-level tracks have been proposed to identify fine-grained sports video new descriptors [18].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Alleviation - F is an improvement channel type calculation from the help. It requires thought of not just one of the multi-class arrangement that K late examples and backing. Support - F gives the loads that have alternate importance dependent on their capacity and classification. The connection is tween's practical, and the Toppan calculation class depends on recognizing tests close in highlights. Weight will be erased highlights than the less specific edge\u201a\u00c4\u00eethis article further decreases applicable excess. Our past work utilized the plan of better alleviation - F.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Be that as it may, it can prompt a ton of examination on the expectation of scholarly execution has been finished, the business forecast is still in the new state. However, the expression \u201a\u00c4\u00fawork\u201a\u00c4\u00f9 doesn't yet have an exact definition. To guarantee the capacity to work, attempt to clarify that it is comparable from numerous points of view to take care of business inside the time determined after graduation. Likewise plan the capacity to work, as indicated by the necessities or wants of the understudies of the work itself to expand the alumni of learning at work [20,21].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "For example, apprenticeship's double arrangement in reducing youth unemployment is regularly promoted as a model for different countries. The program allows young people to develop significant work experience, gaining more employment and promoting the transition from school to work [14]. This embedded database involves a close coordination effort between the public authority and the private sector, where both companies share the cost and improvement of manufacturing material. Such apprenticeship programs can guide how youth unemployment can be reduced [15].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Internet of Things (IoT), the internet, there is a nonstop future innovation Unrest, will influence the entirety of the application area. Estimate pervasive. It influences and is an enormous scope numerous applications from agribusiness, savvy reference, industry, energy, transport. This can be certain that it would have developed hugely. IoT applications and direct the desire to improve innovation. Furthermore, to defeat the current conveyed capacity, Fathom the arrangements that can be exceptionally related to Sending's enormous scope. [16]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Workers primary purpose is an evaluation of a teacher who received the Spanish and English training to compare the role of cultural heritage in the education process. The essential beginning stage for answers to inquiries regarding the examination between nations, chipping away at the advancement of the source, and the verifiable capacity, is an upbeat assessment of the positive learning technique. This assessment depends on the critical history that is helpful for instruction. Direct and exploration and innovation of verifiable training of basically all that is giving the substance of the most recent couple of many years of the estimation of residents past the promising strategies it is by all accounts at the global degree of the development gathering endeavours. Educators who got the Spanish and English preparing will concur that that isn't served in the middle of the first class and nationalist multi-social and worldwide history phony is by endless long stretches of examination, above. To adapt to the past uncritically memory, ask the set of experiences, techniques, assets, techniques, systems, through the assessment methodology of the antiquarian, is an authentic Chinese reasoning, recorded information and essential thinking the capacity to have chosen to prepare understudies to utilize the wellspring of the specific situation, and the way into the appropriate response you are looking for as a control, history. The customary utilization of authentic information and proof is situated in one of the entire lines of conventional training and examination.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Accounting data analysis platform, they will need to help companies. There are many aspects to this service. Until the sales management of huge sales staff, thousands of employees in the company goal are design and development of new products. Economic activities of companies, customers, supply sector, workers, lenders, shareholders, and government at all levels that has jurisdiction over the business directly, has been associated with a number of departments of the interests of the society.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "FPGA is committed to being a machine learning accelerator for training and reasoning. Designing the reconfigurable technology for these circuits, mainly when the circuit an error occurred when only the chip on the list had been prepared is operating at high speed, it has become a problem. This article proposes a flexible debug coverage family that provides a similar debugging time for machine learning applications. At compile time, coverage will be added to the design and compilation. During debugging, overlay, statistics about the determined amount and activated matrix may be configured to record. This configuration can be changed between debug iterations that allow the user to record the observation matrix about different sets' matrices or record different information [9].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In other words, the problem of disassembly is the replacement ofhc with wiring for a given prototype C or a network of interactive component machines-xi that have the same task of terminal behavior in Fig.\u00ac\u20202. This, in turn, can lead to more effective area implementation, performance, power consumption, and testability optimizations. Estimation of the intensity gradient at a pixel in the x and y direction, for an image f, is given by(2)\u201a\u00e0\u00c7f\u201a\u00e0\u00c7x=f(x+1,y)\u201a\u00e0\u00edf(x\u201a\u00e0\u00ed1,y)(3)\u201a\u00e0\u00c7f\u201a\u00e0\u00c7y=f(x,y+1)\u201a\u00e0\u00edf(x,y\u201a\u00e0\u00ed1)",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "5GHealthNet is a cloud-based configuration, especially since it uses dual-key cryptographic algorithms to store medical records and protected data in the cloud. The main purpose of 5GHealthNet is to use the authorized upgrade to access the cloud over wireless networks to protect personal records [7]. Datacenter data remote access guarantee on a front network [8] 5\u00ac\u2020g wireless network. The sensor device can improve vital sign monitoring on the monitor's heart, brain, and lung function and is wearable for high speed related fitness purposes, high capacity, low latency, for health and with 5\u00ac\u2020g technology Small earplug sensor, and low cost [9]. The latest wireless broadband network technology, connectivity anytime, anywhere, and the use of the country's most advanced equipment will improve the quality of life of patients, mainly in terms of health care awareness and capacity [10-11] availability. To ensure Quality of Service (QoS) problems, robust and clinically acceptable medical services from a medical perspective and level of requirements [12]. Therefore, it is necessary to introduce a new subcategory of traditional QoS customized for such medical applications and critical wireless telemedicine solutions [13].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Information technology in sports organizations, including the competition based on various internal and external factors, is very important to analyze all aspects. This method is the concept of sports science, which collaborates in many areas to strengthen sports organization [1,2], and contributors' development. The work's focus is a theoretical overview of information systems with a special emphasis on sports organizations' existence. The purpose of this work is to propose an example of sports-related information systems, in addition to a systematic approach to the use and construction of sports organizations' information systems [3,4].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Since an important feature of the simulation is Mengtekaluo parallelism, many independent path computations. For this reason, massively parallel processing can follow accelerated simulation. This research requires the use of a common self-healing condition heterosporic custom pricing model on the FPGA supercomputer, now known as the realization of Maxwell Monte Carlo simulation. Mengtekaluo from our FPGA-based simulation engine to replay function, the benefits of relatively low power consumption, and the additional benefits of the best peers. Compared to its predecessor, this paper based on the Mengtekaluo analogy FPGA acceleration at any cost has been reported in the literature so far. It describes the complete design of supercomputers and typical FPGA-based simulators Mengtekaluo functions.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The energy consumption of the monitoring network nodes based on wireless sensor network is mainly concentrated in the data transmission unit. The energy consumption at the transmitting end is mainly generated by the transmitting circuit and the power amplifier circuit, and the main energy consumption at the receiving end is generated by the receiving circuit. The energy consumption at the transmitting end is shown in formula (8), and the energy consumption at the receiving end is shown in formula (9):(8)Etr(k,d)={kEelec+kEapm1d2,(d<d0)kEelec+kEapm2d2,(d\u201a\u00e2\u2022d0)(9)Erx(k)=kEelec",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20204: The wellbeing transformer/generator is checked utilizing the web through far off equipment parts and program single-chip guideline. We temperature, current, or any transformers, generators, and the voltage of the mechanical or homegrown burdens, this observing the information as connected to these segments or gadgets straightforwardly. From that point onward, we change from direct 220\u00ac\u2020V AC on this framework. From that point, a momentum sensor, the information of the voltage sensor, and a temperature sensor detecting the water of the evenly, the information is an interface in a simple structure that is changed over to computerized structure through an ADC 0808, an ebb, and flow, a voltage, and temperature sensor. The information is then gotten by the microcontroller using the ADC 0808, the information on the microcontroller show LCD, and sends the information to the Wi-Fi module. This information, such a current, will show up on a devoted site with three unique graphs, for example, voltage and temperature diagram.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Notwithstanding the enormous number of de convolution, dazzle assessment obscure or may exclude a configuration because of the useful challenges of great low computational expense and picture remaking [9]. Not at all like the conventional technique for designating CS assets even sensor, the proposed strategy utilizing distant detecting picture surface element data to direct discernment allot adequate assets. Detecting a majority of assets distributed in a low recurrence area of the high recurrence district, yet more modest. Non-uniform conveyance detecting assets will bring about a similar degree of pressure execution and a similar pressure and remaking top notch remade great execution. Change in the feeling of assets is a fake picture translation is reliable [10].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The number of higher education institutions worldwide has increased significantly over the past two decades through distance education programs, and the number of distance education enrollments in most countries has increased. The literature is abundant, reviewing distance learning trends, delivery developments and emerging distance technology. However, the rapid growth of educational technology has surpassed the design and model research scope. A well-known distance education researcher points out: \"Technologies such as delivery systems are essential for the development of distance education, the research did not reflect, but is encouraged to practice.\" The critical concept of \"teaching form\" shows that it originated from an outstanding education.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Three-dimensional visualization technology makes computer-generated images look more realistic in educational systems. This technology has helped provide content that is very abstract and difficult to recreate. With 3D virtualization technology, English learners feel more depth than just reading comprehension. 3D technology makes them equivalent to computer images of real-world content in English. This technology is suitable for intelligent classroom lessons and has integrated support for simulation and animation to achieve the most complicated English education content. Due to the enormous benefits of teaching video in primary education, 3D video has become one of the most trending technological innovations in English education to support education and learn the process. Download and upload speeds have access to 3D movies, full/super teaching materials, HD quality assignments. 5\u00ac\u2020G provides a heterogeneous air interface that doubles spectral efficiency. 5\u00ac\u2020G provides gene data Uplink Link (UL) and Down Link (DL) up at 10 Gb / s and 20 Gb / s, respectively. Not only can it make such data rates, but it can also download and upload, and also have full HD live video in English for low latency communication. In class, this service application can help lectures, real-time Q & A sessions, synchronization between educational systems, and real-time communication.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In order to consider the occupancy rate without considering the mobility of vehicles a flow level analysis has been performed in the section using two models. The first is Markovian/Markovian/``c'' limited queue size/``c'' servers and the second is Markovian/Markovian/``c'' servers / unlimited queue size. JSim [8] has been used to find the flow level analysis shown in Tables 1-3.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure\u00ac\u20201(a) (b) shows Overall Map Reduce and Spark. Map Reduce involves four disk operations while the spark only involves two disk operations. For these reasons, a spark is one thing much faster than MapReduce. Spark used intermediate data and further improved its performance as reusable parts. Spark show due to cache in better executable memory. This is due to the read/function MapReduce performance required to fix every error on the disk is not as good performance as the spark.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Machine learning can identify potential mergers and acquisitions, manage a better portfolio, find business opportunities, gain intelligence from competitors who support them, and streamline joint investors and transactions [10]. This way, you can support venture capitalists and other words, it has the potential to provide venture investors with better and better information in the post-investment phase to help the company grow. However, interested in a particular situation [11]. Venture capitalists can be great financial investors or great operators. However (usually with messy margins), venture capital firms must also have two other technologies: post-investment support capabilities i) they have good organization, must have interesting transaction processes and understanding. Ii) They should be able to identify the company's successful policies and signals and pay the appropriate amount [12].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Splitting an architectural image of a city is a way to separate modern objects into different sets of bit pixels called super pixels anyway. The goal of this department is medical imaging. In addition, the image description will be changed to a more meaningful and simpler inspection. Image segmentation is typically used to find items and cutoff points in an image.(5)mn(y)=11\u201a\u00e0\u00eda(\u201a\u00e0\u00ebi=1mm(a\u201a\u00e0\u00ed1)\u201a\u00e0\u00ed1)",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Large data mining to focus on, such as heterogeneity, scalability, speed, accuracy, trust, source, privacy crisis, and guidance, is the most critical mining waste problem. Data mining is an inevitable demand for the discovery of knowledge and clears the debris from the Internet. In believe that various abstract technical advice and works to store all data not only leads to abstract data centers [22]. Data mining is an integral part of knowledge discovery. IoT data from various devices, the accumulated first receiving position (image selection and feature extraction, noise abstract, normalized dimension reduction, etc.) certain operations are placed in a suitable format for analysis it is sent to pretreatment means that the data of the mold. The formatted data is then transmitted to the data mining unit, which performs so that the various data mining techniques to extract useful information to a higher level.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Digital Design course at the Technical University is offered around the world. However, the best way to search beyond the larger organization still exists. As a general rule, it uses part of the introduction of the practice, and practice in the laboratory. In most cases, the only simulation method is used. Some universities offer the possibility of establishing a genuine VLSI prototype, but it is still a rare practice, because of the costs involved. This is the FPGA technology which is affordable. The FPGA-based development board is a low-cost digital prototyping and system development provides a powerful educational tool. It enables reprogramming the FPGA, so that not only verify the complete design itself, but also the establishment of an early prototype of the sub-circuit board using the same development.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The specialists' huge test is organize security. Individuals have been working for quite a while in the zone of system security, however till now we have not thought of an ideal solution. In this paper, the system assaults were distinguished utilizing the open source grunt device. The weakness level differs relying upon the application yet can't be understood with the assistance of rules. In instance of parcel change, Snort identifies assaults at application layer. It offers transitory answers for the recognizable proof of malignant bundles and is helpful in numerous associations. The proposed design for half breed interruption perceives new assaults. We plan to improve the location rate and exactness of both the abnormality and mark based segments of the proposed framework through various grouping calculations for our future examination.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Alteration 1: Two self-loops are included in the model, one in the pyramidal cells (P) and the other in the fast-inhibitory interneurons (F). By adding a feedback loop, the model can produce high frequency rhythms even without the participation of the other neuronal populations [13]. The self-loop in P is a positive self-loop, they not only exhibit other neurons but also exhibit themselves. The self-loop in F is an inhibitive negative self-loop, they not only inhibit pyramidal neurons but also inhibit themselves.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Define the Figure 1, RDMA (Remote Direct Memory Access) is an innovation that empowers direct memory access from a host or worker memory to memory on another host or worker without including the CPU. Doing so opens up CPUs to run their applications and work in insignificant manners, for example, preparing information in mass. Afterward, organization and host execution can be adapted better with lower vacation, lower CPU load, and higher data transmission.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Art Design Course Development design and realization of various functions online discussed in this article. Venture status report consistently, understudies will be approached to fill in a report about their advancement in their plan venture status. FPGA item arrangement remembers complex framework for chip incorporated FPGA engineering, hardened IP and microchip CPU center into a solitary segment. The Convolutional Neural Network (CNN) algorithm is a multilayer perceptron superior design for two-dimensional image information recognition. There are always multiple layers. The task progress report satisfies the necessities of both self-reflection and improvement of the educator report. Although the abrogating objective is similar consistently, the necessities will be extraordinary. For instance, the principal status report expects understudies to address these inquiries: for most other weeks, the advancement report will incorporate an outline, achievement, techniques for conquering difficulties, and particular solicitations for help or data\u201a\u00c4\u00eeself and friend audit exercises.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "However, it still does not include a computer-assisted translation system for concrete Tibetan English translation, and Tibetan-to provides more effective support for Chinese translation applications and promote communication and dissemination. Introduced an application designed for system models, key modules, and features in Tibetan-English information [1]. Generally speaking, cloud computing is considered to be a cluster system consisting of several cheap servers and regular PCs in the network. It organically distributes its various resources, providing secure, highly dependent, fast, convenient, and transparent data storage, access, and various computing services. Mobile cloud computing is the use of cloud computing technology for data stored or processed on mobile devices, thereby resolving the constraints of mobile device resources [2].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The English corpus translation is always tricky due to the excellent quality corpus and abundance of Indian languages due to the English to another language machine. For machine translation systems to produce a better translation, the English corpus translation size must be enormous. Also, parallel sentences should bake similar objects, making different sentences available in different fields. An English corpus translating system, such as a test model, can ensure good translation. This English corpus translation is a contribution to the machine translation research community. The proposed method results are the precision result is 95%, the Recall result is 97%, and the classification prediction result is 97%.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The starter is given for the picture data from the base Amazon. In light of everything, by giving Convolutional Neural Network (CNN) endeavors and utilizing a lab cushion to execute the technique. The standard image's proposed advancement is drawn together renaissance, working environment rules and expects to explain the English drawing found. To the English language as text and handle it to give a discussion yield in various vernaculars. The beginning at now made structure offers to translate English substance into English, Hindi and Bengali, which are among the most permitted. The proposed system, with gigantic updates isolated, holds the business reasonableness. This may instigate extraordinary assistance to individuals coming up short on the power of talk, dyslexic individuals.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20202 the idea behind the industry's analysis, the company's profit depends on the structure of the industry. For example, if many companies sell practically the same thing, the industry will be more competitive and lower profits. However, profits more than the number of competition. It also depends on the other four factors: customer power, supplier power, new entrants threats and the threat of substitution. The five forces model helps to analyze the impact of various power industry profitability.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Identification field, an irregular sensor can be circulated to, and scene, k is accessible to cover a specific number of any sensor on one point sensor on the field. The subsequent tends to be covered by K. Different numbers will give a solitary point one cover. In a genuine climate, cannot remove the way and view. Very well may be an obstruction to recreate as mathematical shapes, called the hazy reason line fragment indisputably to hinder the view way [9]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The focus of the IoT, right context, and their left context match one rule are to load the next translated code block and send its FPGA registers, the translated code stored in the output translated code block. When sending a feedback signal to the controller, the translation can know the number of translated characters. After the group of characters has been converted, the characters sent by the English translation code block are one output after another then a new cycle begins.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "At that point, examine the three plan standards of blended schooling in the English downpour homeroom of the college, based on this rule, explicit necessities and a high substance level, including specialized development, \"Progressed Business English under the downpour hall stage examination and challenged the miniature plan of blended instruction obviously, \"the entire cycle of the downpour of class, and all-round intuitive connection [8]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Web of things will give another heading to the improvement of an ordinary keen apparatus. Microwaves are moving toward insight canny microwave can accomplish controller through the change, or cell phone is likewise convoluted control of conventional items has been improved Operability. This circumstance shows up as a connection. It isn't keen microwave and versatile cycle Awesome, and it is found out, it is hard to shrewd control Microwave employing a portable interface. [3]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Yakut of the coal industry, economic activity - is the third-largest contribution of the total regional value of \"mining\". Russian Federation. Republic is the largest exporter of coke in the Asia-Pacific Ocean region. To consider the possibility of increasing the export of coal is appropriate. In the study, use the official statistics and program files and author of the calculation. Coal mining, processing, and coal delivery: This article reflects the Republic of the coal industry [10].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "When the image is fixed in wide camera view or taken from a broadcast camera because a decimal number of pixels represents the ball, it can have different scales, textures, and the main problem of the automation system is the ball the color is very difficult to detect. For this reason, most ball detection methods are based on ball trajectory evaluation. The basic idea can be pointed out that the analysis of mechanical parameters is that groups of balls are mainly developed in the ball detection proposed in these works to perform a single image about it. Do not use time consistency to enhance detection, and there is integration between different perspectives very superficial. Integrates all the information to realize that can continue to work for a long time.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "This part describes the leading indicator of financial credit and real behavior, insight into Italy's financial data. Goal questions the Italian financial information available from multiple sources to lead the examination. Given Files Stalker's research and leadership, he declared no real strategy to show a more accurate model than another model, or better during that period. Information (centralized access to information available from the data) will change after the Italian quarter GDP is deemed necessary variables. This illustrates each quarter's creative activities in Italy, not because of irregularities and expansion and change.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The most important feature of public opinion on public emergencies in a general emergency network is that disagreements and dissemination are real-time. On the other hand, the emergency is a public sector. Social media has emerged very quickly and exceptionally, and the general public can make comprehensive judgments that are difficult, correct and can take an urgent response. On the other hand, the Internet is an entirely open space and is defined as an extended communication channel. Do this efficiently and interactively, and Real time online public opinion responds to emergencies. The most important external environmental factor influencing the spread of network public opinion in emergencies is the system's interference noise.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Instead of the vision that provides a constant recognition of immersion sub-functions. This data, in charge of the natural information, will be access to classify. At this stage, it provides an interface for the client to any of the locations of access through thInternetet. The method is currently, network project to be proposed, a low-power sensor, mobile phone, and the collected information to the cloud stage to creating a UWSN dependent on the remote sensor networks, water, and nature inspection framework configured. Information inspection hub, information base station and a far focus observation: It includes three parts. The framework, rational complex and a massive range of water climate observations, for example, will be used storage, lakes, rivers, wetlands, in the shallow or deep underground [8] [9]. Capacity Planning and Quality (PQ) implementation of the general evaluation framework, process information, to predict that birth rates that depend on the automatic association of neural tissue (map Kohonen), [10] a wireless information communication, and the sensor development It will be molded by. The sincerity of the current article miserable function announcement work is related to the nature of energy. Such a disaster has disappeared in front of the control outside of the people who have to show off their domination; the situation is a resistance element [11]. Fortunately, several in addition to the inspection of the innovative support of verifiable information and disaster events. At the time of the end of the year, the Internet of Things (IoT) view of the world, such heterogeneity, interoperability, lightweight, quantity, such as gardening in the highlight of its appeal, industry, promising for the safety and medical entrance It was opened. A massive problem for cooking and adaptability.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "By bending different structures and changing the shape and size of the print, the woven structure becomes more flexible. 3D printed woven fabrics are similar to some knitted or woven structures that can alter the deformation properties of 3D printed structures tested for manufacture. By controlling the movement of the heat-melting laminate printer head that can be printed with fibers to create a woven texture, the soft and flexible woven texture can be melted. Nozzles of 3D printer behavior, such as capping devices require further research.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The control structure is assembled on well-known components such as noise suppression and reference tracking. The method also includes irrelevant possibilities, multi-objective optimization different, mixed sensitivity problem applications, and standards for other closed-loop constraints. It is a common reference feature that allows it to be determined by strict standards. However, a convex problem, it may be applied to a feedback gain matrix of the controller coefficient or state-space method is that the resolution is no particular restriction becomes difficult.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The evaluate of the audit's main function information system of the security agencies that were in place. Specifically, the audit of information technology, to protect its information assets, the appropriate information to the approver, has been used to assess the organization's ability organizations ability to distribute. Between the big data analysis and CNN, the audit process has brought new challenges and opportunities to the audit. However, they are widely used; it was not used until recently. Most of the financial transaction and document is only in large-scale data collection electronic format. Therefore, the auditor operates normally; the audit must minimize risk in the context of the enormous amount of heterogeneous data sources related to the financial transactions and customer business. The work of intelligent decision support adopted by the auditors and CNN based on big data analysis improves the audit; it is possible to reduce the audit risk level. This article provides an overview of big data and technology's CNN to improve the audit process's support and quality.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A module on the computer highly customizable Field-Programmable Gate Array (FPGA) new building is for embedded vision applications. My links system from a sheet away from the ZYNQ, the module integrates Terry Apalis compatible form factor Adapteva insight floating point accelerator. They are integrated into two robotic platforms to enhance their successful visual processing capabilities. For evaluation, visual guidance, and navigation crash simulation behavior to achieve insects [20].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "With the rapid growth of the construction industry, human living conditions have significantly improved. With a high energy expenditure, heavy pollution, industrial production, and building material, it not only enhances the living environment human, but also significantly pollutes the human living environment. Therefore, the use of green building materials to promote and reduce building pollution represents the truly important human living environment and human community, [9] used to promote the necessary healthy growth. However, evaluation tools from different countries use different standard compositions. This is [10] because each country has different characteristics such as climate, buildings and inventories, which is why different standards are used.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The presentation part describes the work is trailed by subjects identified with part of the writing audit. At that point, part of the examination, information is pre-treated the improvement of the set, portrays information, for the assortment of information. It is a conversation of the outcomes acquired by contrasting the visionary intensity of the various classifications of business has proceeded. In the model advancement segment, the forecast model is followed by an end, and future work is portrayed.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Mobile and wireless networks make significant progress in the past decade. The file is saved in libraries and museums of historical importance along an information center. And library-like file also exists in different categories, such as academic, special, government, newspapers and private archives. It is a trade item in that category, which is a particular file.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A list of the cross country resource value proportion's swapping scale change tends to be deciphered as new observational proof of pragmatic and successful money-related conversion standards. The national rate's genuine, powerful monetary trade shows the incorporated stock-stream approach with a relationship of global financial specialists of co-combination of the net unfamiliar property of benefits. A utilization portrayed regarding reasonable portfolio conduct of the related blunder revision condition reveals that equality brings venture back [13].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Radar or Radio Detection and Ranging, is a device used to emit electromagnetic signals and receive echo signals from objects or targets on the scope of coverage. Radio waves or signals emitted from an object can be captured by the radar which then analyzed to determine the location, speed, direction, and even the type of the object. One fundamental thing in designing a good radar system is the radar resolution, which is the radar's ability to distinguish two different targets at a long distance with a gap between them. This means that the radar system is required to transmit a long pulse with enough energy to detect a target at a long distance [15].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "SDN (Software-Defined Networking) state stream arrangement benefits the heterogeneous reconfigurable organization, opens the stream switch may recognize each of the two, three, four, and steering conventions. Be that as it may, it is an appropriate information transmission line control framework is hard to figure significant organization necessities; for example, CPS information should be sent [5]. Different examinations have been directed to broaden SDN appropriate for these frameworks. VR-CPES is a requirement for an assortment of uses in a two-fold computerized organization that attracts information as per the QoS necessities of VR reenactment. Further, the information transmission time dependent on the number of twins ought to be thought of, a physical individual's consistent activity.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Analysis and dissemination of innovative theory have adopted the technical level of media related to the digital environment's discourse constituents. To do this, a list of the people of the online media has been made. Besides, the field of online media has been described based on its geographical position. Finally, it will analyze the growth of digital technology, such as multimedia and augmented reality. It conclude that video technology has the highest level of adoption [1].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "During a season, people typically enter and exit during times of high injury. By utilizing the normal moving channel at full danger score, you can see the player entering the time of most exceedingly awful risk. Checking these periods is significant in overseeing players and assisting groups with overseeing players expand execution while limiting the danger of injury.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Feature extraction is used to extract the feature in enhanced image, as it upsets the arrangement stage. If the separated highlights are deliberately chosen, the normal list of capabilities will evaluate important data from the information to utilize a decreased portrayal of the full-size input instead of performing the desired task. The main task of texture analysis is to analyze an image, each of which is uniformly textured and it divides the image space into a set of sub-regions, texture segmentation. However, it is a difficult task due to the large factors such as size, shape, position, and intensity and the complexity of the tumor features in the image. It presents feature extraction and segment unsupervised clustering and labeled MRI brain slices used by the new system. Every volume component is allotted with an element example of a scaled group of invariant highlights in the differential calculation. The permanent element design is then relegated to a particular zone inside the two-stage neural organization framework. These modes are translation and rotation invariant, not scale-invariant.(2)Gy(d)=1N\u201a\u00e0\u00eb\u0152\u220fT(d,\u0152\u220f)(3)Gx(d)=max[T(d,\u0152\u220f)]\u201a\u00e0\u00edmin[T(d,\u0152\u220f)]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The procedure for getting the classifier models by training the dataset is done as follows: After selecting the category of classifiers, we fix the member of the category and its default parameters and run the training and training in cascade with cross validation of 10 folds. This is repeated for every classifier in each category and iterated for other categories. The results are tabulated for relatively higher values of accuracy obtained in each iteration.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Adaptive organization information based on a large FPGA dynamic reserve VM worker is further integrated into the component server farm and provide adaptive FPGA and the determined point execution cost is possible. If you need to use it in a VM cloud. Quick assets automatically sent from the other characters. Partial reconfiguration of the FPGA VM cloud networking framework, which is the FPGA steps to become a real star cloud VM resident workers have proposed and implemented design. Implemented from start to finish is designed to understand Distributed Storage Manager(DSM) is easy to use, provides a protected innovation for our customers and meet the needs of all inferred while providing support for heterogeneous groups. Then simply by transmitting a number of incomplete files and their associated composite structure, you can send across different FPGA application. Obviously this study is the first to achieve independence PR throughout the organization and enhance research static management of the FPGA connected to the organization.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In this 5G network, to meet the diagram and the fate of portable correspondence necessities of 5G innovation, it has incorporated an assortment of equipment and programming characterized innovation. FPGA depicts the strategies that are utilized to make the different parts of the 5G foundation. Crossbreed registering stage, for example, equipment quickened technique FPGA-based of the current innovation appears to guarantee the acknowledgment of free energy-sparing Network Function Virtualization (NFV) and Centralized Radio Access Network (C-RAN) engineering. A viable constant sign preparing the structure can be intended to portray countless Multiple Input and Multiple Output (MIMO). To work, while supporting high information traffic, intellectual radio offers a wide scope of utilizations. Its presentation is situated using FPGA, it can successfully improve the miniature and full-scale cells alongside the consolidated activity of the little cells to appoint range to keep away from starvation. Since the radio range is a piece of nature, licenses, and oversight of the range, are dealt with by the legislature. Government organizations, aside from when to lead the fixed range portion to the under-used assets, is a particular unearthly reach is inert. Along these lines, when you access the range that has not been completely used, it is existing because of the reality you can't utilize the range, troublesome issue than the range itself that has not been completely used. Here, Cognitive Radio (CR) under the under-usage range unsupported auxiliary clients, can determine the client range portion.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The public on the quality and quantity of food is increasingly interested in expanding the industrial requirements and expanded agricultural sector. 5Gnetwork remote sensor is an up-and-coming innovation, providing innovative solutions to the modern agribusiness sector. Party inspection agency and logic have been trying to use remote sensors to communicate and position items to address different agriculture areas. However, one might observe the agricultural cycle, actually more concerned about the current agricultural information, accuracy and wisdom than in recent memory. Based on the rapid rise, the 5G network has been upgraded so that almost every industry, including smart agribusiness, enables enterprises to shift from the fact that the method for the quantitative approach. This progressive change has shaken the current agricultural strategy. Analysis of remote sensor gadgets and how to relate to agribusiness applications experienced remote sensors. Sensors can access straightforward integrated enterprise applications in agriculture and soil situation, crop situations, this innovation will support the entire harvest in the of planting (from planting to collect, press and transport). The paper also discusses crops' observation and another ideal for applications such as 5G network communication using increase crop yield. Finally, given this careful study, goal will distinguish between power and remote sensor model for the future of agriculture and respond to potential exploration challenges model.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Huge scope open online hall Massive Open Online Courses (MOOCs) is, distance and has been created from free learning convention, and are getting increasingly famous. As another and energizing field of instruction, MOOCs, by individuals with admittance to the innovation, can get the course for nothing, changing the capability of training and the Internet to form subjects and advantages educators' student potential. General proficient turn of events and English instructor, particularly huge scope open online hall in a limit building (MOOCs). MOOCs, which are getting increasingly mainstream in Pakistan, are the most oblivious idea, is the individuals, particularly educated in the customary vis-\u221a\u2020-vis mode. Suppose remote sensor networks are sent arbitrarily (because the Boolean model's broad utilization doesn't make a difference). In that case, the quantity of way length and the sensor will have the way inclusion restricted. All the more explicitly, are full-way inclusion the quantity of the conveyance of the hole that isn't covered and to discover the likelihood of the chance of the whole's entirety is more modest than a given size. Similarly, the same number of second language college employees don't interest in any MOOCs; are utilized to comfort the information collection inspecting. The just respondent has finished the survey. Dependability of the trust survey. The outcomes show a low number of English instructors in Pakistan ought to partake in an incomplete or full examination of MOOCs. In this manner, as usual, it is an extremely less number of every member MOOCs. Nonetheless, participation, and anybody any individual who partook in the MOOCs, the instructor is advancing their general mastery. Found that it is whether improved and administration abilities improve the language, which is exceptionally valuable.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Installed methods are utilized in such applications to uphold the organization and I/O interface to be prepared by changing a devoted interface processor by the assistant processor's limit. The committed processor additionally investigates the video/sound transfer, and the video/design delivery may be handled [13]. The collaboration of the different transmission portrayed above, regardless of the bundling method's scalar, multivariable nature, is explicitly pondered, yet using multivariate structure work. This strategy's upside is a solitary information single-yield traditional control method profoundly fruitful as a nudist rate seems to be; it tends to be utilized without loss of multivariate information [14].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Due to the logical sequence of the rest of the devices, a 50MHz clock can be externally provided via GPIO (General Purpose Input/Output) pins. The frequencies of all notes are generated by complex frequency generation logic technology. The filtered output is delivered to the speaker, in this case, the simplest audio output device, the audio transducer. In the case of the figure\u00ac\u20201 implementation input of the configuration block, it is received from the FPGA High Performance Algorithm, one of the pins available in the high. As mentioned above, the control logic section employs two modes. The selection of this mode is a manually selected musician.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "FPGA-based equipment used for image processing, upgrades, and classification is used for screening calculations. FPGAs are often used as an installation phase for certain image processing applications because their structures can be used equally. The strategy adopted is by the window manager method of image pixels, and the channels are related to them. Field Programmable Gate Array (FPGA) innovation. So far, the FPGA scale and highlights have achieved significant improvements. Approved stage image processing applications require particularly continuous preparation [2].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The geological body structure is a product of the natural world's geological evolution in the 3D structure of the time dimension. However, many geologists, due to the massive loss of spatial data, are still recording the process and uses the geological data and 2D or 1D pattern. One reason is that the current method, the method of expressing the subsurface geological objects, is limited [3].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The most common data type is social media, but learning is the most common method of random forests in these studies; the most commonly used keyword support vector machines use a summary of the results display/return, deep learning, artificial neural networks and convolution neural networks, land use and land cover, land sit. Recurrence display keyword results in keywords cooperative network together. Classification is dominant keywords that are near related to the support vector machine and the random forest. Predicts more closely with other essential keywords can be traced back to these studies; it is related to the neural network.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Learn from these because can easily learn how to play basketball without injury using the machine learning method. Easily get to know each athlete and their abilities and functions. Learn through these to learn how to deal with risk and how to escape from them based on this learning method. Athletes are analyzed here for their skills and action skills. Different types of recipes are used here for that. By comparing it with the new recipe, find that the new generation highlights its effectiveness. Most games have waves and currents, and the game situation changes over time. Our approach is designed to reflect these trends and tendencies. They put forward their ideas for an intelligent framework that, in the future, consider a fake in sports. Other implementation results may change future planning system, is probability. Based on the Monte Carlo method-forecast Monte to evaluate the overall outcome as a taxonomic learning system.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20204 systems typically include a large number of SSIs (Small Integrated Circuits) and MSIs (Medium Scale Integrated Circuits) in some large integrated circuit components and video teaching components. The first attempt to solve this problem led to the development of custom ICs that replaced many of interconnects. This reduces system complexity and manufacturing costs and improves performance.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The green metric system introduces the content and scope of the evaluation of green industrial buildings for industrial plants and reflects the direction of important measurement parameters for green industrial buildings and groups. In the process of developing standards for green industrial buildings, the unreasonable results of weight distribution of various indicators can be reduced by the expert group Analytic Hierarchy Process (AHP) [13]. Green buildings play an important role in the development of the construction industry. The main problem with green buildings is how to manage them. A green building management cloud platform. Its purpose is to use the Internet for cloud computing and things technology to achieve construction and operational management. It provides cloud server computing [14], as well as hosts and data storage.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "FPGA circuits are provided in several applications, including two memory controls, functional modules, switching routing networks, and the exact number of transistors in a single chip package. It includes static RAM (SRAM), its stored functional units, gates, storage elements, and control memory in the form of wiring routes wiring. Fig.\u00ac\u20202 describes about FPGA series are distinguished by their chip-level architecture as a subdivision through of their functional units and intra frames and connection tie routing. The simplest paradigm for using FPGAs is the (silicon) \"sandbox\" where the system structure can be built for the time required to write to RAM and the level of complexity defined by the chip architecture.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The transcription tag sequence is the function of converting a tag sequence into predicting each frame by CNN probability. The image-based model analysis must find the predictive tag sequence of each frame. It is a free dictionary and vocabulary-based adaptation: In fact, there are two ways of transferring. Dictionary spell check is a set of prediction barrier as a dictionary tag sequence. Vocabulary free mode, the prediction has been made without any of the vocabularies. In the vocabulary mode, the prediction is made by selecting the highest level of the tag sequence as much as possible.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Contract in order to complete the goals of the characteristics, must be skillfully crafted. At the time of the change of industry 4.0, for those coming from the machine of roboticization, there is a keen insight gadgets exponential increase in human resources management system applications. Significant need is rules development organizations, energy efficiency, filled minimization laziness, range capability, storage memory amplification, and the target that are needed to implement the shock boundary as a prerequisite for using the transmission rate.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The Solar Water Heating (SWH) system is a well-known and practical framework for transferring solar energy by thermal energy using stored hot water [6]. The SWH system's efficiency is mainly based on a well-designed solar collector, a perfect operating system. Most of the existing methods improve solar collectors' efficiency, but limited research focuses on improving operating systems [7]. Solar water heating systems to achieve energy management goals and help the building management control mechanism.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "For the early adoption of remote sensing in the sea area, drone clusters have made them vulnerable to various types of cyberattacks as legitimate targets and based on advanced flight control issues of significant security. It is related to the problem. They can also be used as remote sensing monitors. The current flight angle is determined from the measured acceleration. Gravitational acceleration can be divided into three components, parallel to the axis of the vehicle. An accelerometer measures these components. The angle is triangulation (one of the angles becomes uncertain and has one degree of stationary freedom, which must be determined by other devices such as angular velocity integration). It can be determined by surveying.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20202 shows this tool allows the user to customize the synchronization Street View panel's location in the Google Street View panel. These marks can be customized in a utility type, such as the pipe and the pipe diameter. Address from geocoding coordinates of the marker, good marker position and the marker attributes exported to Excel files are added to the spatial display of the pipeline data underground generated by GIS software, arranged for post-processing. It will be reversed after it has been. In some cases, a convenient map is in the public domain. will transform these maps to the shape file. Let's imported directly into GIS software. This study obtained the distribution map of the natural gas pipeline from the Massachusetts National Grid. As it can be converted directly to a shape file in polylines, these pipelines are represented by a vector (more rather pixel representation of the raster map). PDF conversion to shape files, AutoCAD is used as a medium to extract a polyline and export it to the arc map. Then, use the additional spatial information by geo-referenced and space adjustment tool.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "It is a type of physical education, art, and performance analyzed by human rhythmic movements. In the teaching process, the rhythm of accompaniment and sports' emotional implications are difficult to explain to language students. Accurate representations of educational content are included in the Material. Intuitive, vibrant, vibrant pictures can guide students to gain sufficient cognition, composed of multimedia, stimulate interest in learning, deepen understanding and memory, and repeatedly browse.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Research on sports information management systems covers all aspects, improves sports management's status quo, and appears endlessly. Still, such information management systems' function is too simple; there are also some issues, as the content is not comprehensive. The design of the information management system for various projects matches the needs of the users. This is a short-term uniform regulation, which contributes to transplantation and promotion. Sports information systems still have the drawback of studying security issues and enabling the management and sharing of information. This field accumulates certain outcomes and effectively solves the difficulties of practicing sports. Still, it limits the depth and range of applied research and promotion and application of research outcomes and relevant theoretical research.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Emergency global challenges are leading to global warming and climate change. A possible partial solution to this problem, design a building's energy management engine that encourages users who want to maximize and adapt to a technological environment [2]. Energy management technologies are designed for home air conditioning systems, taking into account users' feedback on these technologies [3].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20205 shows that the ZYNQ used programmable logic resources comprised of a computing platform and a processing system (PS). The heterogeneous system also includes a portion of the required input/output interface and the external evaluation board RAM. The proposed solution may be visualized as a result of image processing via the HDMI output. Image analysis result (metadata) may be via a Universal Asynchronous Receiver Transmitter (UART), Ethernet, or simple web service. This section presents pipeline data processing concepts. It also discusses the assumptions used in distributed computing tasks between the PL and PS. Also, the operating system is described for the selection.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Synthetic Aperture Radar (SAR) images' contents because the shape and scattering properties disguise very similar to the real goal. However, compared to the real target, the disguised target still has differences in the structural details. These differences and must be reflected in the SAR (Synthetic Aperture Radar image).suitable to identify a target from the SAR (Synthetic Aperture Radar) image processing. Furthermore, although this original passive camouflage to explain SAR (Synthetic Aperture Radar) image target recognition technology, research has not been involved in a considerable number of documents yet to be resolvedpassive object recognition research disguise beneficial.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Understudies of electrical designing have been prepared English at the college. Understanding the significance of learning an unknown dialect has been affirmed in various administrative archives [17]. Examine the seven significant colleges of to prepare understudies in electrical designing. Content is a combination of code on the present web-based media stage capacity to handle an application for another word to compose Pinyin, a significant essential to language acknowledgment jargon acquiring and word level, posted an assortment of normal language. Code blending is an exploration field in increasingly more characteristic language preparing spread via web-based media, blending text of the code need a difference in voice language and spelling [18].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "To operate better all electronic circuits, the best major electronic components need a power supply and require adjustment. Direct Current (DC) power, some applications, positive, a ground and a negative Requires dual power supplies. This article, by using a step-down transformer and a linear regulator, can build a dual power supply circuit. For all the three dual power supply circuit, but the structure and processing method is the same, the components' specifications will vary depending on the output voltage range. The step-down transformer is reduced to the input volts amplitude vacuum cleaner according to the specifications. Low voltage Alternative Current (AC) power from the secondary transformer's secondary wind is fed to a bridge rectifier module when the rectified DC output is supplied and filtered by a filter capacitor C1 and C2. All circuits in the C1 capacitor are filtered\u201a\u00c4\u00eeall circuits of the positive side of the capacitor C2 and the negative side of the capacitor filter.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "It proposes new emotion recognition techniques to reflect important information that affects the use of acoustic and vocabulary functions. Acoustic features are extracted from the audio signal by extracting features from the emotional Deep Neural Network (DNN) of the statistical function [5,6]. It suggests that Emotional Word Embedding (EWE) jointly learns textual expressions, taking into account their meaning and emotions. It can found that visual and text features are deeply normatively correlated, Deeply Coupled Video and Neural Networks (DCVDN), new visuals that are simultaneously extracted and fused to form a comprehensive representation based on an auto encoder base. Suggested text emotions Analytical model view learning [7,8].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The IoT is an evolving classical paradigm in [11], designed as a framework of billions of minor interrelated devices to present real-world glitches with state-of-the-art findings. Over the last decade, the IoT has gained increasing study interest as a critical design for the continuous integration between human activities and their information technology pictures. The IoT programs include the placement of cellular networks [13] around the board and self-organization. The IoT paradigm [12] is moving into the idea of a cyber-physical universe in which things may be conceived, inspired, mixed, and rationalized to cause every potential connotation to be created. This paper offers a snapshot of existing IoT research that illustrates enabling technology such as fog computing, networks of wireless sensors, context perception, data processing, real-time analytics, cellular connectivity, and virtual reality.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Offshore and onshore, among a plurality of oil and natural gas facilities in different regions, manage the safety-critical systems in real time. It is a big challenge for all companies. through its exploration, development and production subsidiary from a centralized management location in the successful remote, to manage the existing corporate information, expand the digital solutions to the web site of Real-Time (RT) multiple safety-critical systems technology in not you different Information Technology in (IT) infrastructure [5].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Evaluate the general presentation of understudies with routine evaluations and credits, and foresee the exhibition of designing understudies, the Artificial Neural Network Model is 80. For the exactness of understudy grades [17], the affiliation has proposed a mining model-based guideline program for understudy grades assessment rule. Affiliation rules are utilized to check the understudy information base to acquire important data for understudy execution assessment.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "E-commerce companies have amassed vast data, including transactional, interactive and tracking data, and even offline data such as online and social networks and user locations. This data will transition from \"Customer-Centric\u201a\u00c4\u00f9 to \u201a\u00c4\u00faProduct-Centric\" in the marketing field and have made more precise personal needs. The challenges and new possibilities that come with accurate marketing based on big data are the marketing strategies of companies. One is to examine consumer data and behaviors and develop models to reveal the relationship between personal consumption behavior and personal income. Second, It can use social psychology to describe people's inner world through events, including subjective and objective events, after which market speculation and attitudes must harmonize with the harmonious production and consumption of market demand. Therefore, there is a different relationship between data and the market. Also, ML enhances itself to collect data, and even its performance, especially when hidden risks are discovered. From significant data rules, ML data mining is widely used. So far, ML scholars have proposed a large number of algorithms that are suitable for different fields and problems, such as pre-evaluation results trees, neural networks, Support Vector Machine (SVM), K-means mechanisms, etc.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Another way to change smart green buildings design through the Internet of Things (IoT) and 5\u00ac\u2020G networks is to speed up data reporting. IoT connects smart devices are beautifully filmed to respond quickly to the growing trends of the green build design. Demographic applications facility managers understanding the results of optimization will allow for different processes. It also uses a single panel to provide a green building for those in a zone monitored for the use of demographic equipment in this building.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20201 data model, apparently to determine the structure of the data. The data model, usually, experts of data, have been specified in the digital liberal champion in the data administrator, or data modeling notation. These symbols, usually, have been expressed in the form of graphics. From time to time, the data model, especially in the programming language context, can be referred to as a data structure. The data model, usually, in particular, the case of the enterprise model, will be complemented by a functional model. The problem-based learning method is to create an environment in which the learner can search for information independently. To avoid this problem, it is possible to provide an exciting solution for creating a strategy to resolve training you. Current work, which named the project entity, is that students (usually digital natives) are in peace and build a simulator to resolve the actual engineering scenarios to face to build a virtual learning environment platform in the city aims. Aiming to urban platform high school education, they can solve the various problems that have been raised in a close relationship, at the same time students and students of higher education in.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The data management layer begins to function as the source of data, such as data fusion in data interpretation. In the same event, sensors can capture different types, and there are usually different formats of data from different sensors. Therefore, the data can be in a superficial store. The data processing layer has reached the critical stage of computing based on the configuration of the smart premises, integrating computing fog lighting applications, and the data centre cloud on remote premises. Services and tasks can be handled in this layer which is provocative at most times.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Driveline A of the robot is, as the name suggests, the automated guided vehicle embedded in the floor or ceiling of the line-of-sight. Usually, the sight path line goes from the robot is a black line on a white surface (white line on a black surface). Other methods are also possible. Some of the advanced lines will follow the robot's trajectory using a magnetic field that cannot be seen. A large line following robot has usually been used in the industry to support the production process's automation. The robot can also line the following to get the first machine's experience is the first robot beginners. It is a student military applications for artificial support, has been used, for example, the delivery service. Arduino is given. It has been designed to use a simple line follower robot and several other components.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Intellectual class system is designed the challenges of day-to-day of classroom and laboratory to support the faculty and teaching assistant, also, academic interest and performance of students, convenient and practical, and in order to overcome the key solution have to improve the important applications of the technology. By providing a large-scale study in the conference mode of classroom and laboratory of smart class Help faculties and departments, to ensure more and more all the students in learning the classroom. This is also very useful in managing the participation and interest of the students in the classroom. Smart class, it is possible to facilitate the question of the teacher. To understand the basic concepts of abstract course, it is difficult to imagine, student's, you can use the method of interactive multimedia.Quality education is an important prerequisite of the competitive environment of today. Technology affects us in all aspects. Smart class, explained the concept to help them better conceptualization, to improve the reading skills and academic skills, in order to provide a high quality education to students, it is a modern way of Indian education situation education.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Employment and entrepreneurship are key components in manageable development, improving economic, social and natural dimensions. However, Employment and Entrepreneurship and open information are concentrated in writing from a holistic perspective. The embedded database identifies the normative aspects of past tests and proposes a theoretical model for breaking down employment through entrepreneurship. College Students clear investigation and co-word testing took place action related to tools that reuse data distributed by public companies by experts from various organizations to create new expert activities, especially for new portable applications. Entrepreneurship resources, development and action plans can be read as basic elements to embedded database employment through entrepreneurship. A calculated model is introduced, and emerging factors are proposed for future exploration. It emphasizes the importance of empowering joint efforts between different entrepreneurship environment experts for progress and improvement. Improved Ant Colony Optimization Algorithm has identified an emerging topic in its infancy: the embedded database of auxiliary employment through open information as a value creation activity to address practical twists globally.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The Usage-Based Ranking (UBSA) to identify the satisfaction that web customization provides to users within a particular category of the personalized and specific information related to time optimization is called. Evaluation of Internet usage in time and rotation is necessary to determine the above parameters of the network service provider [3]\u201a\u00c4\u00eeuseful web design customization to integrate domain ontology, new indirect user feedback, and event correlation access methods. Quickly find and suggest a standard reverse index structure. The primary target user's personalized search achieves the best search [4].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Long-term planning in vocational schools, community groups and accessibility issues should be considered as a basis. It does not assume complex mental arithmetic operations to ensure that there is always a demand for education. But among cyclical fluctuations, it will produce school education, strong demand [18]. Technological development is mainly based on manufacturer's work (characterized the last century) largely superfluous mass production. Large-scale production creates poverty because it increases the minimum amount of tax revenue to GDP, limiting mobility. In the future, only a wide range of high value-added products and services in market competitiveness and profitability.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "All of the results in Table\u00ac\u20201 are shown below. There were no statistically significant differences. FPGA High Performance Algorithm contains open-ended questions about likes and dislikes about courses, teachers, musical style and repertoire, practice, and family influences. The results prove that enjoying the music of choice by the teacher increases the satisfaction of children playing music lessons and practice time in the classroom and practice.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Similar to Impressionist evaluation, subjective evaluation is much larger when playing the piano in the game process. Therefore, using rigorous systems and components to guide piano teaching is an important factor [5]. It cannot be separated from these three factors. The evaluation aims to determine the evaluation tasks in this process and, thirdly, formulate clear and feasible criteria. Besides, evaluation methods should combine evaluation and education and training [6]. Evaluation objectives are usually vague and require specific limitations.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20201 represents the first step or process, the necessary steps of digital image processing. Error image can be acquired in the image such as that in digital form is simple so. Image enhancement is one of the most comfortable and most attractive areas of digital image processing. The idea behind the reinforcement techniques is to derive the obstruction or emphasize specific features of interest in the image. Image restoration, such as change of such brightness and contrast, is also a region involved in improving the image's appearance. However, the subjective, unlike enhancement, image restoration is an object. In this sense, repair technology is often based on the mathematical or probability model of image degradation. Wavelet is used to represent the basis of an image with varying degrees of resolution. The picture represents a smaller area. It is subdivided into successive data compression and pyramids.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A Distributed Sensor Network (DSN) can reliably identify multiple people in an indoor environment. This DSN is based on a sensor and a combination of move/tilt/zoom camera and control panel sense sensor units for an audio sensor module to receive any information and 3W results [3]. PBTO (Prediction Based Task Offloading) connects with many human detection and monitoring, facial recognition and daily activity recognition. By evaluating this DSNS performance in the classroom, you can ensure that it can help you perform various tasks for system purposes [4].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A model represents consumer behavior as a complex decision-making process. The model here describes the circulation flow of the effect: Each component provides the following input: The communication provided by the model to the customer refers to the situation in which designing and the customer response influences subsequent actions. The Electric Vehicle Purchase Behavior model seeks to explain the buyer's good brand choice behavior with incomplete information and limited capability. The levels of large-scale problem-solving and decision-making method criteria, less information, or evaluation options. FPGA (Field-Programmable Gate Array) based Neural Network solving skills best suits and clear ideas. The best brand is not known for evaluating a clear understanding of regular response behavior-standards and a healthy attitude toward the brand.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Data pre-processing is a data mining technique involved in converting source data into an understandable format. Real-world data do not have some behavior or overlap with each other, and there may be many errors, usually incomplete. Data pre-processing is an effective method to solve such problems. Data pre-processing also generates processing source information.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "By playing out the difference in public monetary arrangement, in the non-disaster protection industry, it will plant of the polarization of the occasion. The majority of the non-disaster protection organization, solitary wellspring of business and the deficiency premium development point. They are unfaithful of venture show, duty, cost, yield, and are confronted with the danger of income. Simultaneously. Part of the effect of the slump in the non-extra security industry. Interest for non-disaster protection has diminished. The entirety of the non-disaster protection industry has brought colossal monetary danger. Therefore, the non-life coverage area that has happened in the administration of early notice is extremely essential and viable.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Based on the proposed marine power generation system of the Asynchronous, Synchronous Motor and this article aim to adjust high electrical standard, cost-effective energy. Widely used power electronics technology, but has contributed to the electrical boat development; dependence has increased in power electronic converter. Compared with the application based on the total volume of the on-board power electronics will be significantly reduced [2]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "To object to networking technology in various fields, such as smart cities, medical, networking platforms adaptation to the monitoring and management of a lot of things. It can be developed [1]. Standardization organizations such as one M2M and Operating Cash Flow (OCF) design, networking standards to regulate the platform's operation, and this standards-based platform for all kinds of things connected devices resource management [2]. A variety of business platforms, such as GE's Predix platform and IBM's (International Business Machines) Watson of Things platform, developed as a dual-platform digital consideration. They support the use of Predix networking services, digital assets, and double machine data analysis.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Actions, gestures, or sports are some of the essential communication tools used by humans. People often use exercise-like hands and heads to tell the story instead of their body parts. Recognition of human behavior is the most active topic in computer vision. Computer vision, machine learning, pattern recognition and automatically analyze gestures of various human activities. Human motion recognition methods have extensive literature on motion recognition in many areas, including other purposes developed using video data, motion capture, depth data, or combining these methods.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Software like FPGA, however, is designed to provide you with flexibility in the form of logical formulation that is programmed to close with application-based integrated circuit speed performance. And with the infinite number of times, since it has been produced, the FPGA has traditionally been used by hardware designers as a prototyping tool. Xilinx consists of a two-dimensional array of programmed logical modules called logic modules for the basic configuration of the FPGA in Fig.\u00ac\u20203.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Present-day cell phones are used to stack the centralized computer and high force/region. Numerous sight, sound applications and image processing applications, are implanted in these cell phones. If not, utilize the substance of the picture in the correct configuration, when all things considered, extremely complex calculations can't separate the right data. By utilizing the histogram, you can undoubtedly handle the picture content. Histogram of design equipment is available to give various sizes of histogram which can be made for each kind of dim scale picture and test system and what could be compared to the information and exactness as a histogram trades utilizing software [2].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Study This cycle will take quite a while, the chance of reusing vehicle is troublesome in a decent condition, surviving plan these issues, called \"insightful framework A vehicle that can lessen, \"run the stream control arrangements Help with inappropriate leaving of the vehicle With the assistance of basic assistance to apply a severe traffic rules innovation. Notwithstanding the offered framework, to help the Short examination time in and robbery location [13]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "5\u00ac\u2020G network, to save money, a stable something than to protect the record, collect the client's information. Low-dormant transmission capacity, thereby to prepare a people-oriented, individual financial management department, to install the data from the area, to allow movement of the continuous data classification and information. In this competent department, to maintain the budget of the guidance in mind, the method continues to set all customers' action information.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Lung Cancer is a disease of symptoms that externally control the proliferation of cells. There are many types of cancer, each of which is initially classified according to the type of cell affected. Lung cancer is the most common cancer. Smoking is a major risk factor for lung cancer. Passive exposure to tobacco smoke can also cause lung cancer. Lung cancer is of two types, different growth lung cancer, and widespread lung cancer.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20202 music recordings, which are in various modes, are completely identified with learning across modes. Notwithstanding matching similitude, semantic likeness between various video, sound and video content in a similar group is additionally expressly thought of. The start to finish profound engineering speaking to a square spoke to by a sound arrangement is examined. The trial assessment run on information chose from demonstrates the viability of the deep audio visual installing calculation in cross-channel music video retrieval",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "There are smart and smart classrooms, and more time fades in all the traditional ways of education. And make the end-to-end teaching and learning process intelligent and straightforward. Create witnesses [13] for the next generation of students and teachers, advanced computing, and smart digital devices. Condition monitoring has improved safety and reliability by reducing maintenance and upgrades due to failure detection, which reduces manual inspection requirements with automatic monitoring. [14]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A positive impact on the future of the supply chain and military spending, 5G technology enables superior data collection to use the material. In the military communication equipment, to be used without a satellite relay station and reduce military operations costs. D2D communication provides high-speed short-range communications. The first part is introduced as a brief description of the requirements of military operations and functions similar to the 5G network. And the application of critical technologies 5G. In the third part of the challenge of 5G are presented with a focus on security needs, challenges, and by a variety of authors and solutions given by standardization bodies. 5G military applications and some of the future battlefield network solutions will leverage 5G.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Remote signal images are usually limited due to image restrictions. Various Super Resolution (S.R.) image reconstruction techniques have been developed to reconstruct blurry view sequences and low resolution of a high-resolution image to solve this problem. This presents distorted and distorted signals from an angle using an efficient, super-resolution image reconstruction method based on validation [9,10].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fayyad, the information mining, are characterized as \"from the information put away in the information base, certain, so far not been known, conceivably cycle of removing helpful data rapidly\" [3]. This to acquire specific and beneficial outcomes for the proprietor of the information base, the main choice of a lot of information to discover the consistency or relationship is obscure, exploration, and displaying of the cycle '' [4]. For every information mining strategy, play alternate purposes relying upon the motivation behind displaying. The two generally basic displays are delegated an expectation a portion of the normal devices for the forecast, neural organizations, and relapse [5].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Virtual Reality (VR) reproduction environment that fills in as the connection between scene plan and Internet of Things assets to construct the web.The goal of the proposed assembly project feasibility studies is demonstrated by the independent and web-based application environment, which implements comparisons and modifications of the assembly sequence and project recommendations. Many methods can create almost optimal assembly plans; Significant are the landscape design wireless-based demographic approaches focused on determining the component sequences that should be optimally close based on these specific target areas and area feed levels. Taking advantage of such an integrated VR landscape-based approach is to make the joint production structure more flexible and responsive by adapting to customer design needs.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Machine learning approach is to establish a overtone learning method using the observation data for explaining the relationship between the corresponding elements with the residence time. This approach is used to estimate the residence time of the first bus. Buses proposes a overtone learning to estimate the bus was residence time which is formulated as a linear function of the time required for boarding passengers and bus open door to the number of two major factors off, residence time.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "More web-based applications have led to vast collections of web server log data, which has led to knowledge discovery through web-based mining technology. The mining and user browsing patterns used in the weblogs for analysis extract useful information. The business community uses this knowledge of discoveries to personalize customers through websites, increasing customer satisfaction and revenue to improve web-based applications' revenue goals. In understanding user behavior and preferences, interesting usage patterns discovered by web usage mining are hidden in web data.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "These algorithms are extensive. These experiments' results are supported by the fact that computer-based data models have been tested to ensure they follow through with performance analysis tasks. There the first part is the algorithm counting algorithm, and the second part is complexity, but on the other hand, it is false.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The load deviation values of all resources are shown in Figure 4, and the corresponding numeric values are shown. The experimental graph shows that the load deviation of the EWBNES algorithm is reduced relative to the existing algorithm. The EWBNES algorithm balances concurrent task schedulers and network environment based big data service load balancing resources in network environments. As a result, the proposed EWBNES algorithm maintains the load deviation within 62%, but the existing methods have the load deviation values between 62% and 105% when the number of tasks is 50.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Students in our Field-Programmable Gate Array (FPGA) incentive is chiefly in research, in order to demonstrate the feasibility and efficiency of the easy-to-use infrastructure in the cloud. it will use the FPGA cloud in the 2018 spring and summer semesters of our COD. Take some important courses related to the computer system's discovery from the course of the practice of class discussion.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The Employment and Entrepreneurship traditional ways and types of innovative open doors are gradually being addressed. New computerized advances that profoundly affect how new companies are being created and created have changed enterprise cycles and outcomes. Utilizing the ability of cooperation and comprehensive insight to send. A computerized setting is a field that additionally creates open information. They try to use cutting-edge innovation and try to assemble new items that are obscure to the market and motivate buyers to acquire them and consequently improve their lifestyle. Employment people find a new market, new product and display another kind of affiliation. Thus, Employment and Entrepreneurship progresses due to the creative ideas and activities of the employment people",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fuel flight is one of the most basic cycles. This will improve the picture's quality and accordingly impact the picture assertion measure for better substance interest. Also, that makes a more precise yield, activating the fulfillment of the character's interest measure. Standardization is one of the essential preprocessing endeavors for text certification",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 1: The level of neurons in each convolutional layer is changed to the most astounding rightness. In the wake of joining the model, utilize the function of each layer of neurons. The plan at the fundamental level is being utilized to help. The dropout layer decreases the multifaceted thoughts of affiliation and planning. With cell phones and versatile contraptions given camera-based applications, understanding these devices' centrality broadens all by the comprehensive length.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "For drone clusters and business individuals, the benefits offer multiple levels. However, drone masonry systems suffer from additional security, security and privacy issues. Security and privacy failures must be addressed at the highest national level using an autonomous drone cluster. There should also be strict ways to reduce the drone's ability to record videos and attributes of images collected without permission.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Job execution is a step-by-step legal procedure. Since the framework scheme is shown in Figure 3. Execution starts with the client. The most important thing is that a need the client because using the Google API to explain the network connection. All oral examination from the beginning of the first execution by law: confirmation of the human voice (voice recognition). If it is not available, the confirmation process will be completed within that time. Make sure that the steps are executed with the help of the Sphinx4 invention.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The lack of a high frequency of such exposure is bound to help compensate for the various deficiencies lacking access to the target language community or insufficient learning strategy in the set. From the result, it is clear that the accuracy level increases when compared with the existing Algorithm. The needs of the characteristics and teaching practice. Android system and the combination is a multi-media technology is designed, has implemented a practice platform of the pre-course based on the Android mobile phone system. Based on such a system architecture and Android system as a development environment, cloud service platform integration resources. Application environment and analysis tools. It also teaches processes and resources to analyze the side from the Android-based educational applications as an interface for evaluating the interaction method and effect. The system can significantly improve the learning effect and the quality level of the student. In the education system, such use or promotion is believed to be conducive to the cultivation of talent quality. During this period, further, as a specialized profession of universality and the music of such experimental research data, there is a need to explore.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A nonstop significance of remote correspondence, traffic access, and range, you have increasingly more are getting tight, the test of quick regulation characterization is expanded. Balance grouping yet had been an exploration point enough, it is hard to accomplish a high precision from a few examples. Moreover, most strategies are not intended to work at a direct rate with a majority of channels or recurrence groups. The technique for the FPGA execution of the heavenly body graph and profound learning model is applied to tackle this issue. [13]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Some techniques have also been incorporated into the Internet of Things platform to copy digital double of physical assets and use them [3]. Since this is a digital copy of the physical asset numbers double feature, the IoT must consider the platform as a digital communication network seamless data transfer network and physical things. Separation plane network abstraction of low-level functions and programmable network configuration facilitates a higher service [4]. This feature relies on a network configuration to adapt to various network requirements for large-scale things.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Economic mobilization of the wireless communication system causes the broadcast explosion error to occur in a multi-layered fading state in many ways, and band loss is difficult. It is necessary to investigate error series that can provide insights into error patterns or 5\u00ac\u2020G wireless data transfer behavior. This market share concept is that the 5th Generation (5\u00ac\u2020G) cellular systems Internet of Things use will be a powerful inspiration in the future. Device-to-Device (D2D) communication is an essential method of evolving and gaining significant benefits and supports for Markov chain integration. It is possible to effectively increase the 5\u00ac\u2020G network internet requirements for research matters for economic accuracy forecasting. To overcome the issue, proposed the method Economic Probability Agglomeration Based Markov Model (EPAMM). The radio error model 5\u00ac\u2020G wireless communication helps provide a complete understanding of the population process, allowing less complicated predictions and shorter simulation time to control and evaluate error strategies. The error sequences generated from the 5\u00ac\u2020G wireless simulation and the Markov model show that can fully model the error behavior of the 5\u00ac\u2020G simulation using the Markov model.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "All the more explicitly, utilize the to recognize a particular sort of picture players, players having a place with the subset an original classes, subclasses recorded images utilizing just a modest bunch of the competitors[5,6] Movement video scene identification improved Ada boosting Category: removing from the picture information to be perceived. Computer generated reality innovation is a fundamental condition for improvement of augmented reality movement reproduction, after precisely re-enact an assortment of sports to finish this premise [7,8].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20201 VR / AR educational services, a physical network must be represented in cyberspace things, the interoperability of these assets. To do this. A double number is fulfilling all its features of the digital-physical copy. For example, cars, traffic signs, and even physical space can be reflected in CyberMart twins. Things in general services, human regular physical environmental data collection by using their mobile devices in the dual-mode digital VR, physical thing is used, because compared to the state monitoring and management improvements in those material things in general.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20203 the application feature extraction mode contains three design decisions. The inventive aspect of this model gets the best possible element extraction abilities. In the wake of finding the element extraction highlight, it has to figure out which highlight to consider, concluding that the number of extra highlights are included between the accuracy and speed of the trade-off. In extreme cases, the system is \"lossless\" and maintains all functionality. This confirms that there are no false positives. However, it is a type of pattern hunting for a large (functional) space and escaping. At different boundaries, just one component is utilized. For this situation, the quest for corruption in practical space essentially brings everything back. Hence, the quantity of this highlights decides the harmony between include space and post-handling time search time.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "There are more and more developers who want to find and integrate related industry knowledge in software development. Most of the existing professional knowledge referral systems are based on changes in paths stressed the robust features of things in eight research areas, rich discussion, from the vision of a global perspective [1]. The development of mineral resources is for economic and social development, but it will also produce a large amount of waste / tailings that will significantly pollute the environment (spreading around the mine effluents, soil / sediment deposition near water levels, air pollution, etc.). Therefore, large-scale development of waste fines / comprehensive use of tailings to improve the environment and the need for sustainable development of resources a day. [2]. Things announced the reference design of the overall system architecture.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "As for evaluating mobile communication networks, 5G is expected to meet the explosion in demand for communication traffic. In 5G deployment, there are many types of heterogeneous research networks [11]. Sonographers can prevent infection and evasion of personal protective equipment. Quality control can be ensured between the remote consultations by the doctor [12]. The satellite communication system is an integral part of the 5G era wireless network's diversification to provide various important civil and military. However, for all of the method's characteristics and the wireless media of broadcasting, there is a threat of serious security from companies [13].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The whole cycle, the motivation behind making promptly accessible. Will likely have the option to escape practice rapidly. This course can be utilized as a prologue to the fundamental stance of playing out the method or introducing the Cross Fit need course. Running preparing. Upon fruitful fulfillment of the course, will get a Certificate of Completion. A Certified Cross Fit Trainer (CCFT) will get seven days' direction to look after CCFT (L3) qualifications. Prescribe that use Google Chrome to see this course. This cycle can be finished in different meetings. Saved before crafted by the somewhat finished module is finished is suggested that complete the total module during the end cycle.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 3 defines. This examination planned an elite model that robotizes the business' CPU framework creation lines for filtering product offering pictures, calling attention to disparities in their gatherings with a model, and moving data about it to the PC overseer. This permits the item to be designed to change the point.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Things rural internet really supports the vision of a smart village, and its purpose is to use the most advanced communication technology to do village management and value-added services to citizens. Progress and Noise Monitoring, Energy Consumption in the Village, Smart Lighting and Environmental Monitoring Enforcement Technologies, Ethics and Structures Things for Rural Internet Automation. In noise monitoring, energy consumption in the village, smart lighting and environmental monitoring technologies, in implementing protocols and structures in the rural areas of the Things Internet. In addition, project submission and technical solutions and best practice guidelines should be discussed on Smart Travel. In order to determine the impact of the Internet of Things in the tourism industry, a model is proposed to simplify the industry tourist movement to thoroughly explore the tourist experience. Tourism is a wide-ranging industry that includes multiple partners in overall channels. The industry is full of diversity and experience. The trend can be used as a thread to sew together to solve problems of micro and experience and clear and accurate data collection in the tourism industry.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Another examination has zeroed in on the subjective appraisal and investigation of instructive assets and learning assessment. For example, different spots, such as this Q-Edutage scale, plan, in the exacting mental instrument, such social legacy training plans and projects with the quality accreditation of building device as the assessment dissolvable of learning assessment, missing up to now there have started the advancement of the locale. What's more, steady with the Commission's prerequisites, openness and social incorporation is, right now with the entirety of the climate of life, attempting to gain from all the individuals, starting to have an impact through social relic's examination it is and will give special consideration to the variety of human capacity. These examinations give social legacy and efficiency of social legacy training, support, and add to the making of intelligent perplexing and significant vision, legacy, and the connection between the development of ethnicity and personality. Luckily, experience keeps the study hall from the past of items and materials, making it more regularly shrewdly, fruitful. Philips plays out the article distributed in this issue. It underlined that there a too sure appraisal of the progressions that have taken gratitude to the area of these works' proposals, which have been fused in the law.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Game programs are an indispensable part of the broadcast media and reveal the packaging, summarizing the game's most exciting moments. However, it requires labor-intensive video editing [20]. An existing approach that will automatically choose the game's focus games to focus on and show the kind to edit the highlights of golf courses and tennis courts will create a real-world system.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Ideally, any internet in the system of things should get all the relevant documents and sort them in descending order for any user's query. However, many related files have been omitted from the search results, and many files don't have to be usually included. The main reason is that this inconsistency can be attributed to several facts, such as search key translations, search key translation selection morphological analysis, search key ambiguities, and search keys.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Cost-effective for a Machine Learning (ML) application, readily expandable, and independent of the proposed [17]. Work of this article, without having to resort to very expensive in today's market, for researchers and developers that are not looking for a budget-friendly solution for improving the performance of his ML application knowledge of solutions focused on providing an economic platform [18]. One of the most time-consuming steps in the CAD process is a direct problem arrangement affect the completion of the design process [19]. Therefore, the competition of the layout of the accessibility-driven routing to solve this problem. Changes in heterologous in ISPD benchmark properties architectures, and different participant's placers different optimization strategies used by the OK location algorithm for some circuits to fire another [20]. Support Vector Machine (SVM) is a teacher of the machine learning model for the classification task. The data sample has been challenging because of the high computational cost and memory requirements [21].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Because these buildings need power, most of which use highly polluting energy and traditional power plant construction project and significantly contribute to global warming. I will digitally image processing, image processing as a computer, convert into a digital video signal format, and process the reversed digital signal process. This system is a choice Dutch low voltage, low power video decoder chip, a pre-video signal processing powerful chip functions, which is the primary function of an analog-digital converter and its output. The digital video signal is measured to the standard. The four analog signal input port may then be derived from any input port, a Composite Video Broadcast Signal (CVBS), analog preprocessing part output buffer area via the test signal to an analog output AOUT digital luminance signal output port, and a / d conversion and subsequent processing of the color difference signal, another portion of the luminance signal processing, color signal.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Four phases are protected by the RSA algorithm: key creation, key distribution, encryption, and decryption. It needs three enormous positive integers, e, d, and n, where the modular exponentiation is between 0 and n for integers m. It consists of both a public and a private key. Private key by integer d. The message is defined by m. Anything that is used for encrypting messages is provided with the public key. The n and e of the integer are represented by its key; and the.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Comprehensive economic evaluation of investment decision-making process is an urgent need to ensure the accuracy. System dynamics is illustrated as an example of stage performances as a tool artist and is associated with local projects to set up models. Proposed model is mainly based on the model, the simulation of the actual project, focused on the financial evaluation and analysis of the project, the profitability of a comprehensive and dynamic understanding is, get the economic rationality of ability to pay off debt and project it can further the sensitivity of the system is detected to determine the key factors that affect the viability of the model. The most sensitive factor is, in the freight and volume, the model is effective and feasible: it indicates that the result is. An FPGA-based super simulator that is part of the trend of this article, any instrument. This is, Virtex-4 FPGA connected torus 64 Xilinx 2D 32 pieces of the visible CPU set of follows. Our machine is faster more than 100 times, practical Maxwell machine equivalent of the software is than it is possible to make a variety of Monte Carlo imitations. The GARCH (Generalized Autoregressive Conditional Heteroskedasticity) option is, in the context of the price model implementation, has been shown in this paper. To be excellent on the implementation of the equivalent of software that our FPGA-based function is running the same number of workstation clusters of computing terminal according to as the actual hardware features have shown the GARCH model.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "It must be managed by an insurance company that operates to accumulate certain risks. One of the types of risk management and control is reinsurance. The risks associated with reinsurance are as follows: risk of fluctuation, risk of error fluctuations, guessing and rating, subjective risk, and premium delay risk [6]. As the type of reinsurance risk limit, an insurance company (reinsurer) is an insurance company and another insurance company (given) I accept the issue to cover a specific loss or part thereof in the insurance company, it is a transaction under it [7], and risk reduction transfer, insurance the premium will be paid to the reinsurance company.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The first part of the purpose of the extracted program-described history, to understand the current, learn the value of citizenship, using the current major issues of concern, with the positive evaluation of the project's methods and strategies. It is to guide the positive load in between. In this part, saturate the source's use and the negative burden evaluation of the document. In the ninth component, regulation, indicating the load between education resources using a press as an educational resource, research strategy is a complex project. Not only is the information and communication technology beneficial to the primary source. There is a positive load by using the textbook as a resource for this part. Component of the tenth extracts a correlation between the oral sources' evaluation, using teachers' notes, the use of museums and teachers interpret as a methodological strategy.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20205 analysis of the communication process in sec. Internet of Things based Microcontroller Unit (MCU) and Radio Frequency (RF) RF24L01 are connected via the Serial Peripheral Interface (SPI). The SPI interface does not have a single chip micros, the data can be read and written via regular input/output virtual SPI. It is worth noting that the general emitter port must be at a lower level during operation as SPI operations can be performed while waiting.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "To assess the proposed format, previously made a picture information base containing items from the CPU yield line. The order finished utilizing four standard classifiers, and the outcomes were contrasted and the proposed framework. Our information base contains 50 imperfect pictures and 100 deficient pictures. Potential defects are separated utilizing vague picture division and strategy acknowledgment strategies as recently depicted. . Table 1 shows the level of right groupings for recognizing screw abandons. The proposed model can identify screw surrenders, absent or free screws in Figure 4.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Augmented reality components and smart classroom. In previous work, the smart classroom structure that has been defined has been referred to as the sash [5]. The architecture of the sash is based on the agent. Specifically, the sash provides services between them and is defined as an agent for the community.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20203 represents the convolutional layer's most essential function: to use a set of connected neurons to transform the input data from the previous layer. It calculates the dot product of the area of the neuron's input layer and the weight of the local connection of the output layer. This provides the final output volume within this layer. Technology is made possible by a concept called convolution. This layer gradually helps prevent over fitting of the training data and reduces the data representation space's size. They typically mix between continuous convolution layers and user input data that is spatially adjusted by maximal manipulation. It can master the collection layer, and not all parameters are generally required to be zero. This layer acts as the network's output layer, where N has an output volume size of [1\u00ac\u2020\u221a\u00f3\u00ac\u20201xN] where the number of output categories should be evaluated. Layer that is fully connected, it has typical neural network layer parameters and hyper. The layer, different convolution layers, and discussed each statement of importance and usefulness are fully connected neural network convolution pool layers. This ends the part of CNN. In the other chapters of this series, will focus on different varieties. Long-term and short-term memory network has its application in natural language processing and translation.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In the transportation system hub, the bridge, the external force, causes the collapse and damage of a severe bridge. To be weakening, it will be exposed to a long period of harsh environment. Acoustic emission is the internal and transient elastic waves generated by the rapid release of energy from a local source material under external stress. Are used for this kind of non-destructive inspection of the stress wave radiation can have such an effect; it will not replace the other non-destructive inspection method [5].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20201 shows the sea area based remote sensing monitoring operations are currently synchronized with other drones on the network, and all operations are synchronized by condensing the drones. Drone clusters are deployed due to continuous innovation in the field of communications. Due to its great flexibility and mobility, drones are increasingly being deployed for surveillance applications. Despite all these advances, drone clusters are misbehaved when deploying to complex environments. As a result, unmanned aerial vehicles need to develop more sophisticated communication and navigation systems to make them more reliable and secure.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Significant progress has been made in the study of heritage education. A lot of research pointed out that positive methods exist, and using the resources and primary materials in the classroom. At this point, the teacher of experience of observations and the future of history and social science research is assumed to be necessary. Therefore, the value of this study, instead of the people of Spanish and initial training of English teachers, not only the presence or absence of cultural relics and its historic teaching process, on the understanding of the methodology, their own opinions and cultural heritage There in the presence or absence of the use of the existing connection between the classroom. It is quantitative research data collected by the non-experimental descriptions and questionnaires. This survey is a project to analyse the teacher of opinion and opinions of the preliminary training of history education in secondary education. The results show that you are using the teacher's initial training value in the high or very high secondary education in a positive way, classes of critical historical and cultural heritage to promote historical skills development. Training of teacher's heritage Spain value is used than the more highly English teacher. English teacher, but to solve the proportion of Spanish teacher emotions and higher and higher training value in terms of the aspects of the problem's motivation through the past of the literature data. Possible forms of cultural partnership in the education process are working with schools and other institutions. It is a learning process. You need more modern management of the different attitudes to the education process. The ultimate quality of service is that the complexity of the knowledge that leads to the young people of the carrier's future.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20204 shows the process involved in the Field Programmable Gate Array accounting system. Today, low power programmable leader for flexible deployment of support extended temperature operating range has MachXO3D \u201a\u00d1\u00a2 FPGA for applications that durability safe and robust automobile control applications and automotive systems. It announced a new version of MachXO3LF \u201a\u00d1\u00a2 FPGA. MachXO3D FPGA is popular system control functions and hardware root trust flexibility of strengthening the platform firmware the MachXO FPGA architecture the industry's most advanced security features of the Lattice, including (ROT) (PFR), and dual-boot support to ensure. The target control bridge, Advanced Driver Assistance System (ADAS), infotainment systems, motor control, and operate the applications in reliably harsh environments comprise 5G communications infrastructure.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Table 2shows it has been carried out to some experiments to analyze the performance of the proposed segmentation algorithm. The experiment is to the data set, including the X-ray image of fracture and normal bone 50. This can be observed displacements that the pixels to bring a bright image with high content. X-ray bone image, because it has a different strength, need to control the degree of displacement corresponding to the image intensity.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In this system, two cameras are used to provide a complete field, as seen in indoor stadiums. The tracking and circuit of the target horse athlete are shown in Figure 3. As an equipment quickening agent to its different compositional favorable circumstances, including high innate parallelism, adaptability, direct interface and camera performance, low power consumption, and whether it is suitable for streaming media applications and its processing: In this work, the efficiency of computationally intensive work is improved based on FPGA technology and vision system.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The aftereffect of the worth demonstrating opportunity investigation is utilized as the item's enthusiastic level, self-assurance and different attributes. The sight and contact are incredible as far as feel. It additionally has a definite feeling of character. Furthermore, from impact, it likewise has a significant effect on society and culture. As far as quality and size, the items are prevalent in measure guidelines. Be that as it may, the item should be improved in center innovation.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Oxidant non-oxidizing atmosphere is generally used instead is used to perform a thermal process required by the metal-induced crystallization of amorphous silicon [18]. Polycrystalline silicon obtained by the manufacturing thin film transistors show improves the device characteristics.\tRadiation transmission plays a fundamental role in several areas of science and engineering [19]. For some applications in the turbid medium to the polarization effect of light caused by the like such an atmosphere and the ocean, vector radioactive transfer equation for the Scalar Radioactive Transfer Equation (SRTE) must be used instead [20].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "If the vanilla option is calculated as the sample or used as a simple barrier option, the input parameters are known as the price of the goods whose output can be obtained from various sources and are compared to the Heston model. Verification is easy. So many different options are very difficult, as many of our property ban contracts are not easy to verify, there is a market for them to see. These deals are customized on the date of sale to each investor and the available market data will not appear in the feeds. However, they are both roughly defined using identical contracts study solutions.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "\"Students and teachers as the body as leaders\" English lessons refer to new educational models that help students actively learn. Teachers, as resource organizers and participants, are just as crucial in their leading role. They should organize learning resources from the student's perspective and guide students on how to learn. To guide students to other independent learning and impart specialized knowledge and skills in the classroom, teachers also know their subjects and provide them in the classroom and student skills to improve their knowledge.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Public sports services are essential for maintaining social justice. In the era of social change, it is possible to strengthen government functionality in the public service of sports and improve sports services that are conducive to community development health. It has vital project significance. Government role building in the age of sports, public service, and operational change. Public sports services are essential for maintaining social justice. In the era of social change, it is possible to strengthen government functionality in the public service of sports and improve sports services that are conducive to community development health. It has vital project significance. Government role building in the age of sports, public service, and operational change.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "COVID-19 is, broke out in India the severe acute respiratory syndrome coronavirus is a further new coronavirus or COVID-19 is an eruption of powerful and attractive viral respiratory diseases equivalent Prediction take Gander in India, meaning that believe that there is. In China, from the beginning of the scene, a life of solid number, R0. Five different regions. This plan's downside is that it did not use the laser. A laser works at the standard of recreated outflow and chips away at electroluminescence guidelines. Boundaries of dispersed mellow are chosen via the centralization of the residue. The one's boundaries additionally rely upon the width of the residue flotsam and jetsam. The more modest the molecule breadth, the more uniform the conveyance of ahead dispersed and in reverse dissipated, while bigger particles are particularly dispersed ahead. The profundity of dissipated light is corresponding to the attention of particles. To give better granularity of photon indicator and restrict the loss of dispersed light and along these lines, the information roughly the point of view of dissipating utilized a region of ultrasonic sensors. The design standard is delineated.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The data collection method used intelligent English classroom exams to assess the knowledge an English teacher needs a practical English lesson. Also, in-depth interviews, primary portals are conducted to understand how they change among teachers. At the end of the smart English classroom education test, each teacher's correct answer will be calculated separately, and the cumulative score (teacher's real correct answer) will be calculated.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "These skills are hard to master and only develop in the industry for a few years, and Machine learning speeds up investors' learning. Early investors sought to establish a data-based approach to help predict the company's future success and understand the risks [13]. Some insights can be taken from qualitative data, and these results are favorable to the prospects in which the organization is established [14]. A suitable mechanism can inform investors of the conditions under which another machine learning method can be enhanced and tested. Our data set is derived from Crunch Base's platform about the company. Its business information, such as the source of funding, founders, business units, etc., is compressed from the initial and above stages [15].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In-Network applications, as in previous work, some object tracking algorithms have been implemented in rebuilt devices due to the benefits provided by FPGA (Field Programmable Gate Arrays). There is no comparison with running software. A design based on the FPGA (Field Programmable Gate Arrays) soft processor that identifies object tracking based on the average change. However, the maximum size of the tracked object is limited to a few pixels and does not exceed performance. The hardware detection system implemented based on them and they reported the largest speedup compared to running the software. However, there is no tracking in its implementation in ASIC (Application-Specific Integrated Circuit).",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In a real-time system, the work under strict time constraints is used to estimate the emergency. Embedded systems and provides a specific function within a more extensive system. If you have embedded components in the real-time system, it is called real-time embedded systems. In previous work, similar to other industrial markets, oil and gas is to improve the process, is a robust result for full use of the data, and makes decisions on the business based on more information, safety, maintenance, and manage costs. The information that can be managed to collect from various sources is growing at such a fast pace. When almost all aspects of the industry's oil and gas business are digitized, embedded computing solutions, to facilitate data collection of oil and gas, play an essential role in simplification. Here, in this work, an integrated energy system for offshore oil and gas platform that proposed Integrated Energy System (IES) is composed of an Energy Supply System (ESS), it is a complex energy-intensive system, Offshore Oil and Gas Operations (OGPS), Diesel Oil Supply System (DOSS) Oil Storage and Transportation System (OSTS). Among them, shows the trend of strongly coupled to the introduction of new technologies such as ESS and OGPS are closely coupled, such as waste heat recovery and the associated gas utilization. It is considered the best operating model for coupling to reduce operating costs and carbon dioxide emissions.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Another key factor strengthening monetary growth in agricultural countries is progress. Embedded database on the combination of Employment and Entrepreneurship and development, especially in non-industrial countries, is in its infancy, regardless of the agreement that the employer will contribute to a higher level of growth. Development can prompt profitable chains and mechanical changes of greater importance, bringing a wider territory and a better nature of goods and ventures. Employment people stimulate development because they are receptive to new employment areas and see opportunities to make new efforts, elements and administrations.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Convolutional Neural Network to classify a class of objects to predict missing attribute values (automatic) A model (the class may not be known) There is). The model builds a first-step process that describes a set of features for a set of data classes and concepts based on the training dataset. This step is also called supervised learning because the data classes and concepts have definitions of pride sounds (the classes to which the learning samples belong). During the second stage, the model is used to predict future classes of data.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The robot control software is a mobile robot. Install the robot control software on a manually interacting machine, and then use the existing face recognition function to process the robot software so that the robot can recognize the key content of nuclear power. The purpose of software and switches is directly related to the stability, real-time and robustness of human-computer interaction. The artificial intelligence robot control system software is calculated and distributed based on VisualC ++ software. When the robot is operating, the host computer sends control commands through the wireless communication module, and the robot software is used to complete. This includes bit machine communication, machine movement control, and panoramic camera. Control, robot body status inspection, and sensor information fusion processing. By integrating these instructions and related systems into the human-computer interaction of the nuclear power monitoring system, the purpose of artificial intelligence to control the entire process is achieved, and then real-time monitoring of the nuclear power system is achieved the goal .",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Human-computer interaction is an important part of intelligent production now. The industrial application is the design of industrial robots. The development of intelligent machines has made human-computer interaction possible, and its applications are rapidly developing in the industrial and service fields. Due to the development of human interaction, this skill has become popular, and it is no longer the exclusive domain of professional and technical personnel. However, some human-machine interactions still need to be improved, because in these areas, they are also exclusive to professionals, especially in the field of nuclear power monitoring. How to improve their performance, improve their interactivity, and improve their interaction efficiency requires careful study. At present, there is not much research on human-machine interaction of industrial robots, the only ones are only in security and graphical programming. Most of the researches are for service or robots with special tasks. The functions used are only sensor interactions, language interactions and natural interactions. However, the reliability of these studies has yet to be studied. The application of time to life still needs research. Different countries develop and different countries have different researches on the human-machine interaction of industrial machines. Now there are many types of industrial robots because of different countries and research teams. Their research and development directions are different. Although the research functions are basically similar, they are in interactive systems The difference is huge.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Temporal component. Because of changes in the attributes of the foreign substance focus and time, as trademark information during the previous 144 hours, consistently, day, month day, end of the week state and past Choose to ride noticeable all-around quality information. The adjustment in the everyday normal grouping of PM2.5 between stations aotizhongxin_aq of the month in the checking name. The grouping of foreign substances in the business day, was discovered to be higher than the finish of a week ago. It might be because of the huge scope development of individuals and extreme car fumes gas during the business day that has influenced the inescapable on the nature of the air.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Image processing is considered one of the fastest-growing areas of data innovation, and its applications are being developed in a variety of information areas. This is a programming image understanding that forms a central area of the quest for software engineering, and the enthusiasm of the design space driven by image upgrades in mechanical technology and PC vision. The number of streams, the image processing application applied to the information image in the preparation chain, maybe less computationally expensive [15].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Microcontrollers with minimal effort System-on-chip (SoC) incorporated remote organization capacities are the development and dependability regularly utilized in Building Automation System (BAS) for connecting industrial sensors and actuators. Represents a high solution. IoT applications\u201a\u00c4\u00f4 development will accelerate these cheap and powerful devices, and even processes will be accelerated by 5G technology [5,6] in the future. The Internet of Things Technology has raised the degree of attention to intensity framework hardware through enormous scope sensor joint effort and data and correspondence organizations. In this article, communication technology for Low Range (LORA) overhead line state recognition things, low power consumption wide-area interconnection applied research [7,8].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In MANETs, various functional characteristics are mentioned below are very important to provide improved privacy concerns in the network environment [5].1.Authentication: Authentication was that it verifies arguments about the legitimacy of the data source.2.Confidentiality: Confidentiality implies that protected data or systems may only be read or executed by designated individuals or device.3.Integrity: Integrity means information isn't modified or corrupted by unauthorised users.4.Availability: Availability corresponds to the network's capability that provide services where required.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Web search engines are widely used to find small amounts of time and large amounts of data on the Internet. Getting users at least accurate with given queries, but sometimes it is difficult. A dedicated web search provides search results tailored to individual user needs and enhances the user's data based on search results [1]. The reluctance of search engines to disclose personal [2] information to users affects personal web search methods' performance. User options customized web search sample includes a review of confidentiality.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 7 shown as Results of low reconstruction error than genetic algorithm and k-means algorithm listed for Convolutional Neural Network algorithm the data is limited. (i.e., Under-sampling rate) is less than 35 percent. Improved reconstruction as compared with the method proposed in it is more pronounced. The reason for this difference is may be due to Convolutional Neural Network it is more efficient to use the smoothness of the reason correspondence Source of art image.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The Cloud phase of the penetration line conditions to be applied to the prediction infiltration line is dependent on the constant observation information that can be obtained in the future. Mathematical model, the water level about dams store thoughts, repeated over the limit equilibrium limit, the water supply amount, and the expected precipitation [12]. The storage level's predictive ability sets the dam's management personnel's framework and basic problem guarantee.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "User-defined functions to determine how to translate to a physical execution plan. In many cases, the execution model will affect the resource utilization of the execution of parallel tasks. Specifically, the task are interested in overlap (1) the parallel processing computation stage, (2) and a calculated step (3) the data pipeline. Hadoop's contains the distributed file system called Hadoop of, HDFS or fault-tolerant storage system. The file system for managing storage on multiple computers has been referred to as a distributed file system. The amount of data is applied when it is too much for a single machine.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Navigation, blind guidance, elevated road traffic systems, vehicle testing, as well as reading such offers read for themselves in the film, such processes are related to various areas of interest such as text-based image searches. Text recognition is more relevant, valuable information than visual images being divided into text parts by non-textual persons. I.e., they are placed in the correct order. Background interference of different types of text formats is a challenge that affects text extraction [16].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Increasing the water-to-oil ratio in the North Sea oil and gas production makes it possible to stimulate the current oil removal facility's optimization. The current mature way of facilities, meet most of the case, the regulation of the government. However, it has also been observed that it is possible to improve these solutions further. In the present study, to monitor the more accurate oil removal operation, generally cyclone facility that is being monitored in real time, which is used in the offshore oil and gas production, examined the oil removal efficiency [13].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The company model is roughly divided into two subsamples, one for training with 57 companies and the other for testing with 30 companies. Each subsample company suffers well health problems and is divided into two categories. Classification types are based on the risk-based approach to values using the formula in corporate finance expanded black and shoals.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 2: shows the A propulsion control system, including the system administrator, the propulsion controller and the bridge operation panel. Starting of the motor, speed, braking, and press the controller remote controller via the Control Area Network (CAN) bus to realize the safe limits and failure alarm, press line adjustment and change of the controller parameter values via the Ethernet (registered trademark) system manager, and optionally to monitor the operating parameters of the time, and then manipulate the state of the ship the entire electric propulsion system.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 2 shows the proposed system block diagram. Adriano's working trends, working voltage, pin setup and association of sensor HC-SR04 to the microcontroller board may be discovered in the element. A servo engine empowers the sensor's revolution to distinguish the shifting and find them inside one hundred eighty stages. It earrings while there may be a location. Those ultrasonic along the ringer decide the field where the thing is located (no matter whether or not it is near or some distance off). A stepper engine is a brushless Direct Current (DC) electric powered engine that isolates a full revolution into a few equivalent advances. It adjustments over teach of info beats into a characterized boom inside the shaft role. The electromagnets in the sync engine are managed with the aid of an outer driving force circuit. Customer's familiarity together with his/her acclimated face-contacting executed as follows. At the same time, the consumer's hand movements are closer to his/her face carefully. The radar depending on ultrasound, sends a humming clamor as a caution. Because of some specialized issues and asset barriers that might have empowered one to check diverse locations of the radar on % glasses, a few take a look at preserving still executable with the model on the versatile band and a few mechanical assist deliberate headset. A few radar pix demonstrating the acknowledgment of deterrents are regarded. The precision of sufficient stamped development closer to the face is assessed to be 70%. One fascinating idea of the airborne particulates estimations depends on the airborne laser innovation. This idea may be very testing mainly from the purpose of the expansion of the frequency which might be utilized by the airborne laser scanner from closer infrared (0.7 to 1, 4 microns) to quick infrared (1,4 to a few microns) on account that the frequencies of the ones require extraordinary concept (as an example from the motive of water refraction and reflection).",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "It improves quality in image processing, editing through editing, and further application in various applications through expansion, partitioning, feature extraction, and classification. Noise is another problem of the image, which can be reduced by adjusting the brightness, changing the color tone and image enhancements, and sharpening the image. Image segmentation divides the input image into non-overlapping, homogeneous, and connected areas, to ensure that the combination of two spatially adjacent areas is not uniform. Image perception is essential to improve image quality. The weight of the convulsive layer in the fully integrated layer for feature extraction and classification is determined during the training process.(4)yi,j,d={[\u0153\u00e2z\u0153\u00dcx]\u201a\u00e0\u00edxi,j,d>00otherwise",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The system presented here is mainly concerned with the realization and design of a multi-sensory based IoT platform for real-time monitoring of humidity and gas in the entrepreneurial park. The proposed Randomized Data Reinforcement Technique (RDRT) system must monitor and control the IoT device for smart entrepreneurial park conditions with help of FPGA Xilinx software. The device consumption power is very low, and it always supplies power from the system power supply module, and the system structure is shown in Fig.\u00ac\u20202.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The recognizable proof of understudies of dyslexia, planned a screening test, gave humble community primary school understudies to concentrate government and tuition-based schools. Phonological mindfulness, visual preparing, fast naming, and to assess the activity limit, task, and the character acknowledgment composing task, word acknowledgment, to perceive rhyming words, test, English and Malayalam spelling (neighborhood language) contains [7]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Image processing, which is played out some commotion decrease, so as to create a more reasonable example, and to get better outcomes in the normal practice. Middle channel is a non-direct computerized separating strategy, regularly utilized for clamour expulsion. It is broadly utilized in advanced picture handling, in light of the fact that, under specific conditions, it holds the edges while eliminating the estimation of the commotion channel module requires its own uncommon mix of the arranging circuit exemplification. Consolidating circuit is chosen rather than a succession of one to accomplish ideal execution and reaction season of the current application. Each are contrasted with one another from the worth, and the incentive in a mix circuit esteems are arranged in dropping request. The middle worth, which is utilized as the new pixel esteem is put rather than the first pixels, a fifth or moderate components as shown in Fig.\u00ac\u20201.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The industrial system's automatic monitoring deals with FPGA's core controller and the analog wireless sensors designed, developed, and analyzed to implement IoT-based solutions for environmental monitoring. These offer commercial off-the-shelf discrete components that can easily create access to the Internet and use minimal additional hardware and software resources. Analysis of the three implementations revealed that Wi-Fi technologies for monitoring applications could successfully compete with the widely used ZigBee protocol. As expected, wireless networks consume more energy, but they can develop solutions that reduce the total cost of ownership by leveraging existing infrastructure. A Randomized Data Reinforcement Technique (RDRT) is proposed to communicate has also proven effective, and satisfactory results encourage systems development based on this technology. The devices will also make these solutions more attractive by improving the protocol and additional mesh network capabilities. Analysis of the developed system also applies to Wi-Fi technology, which was thought to be for wireless sensors designed to consume less power until recently, with more energy-efficient transmission modules available. This work can be enhanced further by connecting the proximity sensor and various other sensors depending on the industry requirement.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The development of urban and rural integration is an essential issue in the development of our national economy. Urban and rural logistics is essential to support urban and rural economic and social development. The modern development of urban and rural logistics industry has become an essential measure to solve the problem, which is urban and rural economic development. In urban and rural logistics, urban and rural logistics information platforms' construction is the critical link of urban and rural logistics. The integrated development of urban and rural areas is an essential issue for our country's economic development. Distribution of urban and rural areas has always been essential for urban and rural areas' economic development. The logistics industry's social essentialist development in urban and rural areas has become an important measure to solve urban and rural economic development issues. In the logistics, urban and rural-urban areas of logistics information platform and rural construction, this is to accelerate the construction and management of the logistics information platform's urban and rural areas. An essential part of the establishment and improvement of urban and rural distribution information disclosure systems is timely and accurate production for the development of logistics urban and rural areas; it is necessary to provide marketing information service distribution am. Distribution of the city of goods will be one of the main components of the sustainable transportation network in traffic congestion and environmental pollution in urban areas. Urbanization, consumption, and the international competition for a wide range of demand for the products and services of bloom in technology are the distribution of products in the urban areas; it gave an essential priority for the public authorities. The growing demand for the cargo transport process's challenge presents a high flow rate in urban development and life quality.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 1: shows the load variation's multi-frequency characteristics, control strategy formulation filter base, show the HESS (Hybrid Energy Storage System) adjustment. Without proper control strategy, Hess solutions may worse than solutions of a single energy storage system. Proposed HESS (Hybrid Energy Storage System) introduces the existing marine electric propulsion system to interact with the power generation system. To evaluate the interaction of a plurality of power supply, when introducing hybrid energy storage systems, do the model-based analysis. In the study, control has shown that when it is not appropriately coordinated, the correct conclusion to bad interaction with the EMS (Energy Management Strategy) is required, and lead. Although knowledge of propulsion load torque is essential for the proposed system-level EMS (Energy Management Strategy), the load torque is immeasurable for most marine applications.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Table 2 shows the performance weight selected to deflect the tire in the leaving highest frequency roll of the chassis displacement and a constant point. It cannot be modified to change the suspension's damping, and these points are called a constant. Because that is forced to be present on only the negative real axis, it gives the free small degree, and it is impossible to explore the negative s-plane of the whole. Similarly, strict criteria are all true small stable percentage of the area that will be imposed in a non-dominant pole.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Fig.\u00ac\u20201. shows the Mobile wireless communication offers a very wide range of connectivity through mobile devices with very little delay for quick service. That is the influence from 5\u00ac\u2020G is really the main precedent the IoT. The Industrial city has quickened the cycle as rivalry requests that is improve their opposition to expand their creation levels. This will build effectiveness with more advantages for organizations. Notwithstanding picking an improvement area, the organization thinks about outside impacts. Organizations are in this way progressively subject to the development and decision of that area to carry outside monetary advantages with them. Likewise, industry reconciliation, the most significant thing is to pull in more individuals and spare exertion. This has prompted city in other related ventures and improved monetary relations between financial elements in the market space. Also, industry coordination ought to advance modern zones and driving organizations advocating Industrial development information and innovation. Advancement, consequently advancing the development of the territorial economy, is the main thrust of monetary development.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "This solution cannot handle large amounts of data in a very short time to establish a desired multi-core processor. Graphics hardware architecture to solve this problem is useful. Graphics card with multiple cores, and each core hardware support for multiple cores. This exclusive. A graphics card with a frame is used for general purposes, graphics card manufacturer [11] is well known, appears capable of handling a large number of parallel data from the home graphics card 8400 GS. In 2006 architecture developed architecture using C / C ++ language. If the programmer knows how to properly use the architecture, and handle distribution rights can be achieved with very high system performance. Recent studies have specified data rates faster than the CPU to process up to 10 times. If the optimization is not running on the CPU. The program cannot be better than a better CPU program [12] 100 times.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Mountains gently park is decently defiled, living territory, transport area, and the modern area are vigorously tainted, has been polluted. Subsequently, moderately little contamination can likewise be defiled by even precipitation and air contamination soil, in the mountains and numerous plants of the recreation center that has not been debased have been steady with the way that is because of a lot of human action. Water, and squandering the fumes gas and buildup, at last, infiltrate the dirt, will be released from the organization of genuine causative ventures that are incorporated weighty metals into a lot of soil contamination. Fumes gas that contains a ton of weighty metal that has been transmitted from engine vehicles running on the entire vehicle area can be found in enormous amounts. Attributes of substantial metals in the dirt from the five useful zones are acquired from common regions a long way from the group and mechanical regions, and the foundation esteem is viewed as the standard for the ordinary substance of the five components to examine the dirt it is based.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Table\u00ac\u20201 shows the implementation Level for Financial Exchange Rates. Artificial intelligence and complex implanted, continuous changes in the budgetary conversion scale, monetary, are the specific estimation of the conversion standard. After the main period of the example is finished, if the substrate is completed, the force gracefully is associated with the test board, as appeared in similar conduct seen in the PC created.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "While the operating costs of public utilities have decreased within the smart cities of the Internet of things, focus on the sustainability of improving the comfort, maintainability, and quality of service of public resources, it is designed to improve the utilization. In general, the application that the 5G smart City-based can be divided into four categories. Tourism application of Smart City is the first category, which includes the consumer electronics connectivity and ubiquitous electronic health care services to physician's remote patient monitoring help. Utility application is smart water network monitoring, air quality, video-based monitoring, which is the second of the category, including public safety and emergency services. The third category is the industrial machinery of the network in a production environment for typical industrial applications. The last category, Intelligent Transport Systems (ITS), or in general, is a mobile application center.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Deep neural networks, especially in computer vision, in both academia and industry, has attracted a great deal of attention to the performance of several artificial intelligence application of the cause. However, these algorithms are referred to as both the score and the model learning application is a stringent need to calculate [18].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Figure 6 shows the main concern of the proposed algorithm. Removing unwanted portions of the X-ray bone images (background and muscle) is an effective bone region extraction. It uses the fact that the bone of the X-ray image is made up of three main areas. The algorithm will begin to reverse the original image. Thin section inversion, to achieve the following: the background is a bright area, the muscle is darker than the background, bone area, and it will be the darkest. To change the contrast of the image to remove the original image's gray level to provide it easily. Among other techniques, the watershed segmentation and K- means, in many cases, is less efficient than the Fuzzy C- Means.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In today's competitive business environment, companies face the challenge of greater productivity and faster decision making in dealing with significant data issues. Many manufacturing systems are not yet ready to manage big data due to lack of intelligent analytics tools. As more and more software and embedded intelligence industrial products and systems are integrated, forecasting technology can weave together electronic components and unlimited intelligence smart mechanisms. These technologies predict product performance deterioration and are independently managed and optimized product service requirements.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "It takes the progress of some of the technology, Such as energy-efficient communication, sensor nodes, and devices of the remote control to ensure different modules and different smart devices, P\u00ac\u2020+\u00ac\u2020t1Y\u00ac\u2020+\u00ac\u2020T2Y2\u00ac\u2020+\u00ac\u2020Y3T3 interoperability between scalability wireless sensor networks, and reliable communications as fault tolerance you [6]. The second challenge N (X |Y)\u00ac\u2020=\u00ac\u2020(p - t1Y1 is the efficient management of large-scale planning and design data sets. Because of environmental planning and design data, a huge amount of \"considered' big data of the data generated by the real-time planning and design. Big data size is large, and wherein rapid collection and, that various, such as data transmission, such, such as the difficulty of storage, has been associated with several challenges in analysis and visualization. Air, water, soil, and simultaneous planning and design of biological variables, will be able to provide a comprehensive understanding of the changes in the ecosystem. Also, it is very important to build a planning and design system based on remote sensing, in optimum integration of the measured values, and model simulation. With multi-compartment Multi-scale planning and design, the system plays an important role to improve efficiency, management [7].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Geographic video spatial acquired by non-terrestrial land and cameras include the temporal, geographical features. With the widespread use of video capture devices, such as smartphones, but the geographical video clip of the user-generated volume has increased significantly, this growth trend has accelerated rapidly. Such large-scale and the number is increasing, and it has brought a great challenge for efficient video management and query. Most of today's video management and query techniques are based on the extraction of the signal level contents. They will not be able to take advantage of the full video geographic information [12].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Lamentably, the measure of vibration that is remembered for the yield of the outcomes, regardless of whether it proceeds in a consistent state, won't go on without serious consequences. Thinking about the level of an opportunity of the structure with the presentation, the regulator eliminates the consistent state yield swell, which can be utilized to audit the remuneration issue's two patterns. Suppose the proposed method to be a general two-venture calculation involving just direct variable-based math measure for getting regulator boundary [5]. In particular, a discrete-time model of the example unaltered, six for every cycle tests, thermistor controlled arrangement capacitor, and the damping regulator introduction planned dependent on the criticism yield sub-harmonic reverberation. It will be utilized to diminish the contort mode's precariousness to the utilization of an outside fixed capacitor [6].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Sports injuries are usually direct impact and application of force than the body is structurally acceptable, is caused by excessive use. Common injuries, bruises, sprains, strains will include joint injury and nose bleeding. General-Purpose Computation on Graphics Processing Units (GPGPU) is Central Processing Units (CPU) usually using a graphics processing a processing unit a computer graphics calculations Graphics Processing Units (GPU), traditionally the central processing unit run the calculation of processing applications. Dynamic prediction, the patient is assumed to have been exposed to danger at a predictable point in time, has an intuitive representation associated with the estimated probability of the occurrence. The Drawback of the existing method does not give proper sports injury images and calculation. The proposed method of the Binary Support Vector System (BSVS) algorithm is to give the proper classification, result, and prediction.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The information depended on estimations from 15 most unpractised members who performed 3-5 arrangements of 10-12 redundancies on a quarter press in the current examination. The main utilized to extricate key highlights of the pre-prepared information [17, 18], and the removed checked demonstrating procedures. Proficient experts were associated with the assessment and grouping measure by investigating the exhibition recorded on the record.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Performance weight will be selected to deflect the tire in the leaving highest frequency roll of the chassis displacement and a constant point. Such as change the way, cannot be modified with the suspension's damping. These points are called invariable. Chassis acceleration is the frequency response of fixed passive configuration as the applied control algorithm.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In the first pilot project, the students stressed that the basic concept of the hybrid powertrain and function calls, and stack management program runtime, disciplined cloud computing nodes ARM processor software programming skills in C language. Passed this way, students have a deep understanding of driving from the perspective of a programmer hardware interface. If educators want to extend more experiments of the software, the location of these projects, based on existing projects like raspberry pie or the traditional x86 platform is basically a high-performance arm. In support of our FPGA running on the processor does not modify the cloud. In addition, a physical node cloud of exclusive possession of the software to ensure that further studies of student performance. To simplify the hardware-centric engineering student design work, template structure our FPGA cloud nodes.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Field Programmable Gate Arrays (FPGAs) are designed to be implemented by the client or designer through the backfield, so the circuit is called \"Field Programmable\" integrated. Field Programmable Gate Teams (FPGA) is a type of general-purpose, which is implemented in the package. Programmable interoperable logic modules for FPGAs are customized by end users with level programming logic devices. Removes multiple size limits for programmable integration between modules, allowing users to perform hierarchical logic. The Programming Logic Device (PLD) is derived from a two-dimensional logic system. This advanced architecture can currently support thousands of logic systems. And the speed is in the tens of megahertz. Sports training information is a cutting, exploration and examination, advancing the fast improvement of human advancement and a fundamental apparatus of progress. What's more, it lessens work power, yet in addition incredibly improves the work productivity of the populace and makes genuine riches for the network.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Video content technology has been used in sportscasts for the past ten years based on basic knowledge and general ideas, hierarchical content models, trends, and challenges. Content-conscious analysis methods refer to objects [11,12], events, and contextual groups. In each group, the gap between emotion and content excitement should bridge the appropriate strategies.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A recent study has proved its advantages on other computing platforms in programmable Field Programmable Gate Array (FPGA) machine learning applications. The code of machine learning is used in high-level software languages such as Python. The algorithm or high-level synthesis algorithm has a registered transfer level for the synthesis code. C code of the manual translation is, in many cases, specifies that take a long time that need a designer in the design of the hardware. Specialized knowledge. [2].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The large scale financial model, edge to anticipate the month to month normal conversion standard for the following month, choice trees, relapse, has been viewed as a relapse strategy dependent on Artificial Intelligence (AI), including Support Vector Machine (SVM) and linear regression. The model joins homegrown cash flexibly, genuine loan fees, the subsidizes rate, and the most recent month of the month to month normal conversion scale to anticipate the following month of the swapping scale. Bits of perception month to month information from the conversion scale and the dollar have been considered an exact trial model [4].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The FPGA (Field-Programmable Gate Array) type receives arbitrary information from the grid and does not use enough information to use it locally at home. On the other hand, a Type FPGA (Field-Programmable Gate Array) receives information about the entire grid's power consumption and can also use household information. Intuitively, this type should provide better global results because they can access information about the grid's overall utilization. The controller type can only respond to changes in each home's power consumption (usually related to overall grid consumption), which is for optimization purposes. On the other hand, the FPGA (Field-Programmable Gate Array) type controller is straightforward and does not require external communication.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Lung cancer is one of the deadliest diseases leading to a high mortality rate worldwide. Pulmonary diseases-based lung Cancer which is an abnormal growth of cells that can be characterized by a single irregular cell and spread to the entire lungs. Therefore, it is necessary to detect affected area and following application steps are to be adopted to find and cure it in the early stages. Lung cancer is often considered as a key indicator in the diagnosis of obstructive pulmonary disease. In the previous method, SVM (Space Vector Modulation) and STFT (Short-Time Fourier Transform algorithms) were used to process the lung cancer detection based image processing system in which CT (Computerized Tomography) images exhibit less accuracy and less efficiency. The transforming method delivers significantly slower results in processing and the image cannot be verified in advanced risk architecture. This proposed FPGA (Field-Programmable Gate Array) and CNN (Conventional Neural Network) are used to develop image processing and easily interface with data without any complexity. FPGA (Field-Programmable Gate Array) is mainly realized by ASIC (Application-Specific Integrated Circuit). This system accelerates the detection of lung and pulmonary disease detection and can be used as a single-process system or as an integral part of another biomedical image detection system. The image processing system relies on bilateral filtration, edge detection, multi-threshold, image segmentation, morphological image processing, and image labeling to collect lung cancer symptoms according to the neural network and gate array.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "An important module that provides video input and generates frames. Create a video to suit your needs, apply this module to collect the required frame, and then assemble this frame for the next module. Object extraction is one of the most important parts of image recognition because objects are used as input to the extraction process.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Digital technology innovation improves employees' work efficiency and existing business processes, enhances customer experience, and uses digital technology and applications to launch new products and business models. A Field-Programmable Gate Array (FPGA) is used to perform more and more image processing applications. Wherein parallelism of the proposed system hardware is implicit in many image processing tasks in parallel space (data level) and time, which can be utilized (task level). Convolution Neural Network (CNN) is deep learning, is a type of neural network. CNN represents a significant breakthrough in image recognition. They are most commonly used to analyze the visual image and have been used to work behind the scenes in many cases, the image classification. The convolutional neural network represents an exciting method for (Cellular Neural Network) adaptive image processing, to form a standard feed-forward neural network links between the adaptive filter. A two-dimensional cellular neural network, and a non-linear activation function and down-sampling possible, has been formed by one or more layers of the two-dimensional filter. CNN's central performance in the local connection of the translation invariance and space (receptive field). The current convolution network architecture. It will be applied to the actual image processing.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "In recent days, the optimization algorithms have been predominantly applied to social network mining. The optimization algorithms have been successfully applied to several real-world problems. In [11] the genetic algorithm was used to classify spam and non-spam emails. The GA was used in the attribute selection process to select the relevant and necessary features. In conjunction with a multilayer perceptron, the suggested model achieved better performance. In [12], the same problem was improved by incorporating particle swarm optimization (PSO) for feature selection using the classification efficiency and length of the feature subset selected, as the performance metrics. The optimization algorithm has been widely used for the feature selection process [13]. In [14], a binary variant of the bat algorithm was used to distinguish the spam profiles of a Facebook social network. The real data was collected and the J-rip classifier was employed as the classification algorithm. The binary version of the bat algorithm was implemented using the sigmoid transfer function to convert the real values to binary ones. In [15], the author proposed a common approach to detecting spam profiles that apply to both Facebook and Twitter networks. By identifying the common features, the experiment showed that the generic features were as effective as network-specific features. A further study on spam campaign analysis was done using the Markov Clustering method.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Much urban Landscape around Subway Research and Engineering Center topic of another possible classification machine learning applications in the Urban Landscape around Subway design classification is based. The urban landscape of many topics accounts for resilience, dominant ecosystem services discussed, green infrastructure. Table\u00ac\u20201 shows the type of each general classification thematic review study landscape around Subway design, which is limited to considering relevant examples in this study.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The database server used to store and manage the data stored on the server will be provided to the user who is authorized to access the Database. This type of server keeps the data regularly to the center's location that can be backed up. Also, allows users and applications to concentrate on network access to data. The database stores all types of music data on the server.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The intrinsic motivation nature of the wireless Internet of Things ecosystem requires even in harsh conditions, such as lack of guarantee of the system's continuity connected to the network infrastructure. In addition to efforts to provide capillary network coverage (thanks to multi-layer cell structure), the unexpected is the lack of support infrastructure likely to be crowded in a crowded event, the network node fails.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Personal health record, or PHR, the patient, private security, and confidentiality of their health information in the environment (and the authorization of others) to maintain, can be managed through the electronic application. Generally speaking, PHR is controlled by an individual to access information. To track, it is an electronic record of health information of individuals who do not need to participate in the health management function. PHR should not be confused with electronic medical records.",
            "prediction": "Most likely AI-generated",
            "source": "Generated"
        },
        {
            "abs": "Compared to the usual research strategy, the system's overall outline simplifies the process. The voting can be completed quickly for data transfer, and the information can be obtained at a lower cost and directly on the computer. Imaginary education is a significant method of combining high quality with innovative gifts to expand, expand and value training, development. By experimenting with creative training strategies, it can promote sports coaching thinking to improve their ideas, change jobs, and improve visual quality and efficiency, but alternatively free reasoning, mental, moral inquiries, and continuing to improve the educational environment, help understudies technology, proper configuration And slip to learn sports respect development. The reason is that school sports science research promotes cutting-edge sports education development to strengthen and reference existing assumptions.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Traditional financial management software generally uses passwords to ensure that different users have different passwords. Assume this type of password verification method can be used consistently. That is, password maintenance uses a lot of skills and resources for Internet users, [20] followed by an increasing number of applications. Most importantly, this model [21] helps urge local government leaders, businesses, and even everyone to establish a good atmosphere and credit culture and improve their competitiveness and competence in attractive areas.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "This article's motivation is to discover the understudy business and work advancement model, given the proper characterization, to apply an alternate arrangement. The execution of the J48 calculation discovered to prune the choice tree calculation of WEKA is the best business possibilities. Understudies with the venture and improved or broadened stress the executive's aptitudes, he is, has been received regardless of whether related work experience. Sympathetic understudies, to share his insight, the presentation to turn the horn, his delicate aptitudes, for example, influential capacity and correspondence help different understudies will show the individual. Moreover, his/her quality lets the individuals from the group searched after by the vast majority of the business. The components that influence this article's work, at that point, it is applied for, looked at an assortment of classes. The impact of the set up enthusiastic aptitudes of boundaries in a few situations real to form to someone else doesn't show much impact.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Reenactment and exploratory outcomes, the sensor lattice configuration has appeared to improve the recreation quality. In particular, the proposed strategy improves picture quality up to contrasted with the condition of the earlier workmanship detecting network plan. Also, the quick multi-goal recreation strategy depends on a plan framework that lessens 3-digit calculation time and doesn't need an iterative cycle [6]. To all the more likely adapt to the issues of loss of the slope in the exceptionally profound organization, it presents can advance present moment and long haul associations in it data starting organization between successful on various layers. A large number of the analyses were performed on a few sorts of clinical clamor pictures, for example, registered tomography and ultrasound pictures, and the proposed technique is better than the cutting edge strategy for demising [7]. In the proposed technique, the source picture is decayed by NSST to get first their multi-scale and multi-directional whole portrayal. The high recurrence band is combined with a neural organization model in which all boundaries melded by the versatile boundary heartbeat can be assessed from the versatile information band. The low-recurrence groups are converged simultaneously by clinical picture combination, another procedure that tackles two significant issues: energy preservation and definite extraction [8]. The picture defocuses rectification convolution is proposed, sifting the one-shot structure, with the regular foundation picture obscuring reclamation straightforwardly tangled novel plan. The optical haze issue is that many imaging applications experience the ill effects of a typical downside of the optical deformity.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The sensor fundamentally incorporates an infrared light source, a LED (Light Emitting Diode), an infrared phototransistor, and its identification procedure. In this process, it is revealed that the phototransistor reflects the infrared light emitted toward the finger at different intensities due to the difference in blood flow due to reflection from the vein. This detected signal is sent to a low-cost microcontroller, purified, and then appropriately amplified. The microcontroller tallies the absolute number of pulsates during a specific time stretch to deliver a proportion of the patient's heart. Regular breaks down performed depend on the recognized time stretches at which the appraisals are approximated by figuring intend to give a precise evaluation of the heart proportion.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Excellent design leads to useful information. In landscape design, designers are more concerned about how the plans will affect the city than choose their plans. The organization also explores the basics of an urban theme park IOT and GIS-based landscape design system [8]. Next, as an example, take an abandoned mining area in Beijing. The author divides the landscape regeneration area of MTG based on GIS. Necessary landscape units and structures were discovered to verify and restore the proper functioning of each unit. [9]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "The despite shrinking arable land but should focus on smarter, better and more productive harvest technology development to meet all the agriculture needs of a growing population is necessary. Now immediately observed improvements and new technologies to improve yields of Innovation is divided, creative and individuals followed the harvest of development, well-being and nutrition. Farming is a way to eliminate the derivatives mark, the link between producers, suppliers, retailers and buyers. Into account all these angles and made some innovative innovations, especially in 5G wireless sensors, overall Economic based Agriculture Performance is best in 80%. To make agriculture more sensitive and skilled to meet future needs. Therefore, consider innovative remote sensors, cloud and communications. Besides it gives a better understanding of the ongoing exploration work\u201a\u00c4\u00eefurthermore, a variety of things based on the model and stage agribusiness applications.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A new method of material distribution in the layout and indoor scenes of automatic furniture has been proposed. The most advanced advantage of this method is that our system can automatically add furniture objects to the room. The addition of this object has been realized as a mutation of interior design in our new genetic algorithm. In many cases, the communication process leaves room for confusion. Even if the designer and the client is properly express their vision, the opportunity to imagine that does not know completely how the object it is work there is always concert. The cost function, which is formed by a set of extensions to the interior design criteria that have been proposed, has been implemented. This cost function, consistent, shows that it is optimized by a genetic algorithm that leads to livable interior design. Finally, our method, the internal design proposal that is close to having been created by professional designers for a manual in certain scenarios, can be created from our perception research results.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Depending on user preferences, it allows users to take the initiative to vote for search results and update the [21] user model automatically and dynamically. The current state of the art model only takes query-only relevant considerations to provide recommendations. What differs from these close models is the need to consider personalized and differentiated results [22].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Not just the scholastic execution of understudies, not just the notoriety of budgetary organizations, dropout rate, maintenance, and because it decides the students. Discovered that training and work in information mining have zeroed in on work in enormous amounts\u201a\u00c4\u00eethe utilization of execution forecast of an alternate arrangement of traits and diverse mining calculation [7,8].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Concerning the development of hardware and software development, today is the amateur level in this technology. Then the above refer to the different analytical techniques have under the same conditions. Worldwide very expensive video-based position tracking system for outdoor training sports, some of the team's top course will use for their gameplay analysis and system for analysis.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Snow and ice-based image recognition is a direct comparative upgrade of the other three basic administration tasks that are needed to achieve the greatest effect. The player's shot changed the hooks' ticking sound a lot. This deformity reconstructs the clumsy three-dimensional shape of the stick during player movement and is used to study the hockey shape and plays a dynamic role in determining the hockey puck's flight. Shot put has an important purpose because it fits the style of the player. Rebuild the system and automatically convert to a new low-cost portable player lens to capture. The efficiency of the neural network method, lets us consider the legitimacy of metric expressions when the look of divergence. The diminutive maxim suggests that an article and the intimacy between it are the same for all articles.",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Budgetary profundity, government, and the private area to help get adequate assets without huge changes in resource costs and the conversion standard to build the money's intensity have been perceived observationally. The conversion standard's vulnerability is viewed as one of the numerous components that influence the money-related market execution [17].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "A Deep Neural Network (DNN) has gained critical ground as of late. New DNN technique, activities, for example, picture or voice acknowledgment effectively and is productively done, if and as important to locate a viable trademark amount and calculations, permits the correlation with past strategies. Be that as it may, regularly it is the significant length and elite figuring assets of time devoured by DNN count. To encourage quick article acknowledgment, this presents a Deep Convolution Neural Network (DCNN) quickening agent dependent on a field-programmable gate array (FPGA). [9]",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        },
        {
            "abs": "Take a challenge and time to develop new or improved optimization reasoning for a computer-aided design that relies on empirical experiments and research experience tools. In the present, that examined whether it could be improved using Reinforcement Learning (RL). This process is to learn practical and adaptive rules of thumb. With the position of the Field-Programmable Gate Array (FPGA), and application of these technologies, it will achieve better runtime and quality trade-off; our enhancement algorithm is superior to the standard placer indicated [18].",
            "prediction": "Most likely human-generated",
            "source": "Generated"
        }
    ]
}