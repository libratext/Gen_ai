[
    {
        "abs": "In this report, we describe a Theano-based AlexNet (Krizhevsky et al., 2012)\nimplementation and its naive data parallelism on multiple GPUs. Our performance\non 2 GPUs is comparable with the state-of-art Caffe library (Jia et al., 2014)\nrun on 1 GPU. To the best of our knowledge, this is the first open-source\nPython-based AlexNet implementation to-date.",
        "title": "Theano-based Large-Scale Visual Recognition with Multiple GPUs"
    },
    {
        "abs": "We show that deep narrow Boltzmann machines are universal approximators of\nprobability distributions on the activities of their visible units, provided\nthey have sufficiently many hidden layers, each containing the same number of\nunits as the visible layer. We show that, within certain parameter domains,\ndeep Boltzmann machines can be studied as feedforward networks. We provide\nupper and lower bounds on the sufficient depth and width of universal\napproximators. These results settle various intuitions regarding undirected\nnetworks and, in particular, they show that deep narrow Boltzmann machines are\nat least as compact universal approximators as narrow sigmoid belief networks\nand restricted Boltzmann machines, with respect to the currently available\nbounds for those models.",
        "title": "Deep Narrow Boltzmann Machines are Universal Approximators"
    },
    {
        "abs": "Leveraging advances in variational inference, we propose to enhance recurrent\nneural networks with latent variables, resulting in Stochastic Recurrent\nNetworks (STORNs). The model i) can be trained with stochastic gradient\nmethods, ii) allows structured and multi-modal conditionals at each time step,\niii) features a reliable estimator of the marginal likelihood and iv) is a\ngeneralisation of deterministic recurrent neural networks. We evaluate the\nmethod on four polyphonic musical data sets and motion capture data.",
        "title": "Learning Stochastic Recurrent Networks"
    },
    {
        "abs": "We describe a general framework for online adaptation of optimization\nhyperparameters by `hot swapping' their values during learning. We investigate\nthis approach in the context of adaptive learning rate selection using an\nexplore-exploit strategy from the multi-armed bandit literature. Experiments on\na benchmark neural network show that the hot swapping approach leads to\nconsistently better solutions compared to well-known alternatives such as\nAdaDelta and stochastic gradient with exhaustive hyperparameter search.",
        "title": "Hot Swapping for Online Adaptation of Optimization Hyperparameters"
    },
    {
        "abs": "Many modern multiclass and multilabel problems are characterized by\nincreasingly large output spaces. For these problems, label embeddings have\nbeen shown to be a useful primitive that can improve computational and\nstatistical efficiency. In this work we utilize a correspondence between rank\nconstrained estimation and low dimensional label embeddings that uncovers a\nfast label embedding algorithm which works in both the multiclass and\nmultilabel settings. The result is a randomized algorithm for partial least\nsquares, whose running time is exponentially faster than naive algorithms. We\ndemonstrate our techniques on two large-scale public datasets, from the Large\nScale Hierarchical Text Challenge and the Open Directory Project, where we\nobtain state of the art results.",
        "title": "Fast Label Embeddings for Extremely Large Output Spaces"
    },
    {
        "abs": "Accurate representational learning of both the explicit and implicit\nrelationships within data is critical to the ability of machines to perform\nmore complex and abstract reasoning tasks. We describe the efficient weakly\nsupervised learning of such inferences by our Dynamic Adaptive Network\nIntelligence (DANI) model. We report state-of-the-art results for DANI over\nquestion answering tasks in the bAbI dataset that have proved difficult for\ncontemporary approaches to learning representation (Weston et al., 2015).",
        "title": "Dynamic Adaptive Network Intelligence"
    },
    {
        "abs": "Automatic speech recognition systems usually rely on spectral-based features,\nsuch as MFCC of PLP. These features are extracted based on prior knowledge such\nas, speech perception or/and speech production. Recently, convolutional neural\nnetworks have been shown to be able to estimate phoneme conditional\nprobabilities in a completely data-driven manner, i.e. using directly temporal\nraw speech signal as input. This system was shown to yield similar or better\nperformance than HMM/ANN based system on phoneme recognition task and on large\nscale continuous speech recognition task, using less parameters. Motivated by\nthese studies, we investigate the use of simple linear classifier in the\nCNN-based framework. Thus, the network learns linearly separable features from\nraw speech. We show that such system yields similar or better performance than\nMLP based system using cepstral-based features as input.",
        "title": "Learning linearly separable features for speech recognition using convolutional neural networks"
    },
    {
        "abs": "We describe the neural-network training framework used in the Kaldi speech\nrecognition toolkit, which is geared towards training DNNs with large amounts\nof training data using multiple GPU-equipped or multi-core machines. In order\nto be as hardware-agnostic as possible, we needed a way to use multiple\nmachines without generating excessive network traffic. Our method is to average\nthe neural network parameters periodically (typically every minute or two), and\nredistribute the averaged parameters to the machines for further training. Each\nmachine sees different data. By itself, this method does not work very well.\nHowever, we have another method, an approximate and efficient implementation of\nNatural Gradient for Stochastic Gradient Descent (NG-SGD), which seems to allow\nour periodic-averaging method to work well, as well as substantially improving\nthe convergence of SGD on a single machine.",
        "title": "Parallel training of DNNs with Natural Gradient and Parameter Averaging"
    },
    {
        "abs": "We develop a new method for visualizing and refining the invariances of\nlearned representations. Specifically, we test for a general form of\ninvariance, linearization, in which the action of a transformation is confined\nto a low-dimensional subspace. Given two reference images (typically, differing\nby some transformation), we synthesize a sequence of images lying on a path\nbetween them that is of minimal length in the space of the representation (a\n\"representational geodesic\"). If the transformation relating the two reference\nimages is linearized by the representation, this sequence should follow the\ngradual evolution of this transformation. We use this method to assess the\ninvariance properties of a state-of-the-art image classification network and\nfind that geodesics generated for image pairs differing by translation,\nrotation, and dilation do not evolve according to their associated\ntransformations. Our method also suggests a remedy for these failures, and\nfollowing this prescription, we show that the modified representation is able\nto linearize a variety of geometric image transformations.",
        "title": "Geodesics of learned representations"
    },
    {
        "abs": "Why does Deep Learning work? What representations does it capture? How do\nhigher-order representations emerge? We study these questions from the\nperspective of group theory, thereby opening a new approach towards a theory of\nDeep learning.\n  One factor behind the recent resurgence of the subject is a key algorithmic\nstep called {\\em pretraining}: first search for a good generative model for the\ninput samples, and repeat the process one layer at a time. We show deeper\nimplications of this simple principle, by establishing a connection with the\ninterplay of orbits and stabilizers of group actions. Although the neural\nnetworks themselves may not form groups, we show the existence of {\\em shadow}\ngroups whose elements serve as close approximations.\n  Over the shadow groups, the pre-training step, originally introduced as a\nmechanism to better initialize a network, becomes equivalent to a search for\nfeatures with minimal orbits. Intuitively, these features are in a way the {\\em\nsimplest}. Which explains why a deep learning network learns simple features\nfirst. Next, we show how the same principle, when repeated in the deeper\nlayers, can capture higher order representations, and why representation\ncomplexity increases as the layers get deeper.",
        "title": "A Group Theoretic Perspective on Unsupervised Deep Learning"
    },
    {
        "abs": "We present a novel architecture, the \"stacked what-where auto-encoders\"\n(SWWAE), which integrates discriminative and generative pathways and provides a\nunified approach to supervised, semi-supervised and unsupervised learning\nwithout relying on sampling during training. An instantiation of SWWAE uses a\nconvolutional net (Convnet) (LeCun et al. (1998)) to encode the input, and\nemploys a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce the\nreconstruction. The objective function includes reconstruction terms that\ninduce the hidden states in the Deconvnet to be similar to those of the\nConvnet. Each pooling layer produces two sets of variables: the \"what\" which\nare fed to the next layer, and its complementary variable \"where\" that are fed\nto the corresponding layer in the generative decoder.",
        "title": "Stacked What-Where Auto-encoders"
    },
    {
        "abs": "We investigate the problem of inducing word embeddings that are tailored for\na particular bilexical relation. Our learning algorithm takes an existing\nlexical vector space and compresses it such that the resulting word embeddings\nare good predictors for a target bilexical relation. In experiments we show\nthat task-specific embeddings can benefit both the quality and efficiency in\nlexical prediction tasks.",
        "title": "Tailoring Word Embeddings for Bilexical Predictions: An Experimental Comparison"
    },
    {
        "abs": "A generative model is developed for deep (multi-layered) convolutional\ndictionary learning. A novel probabilistic pooling operation is integrated into\nthe deep model, yielding efficient bottom-up (pretraining) and top-down\n(refinement) probabilistic learning. Experimental results demonstrate powerful\ncapabilities of the model to learn multi-layer features from images, and\nexcellent classification results are obtained on the MNIST and Caltech 101\ndatasets.",
        "title": "A Generative Model for Deep Convolutional Learning"
    },
    {
        "abs": "Motivated by the recent progress in generative models, we introduce a model\nthat generates images from natural language descriptions. The proposed model\niteratively draws patches on a canvas, while attending to the relevant words in\nthe description. After training on Microsoft COCO, we compare our model with\nseveral baseline generative models on image generation and retrieval tasks. We\ndemonstrate that our model produces higher quality samples than other\napproaches and generates images with novel scene compositions corresponding to\npreviously unseen captions in the dataset.",
        "title": "Generating Images from Captions with Attention"
    },
    {
        "abs": "Convolutional neural networks (CNNs) work well on large datasets. But\nlabelled data is hard to collect, and in some applications larger amounts of\ndata are not available. The problem then is how to use CNNs with small data --\nas CNNs overfit quickly. We present an efficient Bayesian CNN, offering better\nrobustness to over-fitting on small data than traditional approaches. This is\nby placing a probability distribution over the CNN's kernels. We approximate\nour model's intractable posterior with Bernoulli variational distributions,\nrequiring no additional model parameters.\n  On the theoretical side, we cast dropout network training as approximate\ninference in Bayesian neural networks. This allows us to implement our model\nusing existing tools in deep learning with no increase in time complexity,\nwhile highlighting a negative result in the field. We show a considerable\nimprovement in classification accuracy compared to standard techniques and\nimprove on published state-of-the-art results for CIFAR-10.",
        "title": "Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference"
    },
    {
        "abs": "We propose a new method for creating computationally efficient convolutional\nneural networks (CNNs) by using low-rank representations of convolutional\nfilters. Rather than approximating filters in previously-trained networks with\nmore efficient versions, we learn a set of small basis filters from scratch;\nduring training, the network learns to combine these basis filters into more\ncomplex filters that are discriminative for image classification. To train such\nnetworks, a novel weight initialization scheme is used. This allows effective\ninitialization of connection weights in convolutional layers composed of groups\nof differently-shaped filters. We validate our approach by applying it to\nseveral existing CNN architectures and training these networks from scratch\nusing the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or\nhigher accuracy than conventional CNNs with much less compute. Applying our\nmethod to an improved version of VGG-11 network using global max-pooling, we\nachieve comparable validation accuracy using 41% less compute and only 24% of\nthe original VGG-11 model parameters; another variant of our method gives a 1\npercentage point increase in accuracy over our improved VGG-11 model, giving a\ntop-5 center-crop validation accuracy of 89.7% while reducing computation by\n16% relative to the original VGG-11 model. Applying our method to the GoogLeNet\narchitecture for ILSVRC, we achieved comparable accuracy with 26% less compute\nand 41% fewer model parameters. Applying our method to a near state-of-the-art\nnetwork for CIFAR, we achieved comparable accuracy with 46% less compute and\n55% fewer parameters.",
        "title": "Training CNNs with Low-Rank Filters for Efficient Image Classification"
    },
    {
        "abs": "Distributed representations of words have boosted the performance of many\nNatural Language Processing tasks. However, usually only one representation per\nword is obtained, not acknowledging the fact that some words have multiple\nmeanings. This has a negative effect on the individual word representations and\nthe language model as a whole. In this paper we present a simple model that\nenables recent techniques for building word vectors to represent distinct\nsenses of polysemic words. In our assessment of this model we show that it is\nable to effectively discriminate between words' senses and to do so in a\ncomputationally efficient manner.",
        "title": "A Simple and Efficient Method To Generate Word Sense Representations"
    },
    {
        "abs": "We propose Diverse Embedding Neural Network (DENN), a novel architecture for\nlanguage models (LMs). A DENNLM projects the input word history vector onto\nmultiple diverse low-dimensional sub-spaces instead of a single\nhigher-dimensional sub-space as in conventional feed-forward neural network\nLMs. We encourage these sub-spaces to be diverse during network training\nthrough an augmented loss function. Our language modeling experiments on the\nPenn Treebank data set show the performance benefit of using a DENNLM.",
        "title": "Diverse Embedding Neural Network Language Models"
    },
    {
        "abs": "A standard approach to Collaborative Filtering (CF), i.e. prediction of user\nratings on items, relies on Matrix Factorization techniques. Representations\nfor both users and items are computed from the observed ratings and used for\nprediction. Unfortunatly, these transductive approaches cannot handle the case\nof new users arriving in the system, with no known rating, a problem known as\nuser cold-start. A common approach in this context is to ask these incoming\nusers for a few initialization ratings. This paper presents a model to tackle\nthis twofold problem of (i) finding good questions to ask, (ii) building\nefficient representations from this small amount of information. The model can\nalso be used in a more standard (warm) context. Our approach is evaluated on\nthe classical CF problem and on the cold-start problem on four different\ndatasets showing its ability to improve baseline performance in both cases.",
        "title": "Representation Learning for cold-start recommendation"
    },
    {
        "abs": "We propose a deep learning framework for modeling complex high-dimensional\ndensities called Non-linear Independent Component Estimation (NICE). It is\nbased on the idea that a good representation is one in which the data has a\ndistribution that is easy to model. For this purpose, a non-linear\ndeterministic transformation of the data is learned that maps it to a latent\nspace so as to make the transformed data conform to a factorized distribution,\ni.e., resulting in independent latent variables. We parametrize this\ntransformation so that computing the Jacobian determinant and inverse transform\nis trivial, yet we maintain the ability to learn complex non-linear\ntransformations, via a composition of simple building blocks, each based on a\ndeep neural network. The training criterion is simply the exact log-likelihood,\nwhich is tractable. Unbiased ancestral sampling is also easy. We show that this\napproach yields good generative models on four image datasets and can be used\nfor inpainting.",
        "title": "NICE: Non-linear Independent Components Estimation"
    },
    {
        "abs": "We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns\nlinearly separable latent representations in an end-to-end fashion. Classic LDA\nextracts features which preserve class separability and is used for\ndimensionality reduction for many classification problems. The central idea of\nthis paper is to put LDA on top of a deep neural network. This can be seen as a\nnon-linear extension of classic LDA. Instead of maximizing the likelihood of\ntarget labels for individual samples, we propose an objective function that\npushes the network to produce feature distributions which: (a) have low\nvariance within the same class and (b) high variance between different classes.\nOur objective is derived from the general LDA eigenvalue problem and still\nallows to train with stochastic gradient descent and back-propagation. For\nevaluation we test our approach on three different benchmark datasets (MNIST,\nCIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and\nCIFAR-10 and outperforms a network trained with categorical cross entropy (same\narchitecture) on a supervised setting of STL-10.",
        "title": "Deep Linear Discriminant Analysis"
    },
    {
        "abs": "Layer-sequential unit-variance (LSUV) initialization - a simple method for\nweight initialization for deep net learning - is proposed. The method consists\nof the two steps. First, pre-initialize weights of each convolution or\ninner-product layer with orthonormal matrices. Second, proceed from the first\nto the final layer, normalizing the variance of the output of each layer to be\nequal to one.\n  Experiment with different activation functions (maxout, ReLU-family, tanh)\nshow that the proposed initialization leads to learning of very deep nets that\n(i) produces networks with test accuracy better or equal to standard methods\nand (ii) is at least as fast as the complex schemes proposed specifically for\nvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava\net al. (2015)).\n  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets\nand the state-of-the-art, or very close to it, is achieved on the MNIST,\nCIFAR-10/100 and ImageNet datasets.",
        "title": "All you need is a good init"
    },
    {
        "abs": "We introduce a parametric nonlinear transformation that is well-suited for\nGaussianizing data from natural images. The data are linearly transformed, and\neach component is then normalized by a pooled activity measure, computed by\nexponentiating a weighted sum of rectified and exponentiated components and a\nconstant. We optimize the parameters of the full transformation (linear\ntransform, exponents, weights, constant) over a database of natural images,\ndirectly minimizing the negentropy of the responses. The optimized\ntransformation substantially Gaussianizes the data, achieving a significantly\nsmaller mutual information between transformed components than alternative\nmethods including ICA and radial Gaussianization. The transformation is\ndifferentiable and can be efficiently inverted, and thus induces a density\nmodel on images. We show that samples of this model are visually similar to\nsamples of natural image patches. We demonstrate the use of the model as a\nprior probability density that can be used to remove additive noise. Finally,\nwe show that the transformation can be cascaded, with each layer optimized\nusing the same Gaussianization objective, thus offering an unsupervised method\nof optimizing a deep network architecture.",
        "title": "Density Modeling of Images using a Generalized Normalization Transformation"
    },
    {
        "abs": "We present flattened convolutional neural networks that are designed for fast\nfeedforward execution. The redundancy of the parameters, especially weights of\nthe convolutional filters in convolutional neural networks has been extensively\nstudied and different heuristics have been proposed to construct a low rank\nbasis of the filters after training. In this work, we train flattened networks\nthat consist of consecutive sequence of one-dimensional filters across all\ndirections in 3D space to obtain comparable performance as conventional\nconvolutional networks. We tested flattened model on different datasets and\nfound that the flattened layer can effectively substitute for the 3D filters\nwithout loss of accuracy. The flattened convolution pipelines provide around\ntwo times speed-up during feedforward pass compared to the baseline model due\nto the significant reduction of learning parameters. Furthermore, the proposed\nmethod does not require efforts in manual tuning or post processing once the\nmodel is trained.",
        "title": "Flattened Convolutional Neural Networks for Feedforward Acceleration"
    },
    {
        "abs": "In this paper, we introduce a novel deep learning framework, termed Purine.\nIn Purine, a deep network is expressed as a bipartite graph (bi-graph), which\nis composed of interconnected operators and data tensors. With the bi-graph\nabstraction, networks are easily solvable with event-driven task dispatcher. We\nthen demonstrate that different parallelism schemes over GPUs and/or CPUs on\nsingle or multiple PCs can be universally implemented by graph composition.\nThis eases researchers from coding for various parallelization schemes, and the\nsame dispatcher can be used for solving variant graphs. Scheduled by the task\ndispatcher, memory transfers are fully overlapped with other computations,\nwhich greatly reduce the communication overhead and help us achieve approximate\nlinear acceleration.",
        "title": "Purine: A bi-graph based deep learning framework"
    },
    {
        "abs": "In this paper we propose a model that combines the strengths of RNNs and\nSGVB: the Variational Recurrent Auto-Encoder (VRAE). Such a model can be used\nfor efficient, large scale unsupervised learning on time series data, mapping\nthe time series data to a latent vector representation. The model is\ngenerative, such that data can be generated from samples of the latent space.\nAn important contribution of this work is that the model can make use of\nunlabeled data in order to facilitate supervised training of RNNs by\ninitialising the weights and network state.",
        "title": "Variational Recurrent Auto-Encoders"
    },
    {
        "abs": "Current work in lexical distributed representations maps each word to a point\nvector in low-dimensional space. Mapping instead to a density provides many\ninteresting advantages, including better capturing uncertainty about a\nrepresentation and its relationships, expressing asymmetries more naturally\nthan dot product or cosine similarity, and enabling more expressive\nparameterization of decision boundaries. This paper advocates for density-based\ndistributed embeddings and presents a method for learning representations in\nthe space of Gaussian distributions. We compare performance on various word\nembedding benchmarks, investigate the ability of these embeddings to model\nentailment and other asymmetric relationships, and explore novel properties of\nthe representation.",
        "title": "Word Representations via Gaussian Embedding"
    },
    {
        "abs": "Multipliers are the most space and power-hungry arithmetic operators of the\ndigital implementation of deep neural networks. We train a set of\nstate-of-the-art neural networks (Maxout networks) on three benchmark datasets:\nMNIST, CIFAR-10 and SVHN. They are trained with three distinct formats:\nfloating point, fixed point and dynamic fixed point. For each of those datasets\nand for each of those formats, we assess the impact of the precision of the\nmultiplications on the final error after training. We find that very low\nprecision is sufficient not just for running trained networks but also for\ntraining them. For example, it is possible to train Maxout networks with 10\nbits multiplications.",
        "title": "Training deep neural networks with low precision multiplications"
    },
    {
        "abs": "Multiple instance learning (MIL) can reduce the need for costly annotation in\ntasks such as semantic segmentation by weakening the required degree of\nsupervision. We propose a novel MIL formulation of multi-class semantic\nsegmentation learning by a fully convolutional network. In this setting, we\nseek to learn a semantic segmentation model from just weak image-level labels.\nThe model is trained end-to-end to jointly optimize the representation while\ndisambiguating the pixel-image label assignment. Fully convolutional training\naccepts inputs of any size, does not need object proposal pre-processing, and\noffers a pixelwise loss map for selecting latent instances. Our multi-class MIL\nloss exploits the further supervision given by images with multiple labels. We\nevaluate this approach through preliminary experiments on the PASCAL VOC\nsegmentation challenge.",
        "title": "Fully Convolutional Multi-Class Multiple Instance Learning"
    },
    {
        "abs": "Recently, nested dropout was proposed as a method for ordering representation\nunits in autoencoders by their information content, without diminishing\nreconstruction cost. However, it has only been applied to training\nfully-connected autoencoders in an unsupervised setting. We explore the impact\nof nested dropout on the convolutional layers in a CNN trained by\nbackpropagation, investigating whether nested dropout can provide a simple and\nsystematic way to determine the optimal representation size with respect to the\ndesired accuracy and desired task and data complexity.",
        "title": "Learning Compact Convolutional Neural Networks with Nested Dropout"
    },
    {
        "abs": "Stochastic gradient algorithms have been the main focus of large-scale\nlearning problems and they led to important successes in machine learning. The\nconvergence of SGD depends on the careful choice of learning rate and the\namount of the noise in stochastic estimates of the gradients. In this paper, we\npropose a new adaptive learning rate algorithm, which utilizes curvature\ninformation for automatically tuning the learning rates. The information about\nthe element-wise curvature of the loss function is estimated from the local\nstatistics of the stochastic first order gradients. We further propose a new\nvariance reduction technique to speed up the convergence. In our preliminary\nexperiments with deep neural networks, we obtained better performance compared\nto the popular stochastic gradient algorithms.",
        "title": "ADASECANT: Robust Adaptive Secant Method for Stochastic Gradient"
    },
    {
        "abs": "When a three-dimensional object moves relative to an observer, a change\noccurs on the observer's image plane and in the visual representation computed\nby a learned model. Starting with the idea that a good visual representation is\none that transforms linearly under scene motions, we show, using the theory of\ngroup representations, that any such representation is equivalent to a\ncombination of the elementary irreducible representations. We derive a striking\nrelationship between irreducibility and the statistical dependency structure of\nthe representation, by showing that under restricted conditions, irreducible\nrepresentations are decorrelated. Under partial observability, as induced by\nthe perspective projection of a scene onto the image plane, the motion group\ndoes not have a linear action on the space of images, so that it becomes\nnecessary to perform inference over a latent representation that does transform\nlinearly. This idea is demonstrated in a model of rotating NORB objects that\nemploys a latent representation of the non-commutative 3D rotation group SO(3).",
        "title": "Transformation Properties of Learned Visual Representations"
    },
    {
        "abs": "Efficient Maximum Inner Product Search (MIPS) is an important task that has a\nwide applicability in recommendation systems and classification with a large\nnumber of classes. Solutions based on locality-sensitive hashing (LSH) as well\nas tree-based solutions have been investigated in the recent literature, to\nperform approximate MIPS in sublinear time. In this paper, we compare these to\nanother extremely simple approach for solving approximate MIPS, based on\nvariants of the k-means clustering algorithm. Specifically, we propose to train\na spherical k-means, after having reduced the MIPS problem to a Maximum Cosine\nSimilarity Search (MCSS). Experiments on two standard recommendation system\nbenchmarks as well as on large vocabulary word embeddings, show that this\nsimple approach yields much higher speedups, for the same retrieval precision,\nthan current state-of-the-art hashing-based and tree-based methods. This simple\nmethod also yields more robust retrievals when the query is corrupted by noise.",
        "title": "Clustering is Efficient for Approximate Maximum Inner Product Search"
    },
    {
        "abs": "The variational autoencoder (VAE; Kingma, Welling (2014)) is a recently\nproposed generative model pairing a top-down generative network with a\nbottom-up recognition network which approximates posterior inference. It\ntypically makes strong assumptions about posterior inference, for instance that\nthe posterior distribution is approximately factorial, and that its parameters\ncan be approximated with nonlinear regression from the observations. As we show\nempirically, the VAE objective can lead to overly simplified representations\nwhich fail to use the network's entire modeling capacity. We present the\nimportance weighted autoencoder (IWAE), a generative model with the same\narchitecture as the VAE, but which uses a strictly tighter log-likelihood lower\nbound derived from importance weighting. In the IWAE, the recognition network\nuses multiple samples to approximate the posterior, giving it increased\nflexibility to model complex posteriors which do not fit the VAE modeling\nassumptions. We show empirically that IWAEs learn richer latent space\nrepresentations than VAEs, leading to improved test log-likelihood on density\nestimation benchmarks.",
        "title": "Importance Weighted Autoencoders"
    },
    {
        "abs": "This work investigates how using reduced precision data in Convolutional\nNeural Networks (CNNs) affects network accuracy during classification. More\nspecifically, this study considers networks where each layer may use different\nprecision data. Our key result is the observation that the tolerance of CNNs to\nreduced precision data not only varies across networks, a well established\nobservation, but also within networks. Tuning precision per layer is appealing\nas it could enable energy and performance improvements. In this paper we study\nhow error tolerance across layers varies and propose a method for finding a low\nprecision configuration for a network while maintaining high accuracy. A\ndiverse set of CNNs is analyzed showing that compared to a conventional\nimplementation using a 32-bit floating-point representation for all layers, and\nwith less than 1% loss in relative accuracy, the data footprint required by\nthese networks can be reduced by an average of 74% and up to 92%.",
        "title": "Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets"
    },
    {
        "abs": "The efficiency of graph-based semi-supervised algorithms depends on the graph\nof instances on which they are applied. The instances are often in a vectorial\nform before a graph linking them is built. The construction of the graph relies\non a metric over the vectorial space that help define the weight of the\nconnection between entities. The classic choice for this metric is usually a\ndistance measure or a similarity measure based on the euclidean norm. We claim\nthat in some cases the euclidean norm on the initial vectorial space might not\nbe the more appropriate to solve the task efficiently. We propose an algorithm\nthat aims at learning the most appropriate vectorial representation for\nbuilding a graph on which the task at hand is solved efficiently.",
        "title": "Metric learning approach for graph-based label propagation"
    },
    {
        "abs": "Hypernymy, textual entailment, and image captioning can be seen as special\ncases of a single visual-semantic hierarchy over words, sentences, and images.\nIn this paper we advocate for explicitly modeling the partial order structure\nof this hierarchy. Towards this goal, we introduce a general method for\nlearning ordered representations, and show how it can be applied to a variety\nof tasks involving images and language. We show that the resulting\nrepresentations improve performance over current approaches for hypernym\nprediction and image-caption retrieval.",
        "title": "Order-Embeddings of Images and Language"
    },
    {
        "abs": "We propose local distributional smoothness (LDS), a new notion of smoothness\nfor statistical model that can be used as a regularization term to promote the\nsmoothness of the model distribution. We named the LDS based regularization as\nvirtual adversarial training (VAT). The LDS of a model at an input datapoint is\ndefined as the KL-divergence based robustness of the model distribution against\nlocal perturbation around the datapoint. VAT resembles adversarial training,\nbut distinguishes itself in that it determines the adversarial direction from\nthe model distribution alone without using the label information, making it\napplicable to semi-supervised learning. The computational cost for VAT is\nrelatively low. For neural network, the approximated gradient of the LDS can be\ncomputed with no more than three pairs of forward and back propagations. When\nwe applied our technique to supervised and semi-supervised learning for the\nMNIST dataset, it outperformed all the training methods other than the current\nstate of the art method, which is based on a highly advanced generative model.\nWe also applied our method to SVHN and NORB, and confirmed our method's\nsuperior performance over the current state of the art semi-supervised method\napplied to these datasets.",
        "title": "Distributional Smoothing with Virtual Adversarial Training"
    },
    {
        "abs": "The availability of large labeled datasets has allowed Convolutional Network\nmodels to achieve impressive recognition results. However, in many settings\nmanual annotation of the data is impractical; instead our data has noisy\nlabels, i.e. there is some freely available label for each image which may or\nmay not be accurate. In this paper, we explore the performance of\ndiscriminatively-trained Convnets when trained on such noisy data. We introduce\nan extra noise layer into the network which adapts the network outputs to match\nthe noisy label distribution. The parameters of this noise layer can be\nestimated as part of the training process and involve simple modifications to\ncurrent training infrastructures for deep networks. We demonstrate the\napproaches on several datasets, including large scale experiments on the\nImageNet classification benchmark.",
        "title": "Training Convolutional Networks with Noisy Labels"
    },
    {
        "abs": "We provide novel guaranteed approaches for training feedforward neural\nnetworks with sparse connectivity. We leverage on the techniques developed\npreviously for learning linear networks and show that they can also be\neffectively adopted to learn non-linear networks. We operate on the moments\ninvolving label and the score function of the input, and show that their\nfactorization provably yields the weight matrix of the first layer of a deep\nnetwork under mild conditions. In practice, the output of our method can be\nemployed as effective initializers for gradient descent.",
        "title": "Provable Methods for Training Neural Networks with Sparse Connectivity"
    },
    {
        "abs": "Discourse relations bind smaller linguistic elements into coherent texts.\nHowever, automatically identifying discourse relations is difficult, because it\nrequires understanding the semantics of the linked sentences. A more subtle\nchallenge is that it is not enough to represent the meaning of each sentence of\na discourse relation, because the relation may depend on links between\nlower-level elements, such as entity mentions. Our solution computes\ndistributional meaning representations by composition up the syntactic parse\ntree. A key difference from previous work on compositional distributional\nsemantics is that we also compute representations for entity mentions, using a\nnovel downward compositional pass. Discourse relations are predicted not only\nfrom the distributional representations of the sentences, but also of their\ncoreferent entity mentions. The resulting system obtains substantial\nimprovements over the previous state-of-the-art in predicting implicit\ndiscourse relations in the Penn Discourse Treebank.",
        "title": "Entity-Augmented Distributional Semantics for Discourse Relations"
    },
    {
        "abs": "In this work, we propose a new method to integrate two recent lines of work:\nunsupervised induction of shallow semantics (e.g., semantic roles) and\nfactorization of relations in text and knowledge bases. Our model consists of\ntwo components: (1) an encoding component: a semantic role labeling model which\npredicts roles given a rich set of syntactic and lexical features; (2) a\nreconstruction component: a tensor factorization model which relies on roles to\npredict argument fillers. When the components are estimated jointly to minimize\nerrors in argument reconstruction, the induced roles largely correspond to\nroles defined in annotated resources. Our method performs on par with most\naccurate role induction methods on English, even though, unlike these previous\napproaches, we do not incorporate any prior linguistic knowledge about the\nlanguage.",
        "title": "Inducing Semantic Representation from Text by Jointly Predicting and Factorizing Relations"
    },
    {
        "abs": "The notion of metric plays a key role in machine learning problems such as\nclassification, clustering or ranking. However, it is worth noting that there\nis a severe lack of theoretical guarantees that can be expected on the\ngeneralization capacity of the classifier associated to a given metric. The\ntheoretical framework of $(\\epsilon, \\gamma, \\tau)$-good similarity functions\n(Balcan et al., 2008) has been one of the first attempts to draw a link between\nthe properties of a similarity function and those of a linear classifier making\nuse of it. In this paper, we extend and complete this theory by providing a new\ngeneralization bound for the associated classifier based on the algorithmic\nrobustness framework.",
        "title": "Algorithmic Robustness for Learning via $(\u03b5, \u03b3, \u03c4)$-Good Similarity Functions"
    },
    {
        "abs": "We present the multiplicative recurrent neural network as a general model for\ncompositional meaning in language, and evaluate it on the task of fine-grained\nsentiment analysis. We establish a connection to the previously investigated\nmatrix-space models for compositionality, and show they are special cases of\nthe multiplicative recurrent net. Our experiments show that these models\nperform comparably or better than Elman-type additive recurrent neural networks\nand outperform matrix-space models on a standard fine-grained sentiment\nanalysis corpus. Furthermore, they yield comparable results to structural deep\nmodels on the recently published Stanford Sentiment Treebank without the need\nfor generating parse trees.",
        "title": "Modeling Compositionality with Multiplicative Recurrent Neural Networks"
    },
    {
        "abs": "Finding minima of a real valued non-convex function over a high dimensional\nspace is a major challenge in science. We provide evidence that some such\nfunctions that are defined on high dimensional domains have a narrow band of\nvalues whose pre-image contains the bulk of its critical points. This is in\ncontrast with the low dimensional picture in which this band is wide. Our\nsimulations agree with the previous theoretical work on spin glasses that\nproves the existence of such a band when the dimension of the domain tends to\ninfinity. Furthermore our experiments on teacher-student networks with the\nMNIST dataset establish a similar phenomenon in deep networks. We finally\nobserve that both the gradient descent and the stochastic gradient descent\nmethods can reach this level within the same number of steps.",
        "title": "Explorations on high dimensional landscapes"
    },
    {
        "abs": "We develop a new statistical model for photographic images, in which the\nlocal responses of a bank of linear filters are described as jointly Gaussian,\nwith zero mean and a covariance that varies slowly over spatial position. We\noptimize sets of filters so as to minimize the nuclear norms of matrices of\ntheir local activations (i.e., the sum of the singular values), thus\nencouraging a flexible form of sparsity that is not tied to any particular\ndictionary or coordinate system. Filters optimized according to this objective\nare oriented and bandpass, and their responses exhibit substantial local\ncorrelation. We show that images can be reconstructed nearly perfectly from\nestimates of the local filter response covariances alone, and with minimal\ndegradation (either visual or MSE) from low-rank approximations of these\ncovariances. As such, this representation holds much promise for use in\napplications such as denoising, compression, and texture representation, and\nmay form a useful substrate for hierarchical decompositions.",
        "title": "The local low-dimensionality of natural images"
    },
    {
        "abs": "Most modern convolutional neural networks (CNNs) used for object recognition\nare built using the same principles: Alternating convolution and max-pooling\nlayers followed by a small number of fully connected layers. We re-evaluate the\nstate of the art for object recognition from small images with convolutional\nnetworks, questioning the necessity of different components in the pipeline. We\nfind that max-pooling can simply be replaced by a convolutional layer with\nincreased stride without loss in accuracy on several image recognition\nbenchmarks. Following this finding -- and building on other recent work for\nfinding simple network structures -- we propose a new architecture that\nconsists solely of convolutional layers and yields competitive or state of the\nart performance on several object recognition datasets (CIFAR-10, CIFAR-100,\nImageNet). To analyze the network we introduce a new variant of the\n\"deconvolution approach\" for visualizing features learned by CNNs, which can be\napplied to a broader range of network structures than existing approaches.",
        "title": "Striving for Simplicity: The All Convolutional Net"
    },
    {
        "abs": "Artificial neural networks typically have a fixed, non-linear activation\nfunction at each neuron. We have designed a novel form of piecewise linear\nactivation function that is learned independently for each neuron using\ngradient descent. With this adaptive activation function, we are able to\nimprove upon deep neural network architectures composed of static rectified\nlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),\nCIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgs\nboson decay modes.",
        "title": "Learning Activation Functions to Improve Deep Neural Networks"
    },
    {
        "abs": "This paper introduces a greedy parser based on neural networks, which\nleverages a new compositional sub-tree representation. The greedy parser and\nthe compositional procedure are jointly trained, and tightly depends on\neach-other. The composition procedure outputs a vector representation which\nsummarizes syntactically (parsing tags) and semantically (words) sub-trees.\nComposition and tagging is achieved over continuous (word or tag)\nrepresentations, and recurrent neural networks. We reach F1 performance on par\nwith well-known existing parsers, while having the advantage of speed, thanks\nto the greedy nature of the parser. We provide a fully functional\nimplementation of the method described in this paper.",
        "title": "Joint RNN-Based Greedy Parsing and Word Composition"
    },
    {
        "abs": "Suitable lateral connections between encoder and decoder are shown to allow\nhigher layers of a denoising autoencoder (dAE) to focus on invariant\nrepresentations. In regular autoencoders, detailed information needs to be\ncarried through the highest layers but lateral connections from encoder to\ndecoder relieve this pressure. It is shown that abstract invariant features can\nbe translated to detailed reconstructions when invariant features are allowed\nto modulate the strength of the lateral connection. Three dAE structures with\nmodulated and additive lateral connections, and without lateral connections\nwere compared in experiments using real-world images. The experiments verify\nthat adding modulated lateral connections to the model 1) improves the accuracy\nof the probability model for inputs, as measured by denoising performance; 2)\nresults in representations whose degree of invariance grows faster towards the\nhigher layers; and 3) supports the formation of diverse invariant poolings.",
        "title": "Denoising autoencoder with modulated lateral connections learns invariant representations of natural images"
    },
    {
        "abs": "We develop a new method for visualizing and refining the invariances of\nlearned representations. Specifically, we test for a general form of\ninvariance, linearization, in which the action of a transformation is confined\nto a low-dimensional subspace. Given two reference images (typically, differing\nby some transformation), we synthesize a sequence of images lying on a path\nbetween them that is of minimal length in the space of the representation (a\n\"representational geodesic\"). If the transformation relating the two reference\nimages is linearized by the representation, this sequence should follow the\ngradual evolution of this transformation. We use this method to assess the\ninvariance properties of a state-of-the-art image classification network and\nfind that geodesics generated for image pairs differing by translation,\nrotation, and dilation do not evolve according to their associated\ntransformations. Our method also suggests a remedy for these failures, and\nfollowing this prescription, we show that the modified representation is able\nto linearize a variety of geometric image transformations.",
        "title": "Geodesics of learned representations"
    },
    {
        "abs": "Genomics are rapidly transforming medical practice and basic biomedical\nresearch, providing insights into disease mechanisms and improving therapeutic\nstrategies, particularly in cancer. The ability to predict the future course of\na patient's disease from high-dimensional genomic profiling will be essential\nin realizing the promise of genomic medicine, but presents significant\nchallenges for state-of-the-art survival analysis methods. In this abstract we\npresent an investigation in learning genomic representations with neural\nnetworks to predict patient survival in cancer. We demonstrate the advantages\nof this approach over existing survival analysis methods using brain tumor\ndata.",
        "title": "Learning Genomic Representations to Predict Clinical Outcomes in Cancer"
    },
    {
        "abs": "Existing approaches to combine both additive and multiplicative neural units\neither use a fixed assignment of operations or require discrete optimization to\ndetermine what function a neuron should perform. However, this leads to an\nextensive increase in the computational complexity of the training procedure.\n  We present a novel, parameterizable transfer function based on the\nmathematical concept of non-integer functional iteration that allows the\noperation each neuron performs to be smoothly and, most importantly,\ndifferentiablely adjusted between addition and multiplication. This allows the\ndecision between addition and multiplication to be integrated into the standard\nbackpropagation training procedure.",
        "title": "A Differentiable Transition Between Additive and Multiplicative Neurons"
    },
    {
        "abs": "One of the difficulties of training deep neural networks is caused by\nimproper scaling between layers. Scaling issues introduce exploding / gradient\nproblems, and have typically been addressed by careful scale-preserving\ninitialization. We investigate the value of preserving scale, or isometry,\nbeyond the initial weights. We propose two methods of maintaing isometry, one\nexact and one stochastic. Preliminary experiments show that for both\ndeterminant and scale-normalization effectively speeds up learning. Results\nsuggest that isometry is important in the beginning of learning, and\nmaintaining it leads to faster learning.",
        "title": "Scale Normalization"
    },
    {
        "abs": "We extend Stochastic Gradient Variational Bayes to perform posterior\ninference for the weights of Stick-Breaking processes. This development allows\nus to define a Stick-Breaking Variational Autoencoder (SB-VAE), a Bayesian\nnonparametric version of the variational autoencoder that has a latent\nrepresentation with stochastic dimensionality. We experimentally demonstrate\nthat the SB-VAE, and a semi-supervised variant, learn highly discriminative\nlatent representations that often outperform the Gaussian VAE's.",
        "title": "Stick-Breaking Variational Autoencoders"
    },
    {
        "abs": "Unsupervised learning on imbalanced data is challenging because, when given\nimbalanced data, current model is often dominated by the major category and\nignores the categories with small amount of data. We develop a latent variable\nmodel that can cope with imbalanced data by dividing the latent space into a\nshared space and a private space. Based on Gaussian Process Latent Variable\nModels, we propose a new kernel formulation that enables the separation of\nlatent space and derives an efficient variational inference method. The\nperformance of our model is demonstrated with an imbalanced medical image\ndataset.",
        "title": "Unsupervised Learning with Imbalanced Data via Structure Consolidation Latent Variable Model"
    },
    {
        "abs": "Generative adversarial networks (GANs) are successful deep generative models.\nGANs are based on a two-player minimax game. However, the objective function\nderived in the original motivation is changed to obtain stronger gradients when\nlearning the generator. We propose a novel algorithm that repeats the density\nratio estimation and f-divergence minimization. Our algorithm offers a new\nperspective toward the understanding of GANs and is able to make use of\nmultiple viewpoints obtained in the research of density ratio estimation, e.g.\nwhat divergence is stable and relative density ratio is useful.",
        "title": "Generative Adversarial Nets from a Density Ratio Estimation Perspective"
    },
    {
        "abs": "This paper shows how one can directly apply natural language processing (NLP)\nmethods to classification problems in cheminformatics. Connection between these\nseemingly separate fields is shown by considering standard textual\nrepresentation of compound, SMILES. The problem of activity prediction against\na target protein is considered, which is a crucial part of computer aided drug\ndesign process. Conducted experiments show that this way one can not only\noutrank state of the art results of hand crafted representations but also gets\ndirect structural insights into the way decisions are made.",
        "title": "Learning to SMILE(S)"
    },
    {
        "abs": "We introduce a neural network architecture and a learning algorithm to\nproduce factorized symbolic representations. We propose to learn these concepts\nby observing consecutive frames, letting all the components of the hidden\nrepresentation except a small discrete set (gating units) be predicted from the\nprevious frame, and let the factors of variation in the next frame be\nrepresented entirely by these discrete gated units (corresponding to symbolic\nrepresentations). We demonstrate the efficacy of our approach on datasets of\nfaces undergoing 3D transformations and Atari 2600 games.",
        "title": "Understanding Visual Concepts with Continuation Learning"
    },
    {
        "abs": "We look at the eigenvalues of the Hessian of a loss function before and after\ntraining. The eigenvalue distribution is seen to be composed of two parts, the\nbulk which is concentrated around zero, and the edges which are scattered away\nfrom zero. We present empirical evidence for the bulk indicating how\nover-parametrized the system is, and for the edges that depend on the input\ndata.",
        "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond"
    },
    {
        "abs": "We introduce a parametric nonlinear transformation that is well-suited for\nGaussianizing data from natural images. The data are linearly transformed, and\neach component is then normalized by a pooled activity measure, computed by\nexponentiating a weighted sum of rectified and exponentiated components and a\nconstant. We optimize the parameters of the full transformation (linear\ntransform, exponents, weights, constant) over a database of natural images,\ndirectly minimizing the negentropy of the responses. The optimized\ntransformation substantially Gaussianizes the data, achieving a significantly\nsmaller mutual information between transformed components than alternative\nmethods including ICA and radial Gaussianization. The transformation is\ndifferentiable and can be efficiently inverted, and thus induces a density\nmodel on images. We show that samples of this model are visually similar to\nsamples of natural image patches. We demonstrate the use of the model as a\nprior probability density that can be used to remove additive noise. Finally,\nwe show that the transformation can be cascaded, with each layer optimized\nusing the same Gaussianization objective, thus offering an unsupervised method\nof optimizing a deep network architecture.",
        "title": "Density Modeling of Images using a Generalized Normalization Transformation"
    },
    {
        "abs": "Approximate variational inference has shown to be a powerful tool for\nmodeling unknown complex probability distributions. Recent advances in the\nfield allow us to learn probabilistic models of sequences that actively exploit\nspatial and temporal structure. We apply a Stochastic Recurrent Network (STORN)\nto learn robot time series data. Our evaluation demonstrates that we can\nrobustly detect anomalies both off- and on-line.",
        "title": "Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series"
    },
    {
        "abs": "We develop a general problem setting for training and testing the ability of\nagents to gather information efficiently. Specifically, we present a collection\nof tasks in which success requires searching through a partially-observed\nenvironment, for fragments of information which can be pieced together to\naccomplish various goals. We combine deep architectures with techniques from\nreinforcement learning to develop agents that solve our tasks. We shape the\nbehavior of these agents by combining extrinsic and intrinsic rewards. We\nempirically demonstrate that these agents learn to search actively and\nintelligently for new information to reduce their uncertainty, and to exploit\ninformation they have already acquired.",
        "title": "Towards Information-Seeking Agents"
    },
    {
        "abs": "We propose an extension to neural network language models to adapt their\nprediction to the recent history. Our model is a simplified version of memory\naugmented networks, which stores past hidden activations as memory and accesses\nthem through a dot product with the current hidden activation. This mechanism\nis very efficient and scales to very large memory sizes. We also draw a link\nbetween the use of external memory in neural network and cache models used with\ncount based language models. We demonstrate on several language model datasets\nthat our approach performs significantly better than recent memory augmented\nnetworks.",
        "title": "Improving Neural Language Models with a Continuous Cache"
    },
    {
        "abs": "Motivated by the recent progress in generative models, we introduce a model\nthat generates images from natural language descriptions. The proposed model\niteratively draws patches on a canvas, while attending to the relevant words in\nthe description. After training on Microsoft COCO, we compare our model with\nseveral baseline generative models on image generation and retrieval tasks. We\ndemonstrate that our model produces higher quality samples than other\napproaches and generates images with novel scene compositions corresponding to\npreviously unseen captions in the dataset.",
        "title": "Generating Images from Captions with Attention"
    },
    {
        "abs": "We propose a framework for training multiple neural networks simultaneously.\nThe parameters from all models are regularised by the tensor trace norm, so\nthat each neural network is encouraged to reuse others' parameters if possible\n-- this is the main motivation behind multi-task learning. In contrast to many\ndeep multi-task learning models, we do not predefine a parameter sharing\nstrategy by specifying which layers have tied parameters. Instead, our\nframework considers sharing for all shareable layers, and the sharing strategy\nis learned in a data-driven way.",
        "title": "Trace Norm Regularised Deep Multi-Task Learning"
    },
    {
        "abs": "This paper presents an actor-critic deep reinforcement learning agent with\nexperience replay that is stable, sample efficient, and performs remarkably\nwell on challenging environments, including the discrete 57-game Atari domain\nand several continuous control problems. To achieve this, the paper introduces\nseveral innovations, including truncated importance sampling with bias\ncorrection, stochastic dueling network architectures, and a new trust region\npolicy optimization method.",
        "title": "Sample Efficient Actor-Critic with Experience Replay"
    },
    {
        "abs": "We present a novel framework for generating pop music. Our model is a\nhierarchical Recurrent Neural Network, where the layers and the structure of\nthe hierarchy encode our prior knowledge about how pop music is composed. In\nparticular, the bottom layers generate the melody, while the higher levels\nproduce the drums and chords. We conduct several human studies that show strong\npreference of our generated music over that produced by the recent method by\nGoogle. We additionally show two applications of our framework: neural dancing\nand karaoke, as well as neural story singing.",
        "title": "Song From PI: A Musically Plausible Network for Pop Music Generation"
    },
    {
        "abs": "Many machine learning classifiers are vulnerable to adversarial\nperturbations. An adversarial perturbation modifies an input to change a\nclassifier's prediction without causing the input to seem substantially\ndifferent to human perception. We deploy three methods to detect adversarial\nimages. Adversaries trying to bypass our detectors must make the adversarial\nimage less pathological or they will fail trying. Our best detection method\nreveals that adversarial images place abnormal emphasis on the lower-ranked\nprincipal components from PCA. Other detectors and a colorful saliency map are\nin an appendix.",
        "title": "Early Methods for Detecting Adversarial Images"
    },
    {
        "abs": "We propose a new method for creating computationally efficient convolutional\nneural networks (CNNs) by using low-rank representations of convolutional\nfilters. Rather than approximating filters in previously-trained networks with\nmore efficient versions, we learn a set of small basis filters from scratch;\nduring training, the network learns to combine these basis filters into more\ncomplex filters that are discriminative for image classification. To train such\nnetworks, a novel weight initialization scheme is used. This allows effective\ninitialization of connection weights in convolutional layers composed of groups\nof differently-shaped filters. We validate our approach by applying it to\nseveral existing CNN architectures and training these networks from scratch\nusing the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or\nhigher accuracy than conventional CNNs with much less compute. Applying our\nmethod to an improved version of VGG-11 network using global max-pooling, we\nachieve comparable validation accuracy using 41% less compute and only 24% of\nthe original VGG-11 model parameters; another variant of our method gives a 1\npercentage point increase in accuracy over our improved VGG-11 model, giving a\ntop-5 center-crop validation accuracy of 89.7% while reducing computation by\n16% relative to the original VGG-11 model. Applying our method to the GoogLeNet\narchitecture for ILSVRC, we achieved comparable accuracy with 26% less compute\nand 41% fewer model parameters. Applying our method to a near state-of-the-art\nnetwork for CIFAR, we achieved comparable accuracy with 46% less compute and\n55% fewer parameters.",
        "title": "Training CNNs with Low-Rank Filters for Efficient Image Classification"
    },
    {
        "abs": "Layer-sequential unit-variance (LSUV) initialization - a simple method for\nweight initialization for deep net learning - is proposed. The method consists\nof the two steps. First, pre-initialize weights of each convolution or\ninner-product layer with orthonormal matrices. Second, proceed from the first\nto the final layer, normalizing the variance of the output of each layer to be\nequal to one.\n  Experiment with different activation functions (maxout, ReLU-family, tanh)\nshow that the proposed initialization leads to learning of very deep nets that\n(i) produces networks with test accuracy better or equal to standard methods\nand (ii) is at least as fast as the complex schemes proposed specifically for\nvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava\net al. (2015)).\n  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets\nand the state-of-the-art, or very close to it, is achieved on the MNIST,\nCIFAR-10/100 and ImageNet datasets.",
        "title": "All you need is a good init"
    },
    {
        "abs": "This paper builds off recent work from Kiperwasser & Goldberg (2016) using\nneural attention in a simple graph-based dependency parser. We use a larger but\nmore thoroughly regularized parser than other recent BiLSTM-based approaches,\nwith biaffine classifiers to predict arcs and labels. Our parser gets state of\nthe art or near state of the art performance on standard treebanks for six\ndifferent languages, achieving 95.7% UAS and 94.1% LAS on the most popular\nEnglish PTB dataset. This makes it the highest-performing graph-based parser on\nthis benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and\n2.2%---and comparable to the highest performing transition-based parser\n(Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show\nwhich hyperparameter choices had a significant effect on parsing accuracy,\nallowing us to achieve large gains over other graph-based approaches.",
        "title": "Deep Biaffine Attention for Neural Dependency Parsing"
    },
    {
        "abs": "Accurate representational learning of both the explicit and implicit\nrelationships within data is critical to the ability of machines to perform\nmore complex and abstract reasoning tasks. We describe the efficient weakly\nsupervised learning of such inferences by our Dynamic Adaptive Network\nIntelligence (DANI) model. We report state-of-the-art results for DANI over\nquestion answering tasks in the bAbI dataset that have proved difficult for\ncontemporary approaches to learning representation (Weston et al., 2015).",
        "title": "Dynamic Adaptive Network Intelligence"
    },
    {
        "abs": "Spherical data is found in many applications. By modeling the discretized\nsphere as a graph, we can accommodate non-uniformly distributed, partial, and\nchanging samplings. Moreover, graph convolutions are computationally more\nefficient than spherical convolutions. As equivariance is desired to exploit\nrotational symmetries, we discuss how to approach rotation equivariance using\nthe graph neural network introduced in Defferrard et al. (2016). Experiments\nshow good performance on rotation-invariant learning problems. Code and\nexamples are available at https://github.com/SwissDataScienceCenter/DeepSphere",
        "title": "DeepSphere: towards an equivariant graph-based spherical CNN"
    },
    {
        "abs": "High computational complexity hinders the widespread usage of Convolutional\nNeural Networks (CNNs), especially in mobile devices. Hardware accelerators are\narguably the most promising approach for reducing both execution time and power\nconsumption. One of the most important steps in accelerator development is\nhardware-oriented model approximation. In this paper we present Ristretto, a\nmodel approximation framework that analyzes a given CNN with respect to\nnumerical resolution used in representing weights and outputs of convolutional\nand fully connected layers. Ristretto can condense models by using fixed point\narithmetic and representation instead of floating point. Moreover, Ristretto\nfine-tunes the resulting fixed point network. Given a maximum error tolerance\nof 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit.\nThe code for Ristretto is available.",
        "title": "Hardware-oriented Approximation of Convolutional Neural Networks"
    },
    {
        "abs": "The diversity of painting styles represents a rich visual vocabulary for the\nconstruction of an image. The degree to which one may learn and parsimoniously\ncapture this visual vocabulary measures our understanding of the higher level\nfeatures of paintings, if not images in general. In this work we investigate\nthe construction of a single, scalable deep network that can parsimoniously\ncapture the artistic style of a diversity of paintings. We demonstrate that\nsuch a network generalizes across a diversity of artistic styles by reducing a\npainting to a point in an embedding space. Importantly, this model permits a\nuser to explore new painting styles by arbitrarily combining the styles learned\nfrom individual paintings. We hope that this work provides a useful step\ntowards building rich models of paintings and offers a window on to the\nstructure of the learned representation of artistic style.",
        "title": "A Learned Representation For Artistic Style"
    },
    {
        "abs": "Sum-Product Networks (SPNs) are a class of expressive yet tractable\nhierarchical graphical models. LearnSPN is a structure learning algorithm for\nSPNs that uses hierarchical co-clustering to simultaneously identifying similar\nentities and similar features. The original LearnSPN algorithm assumes that all\nthe variables are discrete and there is no missing data. We introduce a\npractical, simplified version of LearnSPN, MiniSPN, that runs faster and can\nhandle missing data and heterogeneous features common in real applications. We\ndemonstrate the performance of MiniSPN on standard benchmark datasets and on\ntwo datasets from Google's Knowledge Graph exhibiting high missingness rates\nand a mix of discrete and continuous features.",
        "title": "A Minimalistic Approach to Sum-Product Network Learning for Real Applications"
    },
    {
        "abs": "Recent research on deep neural networks has focused primarily on improving\naccuracy. For a given accuracy level, it is typically possible to identify\nmultiple DNN architectures that achieve that accuracy level. With equivalent\naccuracy, smaller DNN architectures offer at least three advantages: (1)\nSmaller DNNs require less communication across servers during distributed\ntraining. (2) Smaller DNNs require less bandwidth to export a new model from\nthe cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on\nFPGAs and other hardware with limited memory. To provide all of these\nadvantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet\nachieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.\nAdditionally, with model compression techniques we are able to compress\nSqueezeNet to less than 0.5MB (510x smaller than AlexNet).\n  The SqueezeNet architecture is available for download here:\nhttps://github.com/DeepScale/SqueezeNet",
        "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size"
    },
    {
        "abs": "In this paper, we study the problem of question answering when reasoning over\nmultiple facts is required. We propose Query-Reduction Network (QRN), a variant\nof Recurrent Neural Network (RNN) that effectively handles both short-term\n(local) and long-term (global) sequential dependencies to reason over multiple\nfacts. QRN considers the context sentences as a sequence of state-changing\ntriggers, and reduces the original query to a more informed query as it\nobserves each trigger (context sentence) through time. Our experiments show\nthat QRN produces the state-of-the-art results in bAbI QA and dialog tasks, and\nin a real goal-oriented dialog dataset. In addition, QRN formulation allows\nparallelization on RNN's time axis, saving an order of magnitude in time\ncomplexity for training and inference.",
        "title": "Query-Reduction Networks for Question Answering"
    },
    {
        "abs": "We propose a language-agnostic way of automatically generating sets of\nsemantically similar clusters of entities along with sets of \"outlier\"\nelements, which may then be used to perform an intrinsic evaluation of word\nembeddings in the outlier detection task. We used our methodology to create a\ngold-standard dataset, which we call WikiSem500, and evaluated multiple\nstate-of-the-art embeddings. The results show a correlation between performance\non this dataset and performance on sentiment analysis.",
        "title": "Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations"
    },
    {
        "abs": "Recurrent neural nets are widely used for predicting temporal data. Their\ninherent deep feedforward structure allows learning complex sequential\npatterns. It is believed that top-down feedback might be an important missing\ningredient which in theory could help disambiguate similar patterns depending\non broader context. In this paper we introduce surprisal-driven recurrent\nnetworks, which take into account past error information when making new\npredictions. This is achieved by continuously monitoring the discrepancy\nbetween most recent predictions and the actual observations. Furthermore, we\nshow that it outperforms other stochastic and fully deterministic approaches on\nenwik8 character level prediction task achieving 1.37 BPC on the test portion\nof the text.",
        "title": "Surprisal-Driven Feedback in Recurrent Networks"
    },
    {
        "abs": "Although Generative Adversarial Networks achieve state-of-the-art results on\na variety of generative tasks, they are regarded as highly unstable and prone\nto miss modes. We argue that these bad behaviors of GANs are due to the very\nparticular functional shape of the trained discriminators in high dimensional\nspaces, which can easily make training stuck or push probability mass in the\nwrong direction, towards that of higher concentration than that of the data\ngenerating distribution. We introduce several ways of regularizing the\nobjective, which can dramatically stabilize the training of GAN models. We also\nshow that our regularizers can help the fair distribution of probability mass\nacross the modes of the data generating distribution, during the early phases\nof training and thus providing a unified solution to the missing modes problem.",
        "title": "Mode Regularized Generative Adversarial Networks"
    },
    {
        "abs": "Sample complexity and safety are major challenges when learning policies with\nreinforcement learning for real-world tasks, especially when the policies are\nrepresented using rich function approximators like deep neural networks.\nModel-based methods where the real-world target domain is approximated using a\nsimulated source domain provide an avenue to tackle the above challenges by\naugmenting real data with simulated data. However, discrepancies between the\nsimulated source domain and the target domain pose a challenge for simulated\ntraining. We introduce the EPOpt algorithm, which uses an ensemble of simulated\nsource domains and a form of adversarial training to learn policies that are\nrobust and generalize to a broad range of possible target domains, including\nunmodeled effects. Further, the probability distribution over source domains in\nthe ensemble can be adapted using data from target domain and approximate\nBayesian methods, to progressively make it a better approximation. Thus,\nlearning on a model ensemble, along with source domain adaptation, provides the\nbenefit of both robustness and learning/adaptation.",
        "title": "EPOpt: Learning Robust Neural Network Policies Using Model Ensembles"
    },
    {
        "abs": "We introduce Divnet, a flexible technique for learning networks with diverse\nneurons. Divnet models neuronal diversity by placing a Determinantal Point\nProcess (DPP) over neurons in a given layer. It uses this DPP to select a\nsubset of diverse neurons and subsequently fuses the redundant neurons into the\nselected ones. Compared with previous approaches, Divnet offers a more\nprincipled, flexible technique for capturing neuronal diversity and thus\nimplicitly enforcing regularization. This enables effective auto-tuning of\nnetwork architecture and leads to smaller network sizes without hurting\nperformance. Moreover, through its focus on diversity and neuron fusing, Divnet\nremains compatible with other procedures that seek to reduce memory footprints\nof networks. We present experimental results to corroborate our claims: for\npruning neural networks, Divnet is seen to be notably superior to competing\napproaches.",
        "title": "Diversity Networks: Neural Network Compression Using Determinantal Point Processes"
    },
    {
        "abs": "The efficiency of graph-based semi-supervised algorithms depends on the graph\nof instances on which they are applied. The instances are often in a vectorial\nform before a graph linking them is built. The construction of the graph relies\non a metric over the vectorial space that help define the weight of the\nconnection between entities. The classic choice for this metric is usually a\ndistance measure or a similarity measure based on the euclidean norm. We claim\nthat in some cases the euclidean norm on the initial vectorial space might not\nbe the more appropriate to solve the task efficiently. We propose an algorithm\nthat aims at learning the most appropriate vectorial representation for\nbuilding a graph on which the task at hand is solved efficiently.",
        "title": "Metric learning approach for graph-based label propagation"
    },
    {
        "abs": "One major challenge in training Deep Neural Networks is preventing\noverfitting. Many techniques such as data augmentation and novel regularizers\nsuch as Dropout have been proposed to prevent overfitting without requiring a\nmassive amount of training data. In this work, we propose a new regularizer\ncalled DeCov which leads to significantly reduced overfitting (as indicated by\nthe difference between train and val performance), and better generalization.\nOur regularizer encourages diverse or non-redundant representations in Deep\nNeural Networks by minimizing the cross-covariance of hidden activations. This\nsimple intuition has been explored in a number of past works but surprisingly\nhas never been applied as a regularizer in supervised learning. Experiments\nacross a range of datasets and network architectures show that this loss always\nreduces overfitting while almost always maintaining or increasing\ngeneralization performance and often improving performance over Dropout.",
        "title": "Reducing Overfitting in Deep Networks by Decorrelating Representations"
    },
    {
        "abs": "Deep neural networks are commonly trained using stochastic non-convex\noptimization procedures, which are driven by gradient information estimated on\nfractions (batches) of the dataset. While it is commonly accepted that batch\nsize is an important parameter for offline tuning, the benefits of online\nselection of batches remain poorly understood. We investigate online batch\nselection strategies for two state-of-the-art methods of stochastic\ngradient-based optimization, AdaDelta and Adam. As the loss function to be\nminimized for the whole dataset is an aggregation of loss functions of\nindividual datapoints, intuitively, datapoints with the greatest loss should be\nconsidered (selected in a batch) more frequently. However, the limitations of\nthis intuition and the proper control of the selection pressure over time are\nopen questions. We propose a simple strategy where all datapoints are ranked\nw.r.t. their latest known loss value and the probability to be selected decays\nexponentially as a function of rank. Our experimental results on the MNIST\ndataset suggest that selecting batches speeds up both AdaDelta and Adam by a\nfactor of about 5.",
        "title": "Online Batch Selection for Faster Training of Neural Networks"
    },
    {
        "abs": "We present a scalable approach for semi-supervised learning on\ngraph-structured data that is based on an efficient variant of convolutional\nneural networks which operate directly on graphs. We motivate the choice of our\nconvolutional architecture via a localized first-order approximation of\nspectral graph convolutions. Our model scales linearly in the number of graph\nedges and learns hidden layer representations that encode both local graph\nstructure and features of nodes. In a number of experiments on citation\nnetworks and on a knowledge graph dataset we demonstrate that our approach\noutperforms related methods by a significant margin.",
        "title": "Semi-Supervised Classification with Graph Convolutional Networks"
    },
    {
        "abs": "We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN)\nwhich views the discriminator as an energy function that attributes low\nenergies to the regions near the data manifold and higher energies to other\nregions. Similar to the probabilistic GANs, a generator is seen as being\ntrained to produce contrastive samples with minimal energies, while the\ndiscriminator is trained to assign high energies to these generated samples.\nViewing the discriminator as an energy function allows to use a wide variety of\narchitectures and loss functionals in addition to the usual binary classifier\nwith logistic output. Among them, we show one instantiation of EBGAN framework\nas using an auto-encoder architecture, with the energy being the reconstruction\nerror, in place of the discriminator. We show that this form of EBGAN exhibits\nmore stable behavior than regular GANs during training. We also show that a\nsingle-scale architecture can be trained to generate high-resolution images.",
        "title": "Energy-based Generative Adversarial Network"
    },
    {
        "abs": "Recent research in the deep learning field has produced a plethora of new\narchitectures. At the same time, a growing number of groups are applying deep\nlearning to new applications. Some of these groups are likely to be composed of\ninexperienced deep learning practitioners who are baffled by the dizzying array\nof architecture choices and therefore opt to use an older architecture (i.e.,\nAlexnet). Here we attempt to bridge this gap by mining the collective knowledge\ncontained in recent deep learning research to discover underlying principles\nfor designing neural network architectures. In addition, we describe several\narchitectural innovations, including Fractal of FractalNet network, Stagewise\nBoosting Networks, and Taylor Series Networks (our Caffe code and prototxt\nfiles is available at https://github.com/iPhysicist/CNNDesignPatterns). We hope\nothers are inspired to build on our preliminary work.",
        "title": "Deep Convolutional Neural Network Design Patterns"
    },
    {
        "abs": "Machine comprehension (MC), answering a query about a given context\nparagraph, requires modeling complex interactions between the context and the\nquery. Recently, attention mechanisms have been successfully extended to MC.\nTypically these methods use attention to focus on a small portion of the\ncontext and summarize it with a fixed-size vector, couple attentions\ntemporally, and/or often form a uni-directional attention. In this paper we\nintroduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage\nhierarchical process that represents the context at different levels of\ngranularity and uses bi-directional attention flow mechanism to obtain a\nquery-aware context representation without early summarization. Our\nexperimental evaluations show that our model achieves the state-of-the-art\nresults in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze\ntest.",
        "title": "Bidirectional Attention Flow for Machine Comprehension"
    },
    {
        "abs": "Though with progress, model learning and performing posterior inference still\nremains a common challenge for using deep generative models, especially for\nhandling discrete hidden variables. This paper is mainly concerned with\nalgorithms for learning Helmholz machines, which is characterized by pairing\nthe generative model with an auxiliary inference model. A common drawback of\nprevious learning algorithms is that they indirectly optimize some bounds of\nthe targeted marginal log-likelihood. In contrast, we successfully develop a\nnew class of algorithms, based on stochastic approximation (SA) theory of the\nRobbins-Monro type, to directly optimize the marginal log-likelihood and\nsimultaneously minimize the inclusive KL-divergence. The resulting learning\nalgorithm is thus called joint SA (JSA). Moreover, we construct an effective\nMCMC operator for JSA. Our results on the MNIST datasets demonstrate that the\nJSA's performance is consistently superior to that of competing algorithms like\nRWS, for learning a range of difficult models.",
        "title": "Joint Stochastic Approximation learning of Helmholtz Machines"
    },
    {
        "abs": "Object detection with deep neural networks is often performed by passing a\nfew thousand candidate bounding boxes through a deep neural network for each\nimage. These bounding boxes are highly correlated since they originate from the\nsame image. In this paper we investigate how to exploit feature occurrence at\nthe image scale to prune the neural network which is subsequently applied to\nall bounding boxes. We show that removing units which have near-zero activation\nin the image allows us to significantly reduce the number of parameters in the\nnetwork. Results on the PASCAL 2007 Object Detection Challenge demonstrate that\nup to 40% of units in some fully-connected layers can be entirely eliminated\nwith little change in the detection result.",
        "title": "On-the-fly Network Pruning for Object Detection"
    },
    {
        "abs": "Modeling interactions between features improves the performance of machine\nlearning solutions in many domains (e.g. recommender systems or sentiment\nanalysis). In this paper, we introduce Exponential Machines (ExM), a predictor\nthat models all interactions of every order. The key idea is to represent an\nexponentially large tensor of parameters in a factorized format called Tensor\nTrain (TT). The Tensor Train format regularizes the model and lets you control\nthe number of underlying parameters. To train the model, we develop a\nstochastic Riemannian optimization procedure, which allows us to fit tensors\nwith 2^160 entries. We show that the model achieves state-of-the-art\nperformance on synthetic data with high-order interactions and that it works on\npar with high-order factorization machines on a recommender system dataset\nMovieLens 100K.",
        "title": "Exponential Machines"
    },
    {
        "abs": "We introduce Deep Variational Bayes Filters (DVBF), a new method for\nunsupervised learning and identification of latent Markovian state space\nmodels. Leveraging recent advances in Stochastic Gradient Variational Bayes,\nDVBF can overcome intractable inference distributions via variational\ninference. Thus, it can handle highly nonlinear input data with temporal and\nspatial dependencies such as image sequences without domain knowledge. Our\nexperiments show that enabling backpropagation through transitions enforces\nstate space assumptions and significantly improves information content of the\nlatent embedding. This also enables realistic long-term prediction.",
        "title": "Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data"
    },
    {
        "abs": "Traditional dialog systems used in goal-oriented applications require a lot\nof domain-specific handcrafting, which hinders scaling up to new domains.\nEnd-to-end dialog systems, in which all components are trained from the dialogs\nthemselves, escape this limitation. But the encouraging success recently\nobtained in chit-chat dialog may not carry over to goal-oriented settings. This\npaper proposes a testbed to break down the strengths and shortcomings of\nend-to-end dialog systems in goal-oriented applications. Set in the context of\nrestaurant reservation, our tasks require manipulating sentences and symbols,\nso as to properly conduct conversations, issue API calls and use the outputs of\nsuch calls. We show that an end-to-end dialog system based on Memory Networks\ncan reach promising, yet imperfect, performance and learn to perform\nnon-trivial operations. We confirm those results by comparing our system to a\nhand-crafted slot-filling baseline on data from the second Dialog State\nTracking Challenge (Henderson et al., 2014a). We show similar result patterns\non data extracted from an online concierge service.",
        "title": "Learning End-to-End Goal-Oriented Dialog"
    },
    {
        "abs": "Adversarial training provides a means of regularizing supervised learning\nalgorithms while virtual adversarial training is able to extend supervised\nlearning algorithms to the semi-supervised setting. However, both methods\nrequire making small perturbations to numerous entries of the input vector,\nwhich is inappropriate for sparse high-dimensional inputs such as one-hot word\nrepresentations. We extend adversarial and virtual adversarial training to the\ntext domain by applying perturbations to the word embeddings in a recurrent\nneural network rather than to the original input itself. The proposed method\nachieves state of the art results on multiple benchmark semi-supervised and\npurely supervised tasks. We provide visualizations and analysis showing that\nthe learned word embeddings have improved in quality and that while training,\nthe model is less prone to overfitting. Code is available at\nhttps://github.com/tensorflow/models/tree/master/research/adversarial_text.",
        "title": "Adversarial Training Methods for Semi-Supervised Text Classification"
    },
    {
        "abs": "Unsupervised learning of probabilistic models is a central yet challenging\nproblem in machine learning. Specifically, designing models with tractable\nlearning, sampling, inference and evaluation is crucial in solving this task.\nWe extend the space of such models using real-valued non-volume preserving\n(real NVP) transformations, a set of powerful invertible and learnable\ntransformations, resulting in an unsupervised learning algorithm with exact\nlog-likelihood computation, exact sampling, exact inference of latent\nvariables, and an interpretable latent space. We demonstrate its ability to\nmodel natural images on four datasets through sampling, log-likelihood\nevaluation and latent variable manipulations.",
        "title": "Density estimation using Real NVP"
    },
    {
        "abs": "This paper is focused on studying the view-manifold structure in the feature\nspaces implied by the different layers of Convolutional Neural Networks (CNN).\nThere are several questions that this paper aims to answer: Does the learned\nCNN representation achieve viewpoint invariance? How does it achieve viewpoint\ninvariance? Is it achieved by collapsing the view manifolds, or separating them\nwhile preserving them? At which layer is view invariance achieved? How can the\nstructure of the view manifold at each layer of a deep convolutional neural\nnetwork be quantified experimentally? How does fine-tuning of a pre-trained CNN\non a multi-view dataset affect the representation at each layer of the network?\nIn order to answer these questions we propose a methodology to quantify the\ndeformation and degeneracy of view manifolds in CNN layers. We apply this\nmethodology and report interesting results in this paper that answer the\naforementioned questions.",
        "title": "Digging Deep into the layers of CNNs: In Search of How CNNs Achieve View Invariance"
    },
    {
        "abs": "Bilinear models provide rich representations compared with linear models.\nThey have been applied in various visual tasks, such as object recognition,\nsegmentation, and visual question-answering, to get state-of-the-art\nperformances taking advantage of the expanded representations. However,\nbilinear representations tend to be high-dimensional, limiting the\napplicability to computationally complex tasks. We propose low-rank bilinear\npooling using Hadamard product for an efficient attention mechanism of\nmultimodal learning. We show that our model outperforms compact bilinear\npooling in visual question-answering tasks with the state-of-the-art results on\nthe VQA dataset, having a better parsimonious property.",
        "title": "Hadamard Product for Low-rank Bilinear Pooling"
    },
    {
        "abs": "The standard interpretation of importance-weighted autoencoders is that they\nmaximize a tighter lower bound on the marginal likelihood than the standard\nevidence lower bound. We give an alternate interpretation of this procedure:\nthat it optimizes the standard variational lower bound, but using a more\ncomplex distribution. We formally derive this result, present a tighter lower\nbound, and visualize the implicit importance-weighted distribution.",
        "title": "Reinterpreting Importance-Weighted Autoencoders"
    },
    {
        "abs": "We present a generalization bound for feedforward neural networks in terms of\nthe product of the spectral norm of the layers and the Frobenius norm of the\nweights. The generalization bound is derived using a PAC-Bayes analysis.",
        "title": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks"
    },
    {
        "abs": "In this paper, we propose to equip Generative Adversarial Networks with the\nability to produce direct energy estimates for samples.Specifically, we propose\na flexible adversarial training framework, and prove this framework not only\nensures the generator converges to the true data distribution, but also enables\nthe discriminator to retain the density information at the global optimal. We\nderive the analytic form of the induced solution, and analyze the properties.\nIn order to make the proposed framework trainable in practice, we introduce two\neffective approximation techniques. Empirically, the experiment results closely\nmatch our theoretical analysis, verifying the discriminator is able to recover\nthe energy of data distribution.",
        "title": "Calibrating Energy-based Generative Adversarial Networks"
    },
    {
        "abs": "In this work we perform outlier detection using ensembles of neural networks\nobtained by variational approximation of the posterior in a Bayesian neural\nnetwork setting. The variational parameters are obtained by sampling from the\ntrue posterior by gradient descent. We show our outlier detection results are\ncomparable to those obtained using other efficient ensembling methods.",
        "title": "Efficient variational Bayesian neural network ensembles for outlier detection"
    },
    {
        "abs": "We present two simple ways of reducing the number of parameters and\naccelerating the training of large Long Short-Term Memory (LSTM) networks: the\nfirst one is \"matrix factorization by design\" of LSTM matrix into the product\nof two smaller matrices, and the second one is partitioning of LSTM matrix, its\ninputs and states into the independent groups. Both approaches allow us to\ntrain large LSTM networks significantly faster to the near state-of the art\nperplexity while using significantly less RNN parameters.",
        "title": "Factorization tricks for LSTM networks"
    },
    {
        "abs": "We present observations and discussion of previously unreported phenomena\ndiscovered while training residual networks. The goal of this work is to better\nunderstand the nature of neural networks through the examination of these new\nempirical results. These behaviors were identified through the application of\nCyclical Learning Rates (CLR) and linear network interpolation. Among these\nbehaviors are counterintuitive increases and decreases in training loss and\ninstances of rapid training. For example, we demonstrate how CLR can produce\ngreater testing accuracy than traditional training despite using large learning\nrates. Files to replicate these results are available at\nhttps://github.com/lnsmith54/exploring-loss",
        "title": "Exploring loss function topology with cyclical learning rates"
    },
    {
        "abs": "Machine learning models are often used at test-time subject to constraints\nand trade-offs not present at training-time. For example, a computer vision\nmodel operating on an embedded device may need to perform real-time inference,\nor a translation model operating on a cell phone may wish to bound its average\ncompute time in order to be power-efficient. In this work we describe a\nmixture-of-experts model and show how to change its test-time resource-usage on\na per-input basis using reinforcement learning. We test our method on a small\nMNIST-based example.",
        "title": "Changing Model Behavior at Test-Time Using Reinforcement Learning"
    },
    {
        "abs": "Adversarial examples have been shown to exist for a variety of deep learning\narchitectures. Deep reinforcement learning has shown promising results on\ntraining agent policies directly on raw inputs such as image pixels. In this\npaper we present a novel study into adversarial attacks on deep reinforcement\nlearning polices. We compare the effectiveness of the attacks using adversarial\nexamples vs. random noise. We present a novel method for reducing the number of\ntimes adversarial examples need to be injected for a successful attack, based\non the value function. We further explore how re-training on random noise and\nFGSM perturbations affects the resilience against adversarial examples.",
        "title": "Delving into adversarial attacks on deep policies"
    },
    {
        "abs": "This paper develops variational continual learning (VCL), a simple but\ngeneral framework for continual learning that fuses online variational\ninference (VI) and recent advances in Monte Carlo VI for neural networks. The\nframework can successfully train both deep discriminative models and deep\ngenerative models in complex continual learning settings where existing tasks\nevolve over time and entirely new tasks emerge. Experimental results show that\nVCL outperforms state-of-the-art continual learning methods on a variety of\ntasks, avoiding catastrophic forgetting in a fully automatic way.",
        "title": "Variational Continual Learning"
    },
    {
        "abs": "Automatically determining the optimal size of a neural network for a given\ntask without prior information currently requires an expensive global search\nand training many networks from scratch. In this paper, we address the problem\nof automatically finding a good network size during a single training cycle. We\nintroduce *nonparametric neural networks*, a non-probabilistic framework for\nconducting optimization over all possible network sizes and prove its soundness\nwhen network growth is limited via an L_p penalty. We train networks under this\nframework by continuously adding new units while eliminating redundant units\nvia an L_2 penalty. We employ a novel optimization algorithm, which we term\n*adaptive radial-angular gradient descent* or *AdaRad*, and obtain promising\nresults.",
        "title": "Nonparametric Neural Networks"
    },
    {
        "abs": "Natural Language Inference (NLI) task requires an agent to determine the\nlogical relationship between a natural language premise and a natural language\nhypothesis. We introduce Interactive Inference Network (IIN), a novel class of\nneural network architectures that is able to achieve high-level understanding\nof the sentence pair by hierarchically extracting semantic features from\ninteraction space. We show that an interaction tensor (attention weight)\ncontains semantic information to solve natural language inference, and a denser\ninteraction tensor contains richer semantic information. One instance of such\narchitecture, Densely Interactive Inference Network (DIIN), demonstrates the\nstate-of-the-art performance on large scale NLI copora and large-scale NLI\nalike corpus. It's noteworthy that DIIN achieve a greater than 20% error\nreduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to\nthe strongest published system.",
        "title": "Natural Language Inference over Interaction Space"
    },
    {
        "abs": "The ability to deploy neural networks in real-world, safety-critical systems\nis severely limited by the presence of adversarial examples: slightly perturbed\ninputs that are misclassified by the network. In recent years, several\ntechniques have been proposed for increasing robustness to adversarial examples\n--- and yet most of these have been quickly shown to be vulnerable to future\nattacks. For example, over half of the defenses proposed by papers accepted at\nICLR 2018 have already been broken. We propose to address this difficulty\nthrough formal verification techniques. We show how to construct provably\nminimally distorted adversarial examples: given an arbitrary neural network and\ninput sample, we can construct adversarial examples which we prove are of\nminimal distortion. Using this approach, we demonstrate that one of the recent\nICLR defense proposals, adversarial retraining, provably succeeds at increasing\nthe distortion required to construct adversarial examples by a factor of 4.2.",
        "title": "Provably Minimally-Distorted Adversarial Examples"
    },
    {
        "abs": "We extend Stochastic Gradient Variational Bayes to perform posterior\ninference for the weights of Stick-Breaking processes. This development allows\nus to define a Stick-Breaking Variational Autoencoder (SB-VAE), a Bayesian\nnonparametric version of the variational autoencoder that has a latent\nrepresentation with stochastic dimensionality. We experimentally demonstrate\nthat the SB-VAE, and a semi-supervised variant, learn highly discriminative\nlatent representations that often outperform the Gaussian VAE's.",
        "title": "Stick-Breaking Variational Autoencoders"
    },
    {
        "abs": "We propose a framework for training multiple neural networks simultaneously.\nThe parameters from all models are regularised by the tensor trace norm, so\nthat each neural network is encouraged to reuse others' parameters if possible\n-- this is the main motivation behind multi-task learning. In contrast to many\ndeep multi-task learning models, we do not predefine a parameter sharing\nstrategy by specifying which layers have tied parameters. Instead, our\nframework considers sharing for all shareable layers, and the sharing strategy\nis learned in a data-driven way.",
        "title": "Trace Norm Regularised Deep Multi-Task Learning"
    },
    {
        "abs": "This paper presents an actor-critic deep reinforcement learning agent with\nexperience replay that is stable, sample efficient, and performs remarkably\nwell on challenging environments, including the discrete 57-game Atari domain\nand several continuous control problems. To achieve this, the paper introduces\nseveral innovations, including truncated importance sampling with bias\ncorrection, stochastic dueling network architectures, and a new trust region\npolicy optimization method.",
        "title": "Sample Efficient Actor-Critic with Experience Replay"
    },
    {
        "abs": "Many machine learning classifiers are vulnerable to adversarial\nperturbations. An adversarial perturbation modifies an input to change a\nclassifier's prediction without causing the input to seem substantially\ndifferent to human perception. We deploy three methods to detect adversarial\nimages. Adversaries trying to bypass our detectors must make the adversarial\nimage less pathological or they will fail trying. Our best detection method\nreveals that adversarial images place abnormal emphasis on the lower-ranked\nprincipal components from PCA. Other detectors and a colorful saliency map are\nin an appendix.",
        "title": "Early Methods for Detecting Adversarial Images"
    },
    {
        "abs": "We propose a principled method for kernel learning, which relies on a\nFourier-analytic characterization of translation-invariant or\nrotation-invariant kernels. Our method produces a sequence of feature maps,\niteratively refining the SVM margin. We provide rigorous guarantees for\noptimality and generalization, interpreting our algorithm as online\nequilibrium-finding dynamics in a certain two-player min-max game. Evaluations\non synthetic and real-world datasets demonstrate scalability and consistent\nimprovements over related random features-based methods.",
        "title": "Not-So-Random Features"
    },
    {
        "abs": "State-of-the-art deep reading comprehension models are dominated by recurrent\nneural nets. Their sequential nature is a natural fit for language, but it also\nprecludes parallelization within an instances and often becomes the bottleneck\nfor deploying such models to latency critical scenarios. This is particularly\nproblematic for longer texts. Here we present a convolutional architecture as\nan alternative to these recurrent architectures. Using simple dilated\nconvolutional units in place of recurrent ones, we achieve results comparable\nto the state of the art on two question answering tasks, while at the same time\nachieving up to two orders of magnitude speedups for question answering.",
        "title": "Fast Reading Comprehension with ConvNets"
    },
    {
        "abs": "This report has several purposes. First, our report is written to investigate\nthe reproducibility of the submitted paper On the regularization of Wasserstein\nGANs (2018). Second, among the experiments performed in the submitted paper,\nfive aspects were emphasized and reproduced: learning speed, stability,\nrobustness against hyperparameter, estimating the Wasserstein distance, and\nvarious sampling method. Finally, we identify which parts of the contribution\ncan be reproduced, and at what cost in terms of resources. All source code for\nreproduction is open to the public.",
        "title": "On reproduction of On the regularization of Wasserstein GANs"
    },
    {
        "abs": "Variational Autoencoders (VAEs) were originally motivated (Kingma & Welling,\n2014) as probabilistic generative models in which one performs approximate\nBayesian inference. The proposal of $\\beta$-VAEs (Higgins et al., 2017) breaks\nthis interpretation and generalizes VAEs to application domains beyond\ngenerative modeling (e.g., representation learning, clustering, or lossy data\ncompression) by introducing an objective function that allows practitioners to\ntrade off between the information content (\"bit rate\") of the latent\nrepresentation and the distortion of reconstructed data (Alemi et al., 2018).\nIn this paper, we reconsider this rate/distortion trade-off in the context of\nhierarchical VAEs, i.e., VAEs with more than one layer of latent variables. We\nidentify a general class of inference models for which one can split the rate\ninto contributions from each layer, which can then be tuned independently. We\nderive theoretical bounds on the performance of downstream tasks as functions\nof the individual layers' rates and verify our theoretical findings in\nlarge-scale experiments. Our results provide guidance for practitioners on\nwhich region in rate-space to target for a given application.",
        "title": "Trading Information between Latents in Hierarchical Variational Autoencoders"
    },
    {
        "abs": "Methods that learn representations of nodes in a graph play a critical role\nin network analysis since they enable many downstream learning tasks. We\npropose Graph2Gauss - an approach that can efficiently learn versatile node\nembeddings on large scale (attributed) graphs that show strong performance on\ntasks such as link prediction and node classification. Unlike most approaches\nthat represent nodes as point vectors in a low-dimensional continuous space, we\nembed each node as a Gaussian distribution, allowing us to capture uncertainty\nabout the representation. Furthermore, we propose an unsupervised method that\nhandles inductive learning scenarios and is applicable to different types of\ngraphs: plain/attributed, directed/undirected. By leveraging both the network\nstructure and the associated node attributes, we are able to generalize to\nunseen nodes without additional training. To learn the embeddings we adopt a\npersonalized ranking formulation w.r.t. the node distances that exploits the\nnatural ordering of the nodes imposed by the network structure. Experiments on\nreal world networks demonstrate the high performance of our approach,\noutperforming state-of-the-art network embedding methods on several different\ntasks. Additionally, we demonstrate the benefits of modeling uncertainty - by\nanalyzing it we can estimate neighborhood diversity and detect the intrinsic\nlatent dimensionality of a graph.",
        "title": "Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking"
    },
    {
        "abs": "This paper explores the use of self-ensembling for visual domain adaptation\nproblems. Our technique is derived from the mean teacher variant (Tarvainen et\nal., 2017) of temporal ensembling (Laine et al;, 2017), a technique that\nachieved state of the art results in the area of semi-supervised learning. We\nintroduce a number of modifications to their approach for challenging domain\nadaptation scenarios and evaluate its effectiveness. Our approach achieves\nstate of the art results in a variety of benchmarks, including our winning\nentry in the VISDA-2017 visual domain adaptation challenge. In small image\nbenchmarks, our algorithm not only outperforms prior art, but can also achieve\naccuracy that is close to that of a classifier trained in a supervised fashion.",
        "title": "Self-ensembling for visual domain adaptation"
    },
    {
        "abs": "Most machine learning classifiers, including deep neural networks, are\nvulnerable to adversarial examples. Such inputs are typically generated by\nadding small but purposeful modifications that lead to incorrect outputs while\nimperceptible to human eyes. The goal of this paper is not to introduce a\nsingle method, but to make theoretical steps towards fully understanding\nadversarial examples. By using concepts from topology, our theoretical analysis\nbrings forth the key reasons why an adversarial example can fool a classifier\n($f_1$) and adds its oracle ($f_2$, like human eyes) in such analysis. By\ninvestigating the topological relationship between two (pseudo)metric spaces\ncorresponding to predictor $f_1$ and oracle $f_2$, we develop necessary and\nsufficient conditions that can determine if $f_1$ is always robust\n(strong-robust) against adversarial examples according to $f_2$. Interestingly\nour theorems indicate that just one unnecessary feature can make $f_1$ not\nstrong-robust, and the right feature representation learning is the key to\ngetting a classifier that is both accurate and strong-robust.",
        "title": "A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Examples"
    },
    {
        "abs": "We develop a general problem setting for training and testing the ability of\nagents to gather information efficiently. Specifically, we present a collection\nof tasks in which success requires searching through a partially-observed\nenvironment, for fragments of information which can be pieced together to\naccomplish various goals. We combine deep architectures with techniques from\nreinforcement learning to develop agents that solve our tasks. We shape the\nbehavior of these agents by combining extrinsic and intrinsic rewards. We\nempirically demonstrate that these agents learn to search actively and\nintelligently for new information to reduce their uncertainty, and to exploit\ninformation they have already acquired.",
        "title": "Towards Information-Seeking Agents"
    },
    {
        "abs": "We propose an extension to neural network language models to adapt their\nprediction to the recent history. Our model is a simplified version of memory\naugmented networks, which stores past hidden activations as memory and accesses\nthem through a dot product with the current hidden activation. This mechanism\nis very efficient and scales to very large memory sizes. We also draw a link\nbetween the use of external memory in neural network and cache models used with\ncount based language models. We demonstrate on several language model datasets\nthat our approach performs significantly better than recent memory augmented\nnetworks.",
        "title": "Improving Neural Language Models with a Continuous Cache"
    },
    {
        "abs": "Generative adversarial networks (GANs) are successful deep generative models.\nGANs are based on a two-player minimax game. However, the objective function\nderived in the original motivation is changed to obtain stronger gradients when\nlearning the generator. We propose a novel algorithm that repeats the density\nratio estimation and f-divergence minimization. Our algorithm offers a new\nperspective toward the understanding of GANs and is able to make use of\nmultiple viewpoints obtained in the research of density ratio estimation, e.g.\nwhat divergence is stable and relative density ratio is useful.",
        "title": "Generative Adversarial Nets from a Density Ratio Estimation Perspective"
    },
    {
        "abs": "We present a novel framework for generating pop music. Our model is a\nhierarchical Recurrent Neural Network, where the layers and the structure of\nthe hierarchy encode our prior knowledge about how pop music is composed. In\nparticular, the bottom layers generate the melody, while the higher levels\nproduce the drums and chords. We conduct several human studies that show strong\npreference of our generated music over that produced by the recent method by\nGoogle. We additionally show two applications of our framework: neural dancing\nand karaoke, as well as neural story singing.",
        "title": "Song From PI: A Musically Plausible Network for Pop Music Generation"
    },
    {
        "abs": "We look at the eigenvalues of the Hessian of a loss function before and after\ntraining. The eigenvalue distribution is seen to be composed of two parts, the\nbulk which is concentrated around zero, and the edges which are scattered away\nfrom zero. We present empirical evidence for the bulk indicating how\nover-parametrized the system is, and for the edges that depend on the input\ndata.",
        "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond"
    },
    {
        "abs": "In this paper, we propose a new feature extraction technique for program\nexecution logs. First, we automatically extract complex patterns from a\nprogram's behavior graph. Then, we embed these patterns into a continuous space\nby training an autoencoder. We evaluate the proposed features on a real-world\nmalicious software detection task. We also find that the embedding space\ncaptures interpretable structures in the space of pattern parts.",
        "title": "Semantic embeddings for program behavior patterns"
    },
    {
        "abs": "We compared the efficiency of the FlyHash model, an insect-inspired sparse\nneural network (Dasgupta et al., 2017), to similar but non-sparse models in an\nembodied navigation task. This requires a model to control steering by\ncomparing current visual inputs to memories stored along a training route. We\nconcluded the FlyHash model is more efficient than others, especially in terms\nof data encoding.",
        "title": "Vision-based route following by an embodied insect-inspired sparse neural network"
    },
    {
        "abs": "In peer review, reviewers are usually asked to provide scores for the papers.\nThe scores are then used by Area Chairs or Program Chairs in various ways in\nthe decision-making process. The scores are usually elicited in a quantized\nform to accommodate the limited cognitive ability of humans to describe their\nopinions in numerical values. It has been found that the quantized scores\nsuffer from a large number of ties, thereby leading to a significant loss of\ninformation. To mitigate this issue, conferences have started to ask reviewers\nto additionally provide a ranking of the papers they have reviewed. There are\nhowever two key challenges. First, there is no standard procedure for using\nthis ranking information and Area Chairs may use it in different ways\n(including simply ignoring them), thereby leading to arbitrariness in the\npeer-review process. Second, there are no suitable interfaces for judicious use\nof this data nor methods to incorporate it in existing workflows, thereby\nleading to inefficiencies. We take a principled approach to integrate the\nranking information into the scores. The output of our method is an updated\nscore pertaining to each review that also incorporates the rankings. Our\napproach addresses the two aforementioned challenges by: (i) ensuring that\nrankings are incorporated into the updates scores in the same manner for all\npapers, thereby mitigating arbitrariness, and (ii) allowing to seamlessly use\nexisting interfaces and workflows designed for scores. We empirically evaluate\nour method on synthetic datasets as well as on peer reviews from the ICLR 2017\nconference, and find that it reduces the error by approximately 30% as compared\nto the best performing baseline on the ICLR 2017 data.",
        "title": "Integrating Rankings into Quantized Scores in Peer Review"
    },
    {
        "abs": "Many recent studies have probed status bias in the peer-review process of\nacademic journals and conferences. In this article, we investigated the\nassociation between author metadata and area chairs' final decisions\n(Accept/Reject) using our compiled database of 5,313 borderline submissions to\nthe International Conference on Learning Representations (ICLR) from 2017 to\n2022. We carefully defined elements in a cause-and-effect analysis, including\nthe treatment and its timing, pre-treatment variables, potential outcomes and\ncausal null hypothesis of interest, all in the context of study units being\ntextual data and under Neyman and Rubin's potential outcomes (PO) framework. We\nfound some weak evidence that author metadata was associated with articles'\nfinal decisions. We also found that, under an additional stability assumption,\nborderline articles from high-ranking institutions (top-30% or top-20%) were\nless favored by area chairs compared to their matched counterparts. The results\nwere consistent in two different matched designs (odds ratio = 0.82 [95% CI:\n0.67 to 1.00] in a first design and 0.83 [95% CI: 0.64 to 1.07] in a\nstrengthened design). We discussed how to interpret these results in the\ncontext of multiple interactions between a study unit and different agents\n(reviewers and area chairs) in the peer-review system.",
        "title": "Association between author metadata and acceptance: A feature-rich, matched observational study of a corpus of ICLR submissions between 2017-2022"
    },
    {
        "abs": "We present a variational approximation to the information bottleneck of\nTishby et al. (1999). This variational approach allows us to parameterize the\ninformation bottleneck model using a neural network and leverage the\nreparameterization trick for efficient training. We call this method \"Deep\nVariational Information Bottleneck\", or Deep VIB. We show that models trained\nwith the VIB objective outperform those that are trained with other forms of\nregularization, in terms of generalization performance and robustness to\nadversarial attack.",
        "title": "Deep Variational Information Bottleneck"
    },
    {
        "abs": "Attention networks have proven to be an effective approach for embedding\ncategorical inference within a deep neural network. However, for many tasks we\nmay want to model richer structural dependencies without abandoning end-to-end\ntraining. In this work, we experiment with incorporating richer structural\ndistributions, encoded using graphical models, within deep networks. We show\nthat these structured attention networks are simple extensions of the basic\nattention procedure, and that they allow for extending attention beyond the\nstandard soft-selection approach, such as attending to partial segmentations or\nto subtrees. We experiment with two different classes of structured attention\nnetworks: a linear-chain conditional random field and a graph-based parsing\nmodel, and describe how these models can be practically implemented as neural\nnetwork layers. Experiments show that this approach is effective for\nincorporating structural biases, and structured attention networks outperform\nbaseline attention models on a variety of synthetic and real tasks: tree\ntransduction, neural machine translation, question answering, and natural\nlanguage inference. We further find that models trained in this way learn\ninteresting unsupervised hidden representations that generalize simple\nattention.",
        "title": "Structured Attention Networks"
    },
    {
        "abs": "We are proposing to use an ensemble of diverse specialists, where speciality\nis defined according to the confusion matrix. Indeed, we observed that for\nadversarial instances originating from a given class, labeling tend to be done\ninto a small subset of (incorrect) classes. Therefore, we argue that an\nensemble of specialists should be better able to identify and reject fooling\ninstances, with a high entropy (i.e., disagreement) over the decisions in the\npresence of adversaries. Experimental results obtained confirm that\ninterpretation, opening a way to make the system more robust to adversarial\nexamples through a rejection mechanism, rather than trying to classify them\nproperly at any cost.",
        "title": "Robustness to Adversarial Examples through an Ensemble of Specialists"
    },
    {
        "abs": "In this paper, we present Neural Phrase-based Machine Translation (NPMT). Our\nmethod explicitly models the phrase structures in output sequences using\nSleep-WAke Networks (SWAN), a recently proposed segmentation-based sequence\nmodeling method. To mitigate the monotonic alignment requirement of SWAN, we\nintroduce a new layer to perform (soft) local reordering of input sequences.\nDifferent from existing neural machine translation (NMT) approaches, NPMT does\nnot use attention-based decoding mechanisms. Instead, it directly outputs\nphrases in a sequential order and can decode in linear time. Our experiments\nshow that NPMT achieves superior performances on IWSLT 2014\nGerman-English/English-German and IWSLT 2015 English-Vietnamese machine\ntranslation tasks compared with strong NMT baselines. We also observe that our\nmethod produces meaningful phrases in output languages.",
        "title": "Towards Neural Phrase-based Machine Translation"
    },
    {
        "abs": "We present LR-GAN: an adversarial image generation model which takes scene\nstructure and context into account. Unlike previous generative adversarial\nnetworks (GANs), the proposed GAN learns to generate image background and\nforegrounds separately and recursively, and stitch the foregrounds on the\nbackground in a contextually relevant manner to produce a complete natural\nimage. For each foreground, the model learns to generate its appearance, shape\nand pose. The whole model is unsupervised, and is trained in an end-to-end\nmanner with gradient descent methods. The experiments demonstrate that LR-GAN\ncan generate more natural images with objects that are more human recognizable\nthan DCGAN.",
        "title": "LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation"
    },
    {
        "abs": "We describe a simple scheme that allows an agent to learn about its\nenvironment in an unsupervised manner. Our scheme pits two versions of the same\nagent, Alice and Bob, against one another. Alice proposes a task for Bob to\ncomplete; and then Bob attempts to complete the task. In this work we will\nfocus on two kinds of environments: (nearly) reversible environments and\nenvironments that can be reset. Alice will \"propose\" the task by doing a\nsequence of actions and then Bob must undo or repeat them, respectively. Via an\nappropriate reward structure, Alice and Bob automatically generate a curriculum\nof exploration, enabling unsupervised training of the agent. When Bob is\ndeployed on an RL task within the environment, this unsupervised training\nreduces the number of supervised episodes needed to learn, and in some cases\nconverges to a higher reward.",
        "title": "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play"
    },
    {
        "abs": "Maximum entropy modeling is a flexible and popular framework for formulating\nstatistical models given partial knowledge. In this paper, rather than the\ntraditional method of optimizing over the continuous density directly, we learn\na smooth and invertible transformation that maps a simple distribution to the\ndesired maximum entropy distribution. Doing so is nontrivial in that the\nobjective being maximized (entropy) is a function of the density itself. By\nexploiting recent developments in normalizing flow networks, we cast the\nmaximum entropy problem into a finite-dimensional constrained optimization, and\nsolve the problem by combining stochastic optimization with the augmented\nLagrangian method. Simulation results demonstrate the effectiveness of our\nmethod, and applications to finance and computer vision show the flexibility\nand accuracy of using maximum entropy flow networks.",
        "title": "Maximum Entropy Flow Networks"
    },
    {
        "abs": "With machine learning successfully applied to new daunting problems almost\nevery day, general AI starts looking like an attainable goal. However, most\ncurrent research focuses instead on important but narrow applications, such as\nimage classification or machine translation. We believe this to be largely due\nto the lack of objective ways to measure progress towards broad machine\nintelligence. In order to fill this gap, we propose here a set of concrete\ndesiderata for general AI, together with a platform to test machines on how\nwell they satisfy such desiderata, while keeping all further complexities to a\nminimum.",
        "title": "CommAI: Evaluating the first steps towards a useful general AI"
    },
    {
        "abs": "Neural networks that compute over graph structures are a natural fit for\nproblems in a variety of domains, including natural language (parse trees) and\ncheminformatics (molecular graphs). However, since the computation graph has a\ndifferent shape and size for every input, such networks do not directly support\nbatched training or inference. They are also difficult to implement in popular\ndeep learning libraries, which are based on static data-flow graphs. We\nintroduce a technique called dynamic batching, which not only batches together\noperations between different input graphs of dissimilar shape, but also between\ndifferent nodes within a single input graph. The technique allows us to create\nstatic graphs, using popular libraries, that emulate dynamic computation graphs\nof arbitrary shape and size. We further present a high-level library of\ncompositional blocks that simplifies the creation of dynamic graph models.\nUsing the library, we demonstrate concise and batch-wise parallel\nimplementations for a variety of models from the literature.",
        "title": "Deep Learning with Dynamic Computation Graphs"
    },
    {
        "abs": "Although deep learning models have proven effective at solving problems in\nnatural language processing, the mechanism by which they come to their\nconclusions is often unclear. As a result, these models are generally treated\nas black boxes, yielding no insight of the underlying learned patterns. In this\npaper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new\napproach for tracking the importance of a given input to the LSTM for a given\noutput. By identifying consistently important patterns of words, we are able to\ndistill state of the art LSTMs on sentiment analysis and question answering\ninto a set of representative phrases. This representation is then\nquantitatively validated by using the extracted phrases to construct a simple,\nrule-based classifier which approximates the output of the LSTM.",
        "title": "Automatic Rule Extraction from Long Short Term Memory Networks"
    },
    {
        "abs": "Deep reinforcement learning has achieved many impressive results in recent\nyears. However, tasks with sparse rewards or long horizons continue to pose\nsignificant challenges. To tackle these important problems, we propose a\ngeneral framework that first learns useful skills in a pre-training\nenvironment, and then leverages the acquired skills for learning faster in\ndownstream tasks. Our approach brings together some of the strengths of\nintrinsic motivation and hierarchical methods: the learning of useful skill is\nguided by a single proxy reward, the design of which requires very minimal\ndomain knowledge about the downstream tasks. Then a high-level policy is\ntrained on top of these skills, providing a significant improvement of the\nexploration and allowing to tackle sparse rewards in the downstream tasks. To\nefficiently pre-train a large span of skills, we use Stochastic Neural Networks\ncombined with an information-theoretic regularizer. Our experiments show that\nthis combination is effective in learning a wide span of interpretable skills\nin a sample-efficient way, and can significantly boost the learning performance\nuniformly across a wide range of downstream tasks.",
        "title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning"
    },
    {
        "abs": "Deep generative models have achieved impressive success in recent years.\nGenerative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as\nemerging families for generative model learning, have largely been considered\nas two distinct paradigms and received extensive independent studies\nrespectively. This paper aims to establish formal connections between GANs and\nVAEs through a new formulation of them. We interpret sample generation in GANs\nas performing posterior inference, and show that GANs and VAEs involve\nminimizing KL divergences of respective posterior and inference distributions\nwith opposite directions, extending the two learning phases of classic\nwake-sleep algorithm, respectively. The unified view provides a powerful tool\nto analyze a diverse set of existing model variants, and enables to transfer\ntechniques across research lines in a principled way. For example, we apply the\nimportance weighting method in VAE literatures for improved GAN learning, and\nenhance VAEs with an adversarial mechanism that leverages generated samples.\nExperiments show generality and effectiveness of the transferred techniques.",
        "title": "On Unifying Deep Generative Models"
    },
    {
        "abs": "We consider the problem of detecting out-of-distribution images in neural\nnetworks. We propose ODIN, a simple and effective method that does not require\nany change to a pre-trained neural network. Our method is based on the\nobservation that using temperature scaling and adding small perturbations to\nthe input can separate the softmax score distributions between in- and\nout-of-distribution images, allowing for more effective detection. We show in a\nseries of experiments that ODIN is compatible with diverse network\narchitectures and datasets. It consistently outperforms the baseline approach\nby a large margin, establishing a new state-of-the-art performance on this\ntask. For example, ODIN reduces the false positive rate from the baseline 34.7%\nto 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is\n95%.",
        "title": "Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks"
    },
    {
        "abs": "A framework is presented for unsupervised learning of representations based\non infomax principle for large-scale neural populations. We use an asymptotic\napproximation to the Shannon's mutual information for a large neural population\nto demonstrate that a good initial approximation to the global\ninformation-theoretic optimum can be obtained by a hierarchical infomax method.\nStarting from the initial solution, an efficient algorithm based on gradient\ndescent of the final objective function is proposed to learn representations\nfrom the input datasets, and the method works for complete, overcomplete, and\nundercomplete bases. As confirmed by numerical experiments, our method is\nrobust and highly efficient for extracting salient features from input\ndatasets. Compared with the main existing methods, our algorithm has a distinct\nadvantage in both the training speed and the robustness of unsupervised\nrepresentation learning. Furthermore, the proposed method is easily extended to\nthe supervised or unsupervised model for training deep structure networks.",
        "title": "An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax"
    },
    {
        "abs": "Recurrent Neural Networks (RNNs) continue to show outstanding performance in\nsequence modeling tasks. However, training RNNs on long sequences often face\nchallenges like slow inference, vanishing gradients and difficulty in capturing\nlong term dependencies. In backpropagation through time settings, these issues\nare tightly coupled with the large, sequential computational graph resulting\nfrom unfolding the RNN in time. We introduce the Skip RNN model which extends\nexisting RNN models by learning to skip state updates and shortens the\neffective size of the computational graph. This model can also be encouraged to\nperform fewer state updates through a budget constraint. We evaluate the\nproposed model on various tasks and show how it can reduce the number of\nrequired RNN updates while preserving, and sometimes even improving, the\nperformance of the baseline RNN models. Source code is publicly available at\nhttps://imatge-upc.github.io/skiprnn-2017-telecombcn/ .",
        "title": "Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks"
    },
    {
        "abs": "Restart techniques are common in gradient-free optimization to deal with\nmultimodal functions. Partial warm restarts are also gaining popularity in\ngradient-based optimization to improve the rate of convergence in accelerated\ngradient schemes to deal with ill-conditioned functions. In this paper, we\npropose a simple warm restart technique for stochastic gradient descent to\nimprove its anytime performance when training deep neural networks. We\nempirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where\nwe demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively.\nWe also demonstrate its advantages on a dataset of EEG recordings and on a\ndownsampled version of the ImageNet dataset. Our source code is available at\nhttps://github.com/loshchil/SGDR",
        "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"
    },
    {
        "abs": "Policy gradient methods have achieved remarkable successes in solving\nchallenging reinforcement learning problems. However, it still often suffers\nfrom the large variance issue on policy gradient estimation, which leads to\npoor sample efficiency during training. In this work, we propose a control\nvariate method to effectively reduce variance for policy gradient methods.\nMotivated by the Stein's identity, our method extends the previous control\nvariate methods used in REINFORCE and advantage actor-critic by introducing\nmore general action-dependent baseline functions. Empirical studies show that\nour method significantly improves the sample efficiency of the state-of-the-art\npolicy gradient approaches.",
        "title": "Action-depedent Control Variates for Policy Optimization via Stein's Identity"
    },
    {
        "abs": "Skip connections made the training of very deep networks possible and have\nbecome an indispensable component in a variety of neural architectures. A\ncompletely satisfactory explanation for their success remains elusive. Here, we\npresent a novel explanation for the benefits of skip connections in training\nvery deep networks. The difficulty of training deep networks is partly due to\nthe singularities caused by the non-identifiability of the model. Several such\nsingularities have been identified in previous works: (i) overlap singularities\ncaused by the permutation symmetry of nodes in a given layer, (ii) elimination\nsingularities corresponding to the elimination, i.e. consistent deactivation,\nof nodes, (iii) singularities generated by the linear dependence of the nodes.\nThese singularities cause degenerate manifolds in the loss landscape that slow\ndown learning. We argue that skip connections eliminate these singularities by\nbreaking the permutation symmetry of nodes, by reducing the possibility of node\nelimination and by making the nodes less linearly dependent. Moreover, for\ntypical initializations, skip connections move the network away from the\n\"ghosts\" of these singularities and sculpt the landscape around them to\nalleviate the learning slow-down. These hypotheses are supported by evidence\nfrom simplified models, as well as from experiments with deep networks trained\non real-world datasets.",
        "title": "Skip Connections Eliminate Singularities"
    },
    {
        "abs": "We have tried to reproduce the results of the paper \"Natural Language\nInference over Interaction Space\" submitted to ICLR 2018 conference as part of\nthe ICLR 2018 Reproducibility Challenge. Initially, we were not aware that the\ncode was available, so we started to implement the network from scratch. We\nhave evaluated our version of the model on Stanford NLI dataset and reached\n86.38% accuracy on the test set, while the paper claims 88.0% accuracy. The\nmain difference, as we understand it, comes from the optimizers and the way\nmodel selection is performed.",
        "title": "Natural Language Inference over Interaction Space: ICLR 2018 Reproducibility Report"
    },
    {
        "abs": "We have successfully implemented the \"Learn to Pay Attention\" model of\nattention mechanism in convolutional neural networks, and have replicated the\nresults of the original paper in the categories of image classification and\nfine-grained recognition.",
        "title": "Reproduction Report on \"Learn to Pay Attention\""
    },
    {
        "abs": "Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose a method to learn such\nrepresentations by encoding the suffixes of word sequences in a sentence and\ntraining on the Stanford Natural Language Inference (SNLI) dataset. We\ndemonstrate the effectiveness of our approach by evaluating it on the SentEval\nbenchmark, improving on existing approaches on several transfer tasks.",
        "title": "SufiSent - Universal Sentence Representations Using Suffix Encodings"
    },
    {
        "abs": "In many neural models, new features as polynomial functions of existing ones\nare used to augment representations. Using the natural language inference task\nas an example, we investigate the use of scaled polynomials of degree 2 and\nabove as matching features. We find that scaling degree 2 features has the\nhighest impact on performance, reducing classification error by 5% in the best\nmodels.",
        "title": "On the scaling of polynomial features for representation matching"
    },
    {
        "abs": "We present a generalization bound for feedforward neural networks in terms of\nthe product of the spectral norm of the layers and the Frobenius norm of the\nweights. The generalization bound is derived using a PAC-Bayes analysis.",
        "title": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks"
    },
    {
        "abs": "In this work, we investigate Batch Normalization technique and propose its\nprobabilistic interpretation. We propose a probabilistic model and show that\nBatch Normalization maximazes the lower bound of its marginalized\nlog-likelihood. Then, according to the new probabilistic model, we design an\nalgorithm which acts consistently during train and test. However, inference\nbecomes computationally inefficient. To reduce memory and computational cost,\nwe propose Stochastic Batch Normalization -- an efficient approximation of\nproper inference procedure. This method provides us with a scalable uncertainty\nestimation technique. We demonstrate the performance of Stochastic Batch\nNormalization on popular architectures (including deep convolutional\narchitectures: VGG-like and ResNets) for MNIST and CIFAR-10 datasets.",
        "title": "Uncertainty Estimation via Stochastic Batch Normalization"
    },
    {
        "abs": "It is widely believed that the success of deep convolutional networks is\nbased on progressively discarding uninformative variability about the input\nwith respect to the problem at hand. This is supported empirically by the\ndifficulty of recovering images from their hidden representations, in most\ncommonly used network architectures. In this paper we show via a one-to-one\nmapping that this loss of information is not a necessary condition to learn\nrepresentations that generalize well on complicated problems, such as ImageNet.\nVia a cascade of homeomorphic layers, we build the i-RevNet, a network that can\nbe fully inverted up to the final projection onto the classes, i.e. no\ninformation is discarded. Building an invertible architecture is difficult, for\none, because the local inversion is ill-conditioned, we overcome this by\nproviding an explicit inverse. An analysis of i-RevNets learned representations\nsuggests an alternative explanation for the success of deep networks by a\nprogressive contraction and linear separation with depth. To shed light on the\nnature of the model learned by the i-RevNet we reconstruct linear\ninterpolations between natural image representations.",
        "title": "i-RevNet: Deep Invertible Networks"
    },
    {
        "abs": "Deep latent variable models are powerful tools for representation learning.\nIn this paper, we adopt the deep information bottleneck model, identify its\nshortcomings and propose a model that circumvents them. To this end, we apply a\ncopula transformation which, by restoring the invariance properties of the\ninformation bottleneck method, leads to disentanglement of the features in the\nlatent space. Building on that, we show how this transformation translates to\nsparsity of the latent space in the new model. We evaluate our method on\nartificial and real data.",
        "title": "Learning Sparse Latent Representations with the Deep Copula Information Bottleneck"
    },
    {
        "abs": "We introduce a variant of the MAC model (Hudson and Manning, ICLR 2018) with\na simplified set of equations that achieves comparable accuracy, while training\nfaster. We evaluate both models on CLEVR and CoGenT, and show that, transfer\nlearning with fine-tuning results in a 15 point increase in accuracy, matching\nthe state of the art. Finally, in contrast, we demonstrate that improper\nfine-tuning can actually reduce a model's accuracy as well.",
        "title": "On transfer learning using a MAC model variant"
    },
    {
        "abs": "Adaptive Computation Time for Recurrent Neural Networks (ACT) is one of the\nmost promising architectures for variable computation. ACT adapts to the input\nsequence by being able to look at each sample more than once, and learn how\nmany times it should do it. In this paper, we compare ACT to Repeat-RNN, a\nnovel architecture based on repeating each sample a fixed number of times. We\nfound surprising results, where Repeat-RNN performs as good as ACT in the\nselected tasks. Source code in TensorFlow and PyTorch is publicly available at\nhttps://imatge-upc.github.io/danifojo-2018-repeatrnn/",
        "title": "Comparing Fixed and Adaptive Computation Time for Recurrent Neural Networks"
    },
    {
        "abs": "Generative adversarial networks (GANs) are able to model the complex\nhighdimensional distributions of real-world data, which suggests they could be\neffective for anomaly detection. However, few works have explored the use of\nGANs for the anomaly detection task. We leverage recently developed GAN models\nfor anomaly detection, and achieve state-of-the-art performance on image and\nnetwork intrusion datasets, while being several hundred-fold faster at test\ntime than the only published GAN-based method.",
        "title": "Efficient GAN-Based Anomaly Detection"
    },
    {
        "abs": "Natural Language Inference (NLI) task requires an agent to determine the\nlogical relationship between a natural language premise and a natural language\nhypothesis. We introduce Interactive Inference Network (IIN), a novel class of\nneural network architectures that is able to achieve high-level understanding\nof the sentence pair by hierarchically extracting semantic features from\ninteraction space. We show that an interaction tensor (attention weight)\ncontains semantic information to solve natural language inference, and a denser\ninteraction tensor contains richer semantic information. One instance of such\narchitecture, Densely Interactive Inference Network (DIIN), demonstrates the\nstate-of-the-art performance on large scale NLI copora and large-scale NLI\nalike corpus. It's noteworthy that DIIN achieve a greater than 20% error\nreduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to\nthe strongest published system.",
        "title": "Natural Language Inference over Interaction Space"
    },
    {
        "abs": "The ability to deploy neural networks in real-world, safety-critical systems\nis severely limited by the presence of adversarial examples: slightly perturbed\ninputs that are misclassified by the network. In recent years, several\ntechniques have been proposed for increasing robustness to adversarial examples\n--- and yet most of these have been quickly shown to be vulnerable to future\nattacks. For example, over half of the defenses proposed by papers accepted at\nICLR 2018 have already been broken. We propose to address this difficulty\nthrough formal verification techniques. We show how to construct provably\nminimally distorted adversarial examples: given an arbitrary neural network and\ninput sample, we can construct adversarial examples which we prove are of\nminimal distortion. Using this approach, we demonstrate that one of the recent\nICLR defense proposals, adversarial retraining, provably succeeds at increasing\nthe distortion required to construct adversarial examples by a factor of 4.2.",
        "title": "Provably Minimally-Distorted Adversarial Examples"
    },
    {
        "abs": "Deep neural networks (DNNs) have achieved impressive predictive performance\ndue to their ability to learn complex, non-linear relationships between\nvariables. However, the inability to effectively visualize these relationships\nhas led to DNNs being characterized as black boxes and consequently limited\ntheir applications. To ameliorate this problem, we introduce the use of\nhierarchical interpretations to explain DNN predictions through our proposed\nmethod, agglomerative contextual decomposition (ACD). Given a prediction from a\ntrained DNN, ACD produces a hierarchical clustering of the input features,\nalong with the contribution of each cluster to the final prediction. This\nhierarchy is optimized to identify clusters of features that the DNN learned\nare predictive. Using examples from Stanford Sentiment Treebank and ImageNet,\nwe show that ACD is effective at diagnosing incorrect predictions and\nidentifying dataset bias. Through human experiments, we demonstrate that ACD\nenables users both to identify the more accurate of two DNNs and to better\ntrust a DNN's outputs. We also find that ACD's hierarchy is largely robust to\nadversarial perturbations, implying that it captures fundamental aspects of the\ninput and ignores spurious noise.",
        "title": "Hierarchical interpretations for neural network predictions"
    },
    {
        "abs": "In this work, we address the problem of musical timbre transfer, where the\ngoal is to manipulate the timbre of a sound sample from one instrument to match\nanother instrument while preserving other musical content, such as pitch,\nrhythm, and loudness. In principle, one could apply image-based style transfer\ntechniques to a time-frequency representation of an audio signal, but this\ndepends on having a representation that allows independent manipulation of\ntimbre as well as high-quality waveform generation. We introduce TimbreTron, a\nmethod for musical timbre transfer which applies \"image\" domain style transfer\nto a time-frequency representation of the audio signal, and then produces a\nhigh-quality waveform using a conditional WaveNet synthesizer. We show that the\nConstant Q Transform (CQT) representation is particularly well-suited to\nconvolutional architectures due to its approximate pitch equivariance. Based on\nhuman perceptual evaluations, we confirmed that TimbreTron recognizably\ntransferred the timbre while otherwise preserving the musical content, for both\nmonophonic and polyphonic samples.",
        "title": "TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer"
    },
    {
        "abs": "We consider the task of word-level language modeling and study the\npossibility of combining hidden-states-based short-term representations with\nmedium-term representations encoded in dynamical weights of a language model.\nOur work extends recent experiments on language models with dynamically\nevolving weights by casting the language modeling problem into an online\nlearning-to-learn framework in which a meta-learner is trained by\ngradient-descent to continuously update a language model weights.",
        "title": "Meta-Learning a Dynamical Language Model"
    },
    {
        "abs": "GANS are powerful generative models that are able to model the manifold of\nnatural images. We leverage this property to perform manifold regularization by\napproximating the Laplacian norm using a Monte Carlo approximation that is\neasily computed with the GAN. When incorporated into the feature-matching GAN\nof Improved GAN, we achieve state-of-the-art results for GAN-based\nsemi-supervised learning on the CIFAR-10 dataset, with a method that is\nsignificantly easier to implement than competing methods.",
        "title": "Semi-Supervised Learning with GANs: Revisiting Manifold Regularization"
    },
    {
        "abs": "We identify a class of over-parameterized deep neural networks with standard\nactivation functions and cross-entropy loss which provably have no bad local\nvalley, in the sense that from any point in parameter space there exists a\ncontinuous path on which the cross-entropy loss is non-increasing and gets\narbitrarily close to zero. This implies that these networks have no sub-optimal\nstrict local minima.",
        "title": "On the loss landscape of a class of deep neural networks with no bad local valleys"
    },
    {
        "abs": "Visual Question Answering (VQA) models have struggled with counting objects\nin natural images so far. We identify a fundamental problem due to soft\nattention in these models as a cause. To circumvent this problem, we propose a\nneural network component that allows robust counting from object proposals.\nExperiments on a toy task show the effectiveness of this component and we\nobtain state-of-the-art accuracy on the number category of the VQA v2 dataset\nwithout negatively affecting other categories, even outperforming ensemble\nmodels with our single model. On a difficult balanced pair metric, the\ncomponent gives a substantial improvement in counting over a strong baseline by\n6.6%.",
        "title": "Learning to Count Objects in Natural Images for Visual Question Answering"
    },
    {
        "abs": "One of the challenges in the study of generative adversarial networks is the\ninstability of its training. In this paper, we propose a novel weight\nnormalization technique called spectral normalization to stabilize the training\nof the discriminator. Our new normalization technique is computationally light\nand easy to incorporate into existing implementations. We tested the efficacy\nof spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we\nexperimentally confirmed that spectrally normalized GANs (SN-GANs) is capable\nof generating images of better or equal quality relative to the previous\ntraining stabilization techniques.",
        "title": "Spectral Normalization for Generative Adversarial Networks"
    },
    {
        "abs": "Embedding graph nodes into a vector space can allow the use of machine\nlearning to e.g. predict node classes, but the study of node embedding\nalgorithms is immature compared to the natural language processing field\nbecause of a diverse nature of graphs. We examine the performance of node\nembedding algorithms with respect to graph centrality measures that\ncharacterize diverse graphs, through systematic experiments with four node\nembedding algorithms, four or five graph centralities, and six datasets.\nExperimental results give insights into the properties of node embedding\nalgorithms, which can be a basis for further research on this topic.",
        "title": "Node Centralities and Classification Performance for Characterizing Node Embedding Algorithms"
    },
    {
        "abs": "We introduce a new dataset of logical entailments for the purpose of\nmeasuring models' ability to capture and exploit the structure of logical\nexpressions against an entailment prediction task. We use this task to compare\na series of architectures which are ubiquitous in the sequence-processing\nliterature, in addition to a new model class---PossibleWorldNets---which\ncomputes entailment as a \"convolution over possible worlds\". Results show that\nconvolutional networks present the wrong inductive bias for this class of\nproblems relative to LSTM RNNs, tree-structured neural networks outperform LSTM\nRNNs due to their enhanced ability to exploit the syntax of logic, and\nPossibleWorldNets outperform all benchmarks.",
        "title": "Can Neural Networks Understand Logical Entailment?"
    },
    {
        "abs": "Neural network pruning techniques can reduce the parameter counts of trained\nnetworks by over 90%, decreasing storage requirements and improving\ncomputational performance of inference without compromising accuracy. However,\ncontemporary experience is that the sparse architectures produced by pruning\nare difficult to train from the start, which would similarly improve training\nperformance.\n  We find that a standard pruning technique naturally uncovers subnetworks\nwhose initializations made them capable of training effectively. Based on these\nresults, we articulate the \"lottery ticket hypothesis:\" dense,\nrandomly-initialized, feed-forward networks contain subnetworks (\"winning\ntickets\") that - when trained in isolation - reach test accuracy comparable to\nthe original network in a similar number of iterations. The winning tickets we\nfind have won the initialization lottery: their connections have initial\nweights that make training particularly effective.\n  We present an algorithm to identify winning tickets and a series of\nexperiments that support the lottery ticket hypothesis and the importance of\nthese fortuitous initializations. We consistently find winning tickets that are\nless than 10-20% of the size of several fully-connected and convolutional\nfeed-forward architectures for MNIST and CIFAR10. Above this size, the winning\ntickets that we find learn faster than the original network and reach higher\ntest accuracy.",
        "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
    },
    {
        "abs": "We characterize the singular values of the linear transformation associated\nwith a standard 2D multi-channel convolutional layer, enabling their efficient\ncomputation. This characterization also leads to an algorithm for projecting a\nconvolutional layer onto an operator-norm ball. We show that this is an\neffective regularizer; for example, it improves the test error of a deep\nresidual network using batch normalization on CIFAR-10 from 6.2\\% to 5.3\\%.",
        "title": "The Singular Values of Convolutional Layers"
    },
    {
        "abs": "Understanding theoretical properties of deep and locally connected nonlinear\nnetwork, such as deep convolutional neural network (DCNN), is still a hard\nproblem despite its empirical success. In this paper, we propose a novel\ntheoretical framework for such networks with ReLU nonlinearity. The framework\nexplicitly formulates data distribution, favors disentangled representations\nand is compatible with common regularization techniques such as Batch Norm. The\nframework is built upon teacher-student setting, by expanding the student\nforward/backward propagation onto the teacher's computational graph. The\nresulting model does not impose unrealistic assumptions (e.g., Gaussian inputs,\nindependence of activation, etc). Our framework could help facilitate\ntheoretical analysis of many practical issues, e.g. overfitting,\ngeneralization, disentangled representations in deep networks.",
        "title": "A theoretical framework for deep locally connected ReLU network"
    },
    {
        "abs": "We present a Neural Program Search, an algorithm to generate programs from\nnatural language description and a small number of input/output examples. The\nalgorithm combines methods from Deep Learning and Program Synthesis fields by\ndesigning rich domain-specific language (DSL) and defining efficient search\nalgorithm guided by a Seq2Tree model on it. To evaluate the quality of the\napproach we also present a semi-synthetic dataset of descriptions with test\nexamples and corresponding programs. We show that our algorithm significantly\noutperforms a sequence-to-sequence model with attention baseline.",
        "title": "Neural Program Search: Solving Programming Tasks from Description and Examples"
    },
    {
        "abs": "Most state-of-the-art neural machine translation systems, despite being\ndifferent in architectural skeletons (e.g. recurrence, convolutional), share an\nindispensable feature: the Attention. However, most existing attention methods\nare token-based and ignore the importance of phrasal alignments, the key\ningredient for the success of phrase-based statistical machine translation. In\nthis paper, we propose novel phrase-based attention methods to model n-grams of\ntokens as attention entities. We incorporate our phrase-based attentions into\nthe recently proposed Transformer network, and demonstrate that our approach\nyields improvements of 1.3 BLEU for English-to-German and 0.5 BLEU for\nGerman-to-English translation tasks on WMT newstest2014 using WMT'16 training\ndata.",
        "title": "Phrase-Based Attentions"
    },
    {
        "abs": "We introduce the problem of learning distributed representations of edits. By\ncombining a \"neural editor\" with an \"edit encoder\", our models learn to\nrepresent the salient information of an edit and can be used to apply edits to\nnew inputs. We experiment on natural language and source code edit data. Our\nevaluation yields promising results that suggest that our neural network models\nlearn to capture the structure and semantics of edits. We hope that this\ninteresting task and data source will inspire other researchers to work further\non this problem.",
        "title": "Learning to Represent Edits"
    },
    {
        "abs": "We propose a principled method for kernel learning, which relies on a\nFourier-analytic characterization of translation-invariant or\nrotation-invariant kernels. Our method produces a sequence of feature maps,\niteratively refining the SVM margin. We provide rigorous guarantees for\noptimality and generalization, interpreting our algorithm as online\nequilibrium-finding dynamics in a certain two-player min-max game. Evaluations\non synthetic and real-world datasets demonstrate scalability and consistent\nimprovements over related random features-based methods.",
        "title": "Not-So-Random Features"
    },
    {
        "abs": "This paper develops variational continual learning (VCL), a simple but\ngeneral framework for continual learning that fuses online variational\ninference (VI) and recent advances in Monte Carlo VI for neural networks. The\nframework can successfully train both deep discriminative models and deep\ngenerative models in complex continual learning settings where existing tasks\nevolve over time and entirely new tasks emerge. Experimental results show that\nVCL outperforms state-of-the-art continual learning methods on a variety of\ntasks, avoiding catastrophic forgetting in a fully automatic way.",
        "title": "Variational Continual Learning"
    },
    {
        "abs": "This report has several purposes. First, our report is written to investigate\nthe reproducibility of the submitted paper On the regularization of Wasserstein\nGANs (2018). Second, among the experiments performed in the submitted paper,\nfive aspects were emphasized and reproduced: learning speed, stability,\nrobustness against hyperparameter, estimating the Wasserstein distance, and\nvarious sampling method. Finally, we identify which parts of the contribution\ncan be reproduced, and at what cost in terms of resources. All source code for\nreproduction is open to the public.",
        "title": "On reproduction of On the regularization of Wasserstein GANs"
    },
    {
        "abs": "In this paper, we propose a new feature extraction technique for program\nexecution logs. First, we automatically extract complex patterns from a\nprogram's behavior graph. Then, we embed these patterns into a continuous space\nby training an autoencoder. We evaluate the proposed features on a real-world\nmalicious software detection task. We also find that the embedding space\ncaptures interpretable structures in the space of pattern parts.",
        "title": "Semantic embeddings for program behavior patterns"
    },
    {
        "abs": "We propose a single neural probabilistic model based on variational\nautoencoder that can be conditioned on an arbitrary subset of observed features\nand then sample the remaining features in \"one shot\". The features may be both\nreal-valued and categorical. Training of the model is performed by stochastic\nvariational Bayes. The experimental evaluation on synthetic data, as well as\nfeature imputation and image inpainting problems, shows the effectiveness of\nthe proposed approach and diversity of the generated samples.",
        "title": "Variational Autoencoder with Arbitrary Conditioning"
    },
    {
        "abs": "Variational Autoencoders (VAEs) were originally motivated (Kingma & Welling,\n2014) as probabilistic generative models in which one performs approximate\nBayesian inference. The proposal of $\\beta$-VAEs (Higgins et al., 2017) breaks\nthis interpretation and generalizes VAEs to application domains beyond\ngenerative modeling (e.g., representation learning, clustering, or lossy data\ncompression) by introducing an objective function that allows practitioners to\ntrade off between the information content (\"bit rate\") of the latent\nrepresentation and the distortion of reconstructed data (Alemi et al., 2018).\nIn this paper, we reconsider this rate/distortion trade-off in the context of\nhierarchical VAEs, i.e., VAEs with more than one layer of latent variables. We\nidentify a general class of inference models for which one can split the rate\ninto contributions from each layer, which can then be tuned independently. We\nderive theoretical bounds on the performance of downstream tasks as functions\nof the individual layers' rates and verify our theoretical findings in\nlarge-scale experiments. Our results provide guidance for practitioners on\nwhich region in rate-space to target for a given application.",
        "title": "Trading Information between Latents in Hierarchical Variational Autoencoders"
    },
    {
        "abs": "Understanding and characterizing the subspaces of adversarial examples aid in\nstudying the robustness of deep neural networks (DNNs) to adversarial\nperturbations. Very recently, Ma et al. (ICLR 2018) proposed to use local\nintrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to\nstudy adversarial subspaces. It was demonstrated that LID can be used to\ncharacterize the adversarial subspaces associated with different attack\nmethods, e.g., the Carlini and Wagner's (C&W) attack and the fast gradient sign\nattack.\n  In this paper, we use MNIST and CIFAR-10 to conduct two new sets of\nexperiments that are absent in existing LID analysis and report the limitation\nof LID in characterizing the corresponding adversarial subspaces, which are (i)\noblivious attacks and LID analysis using adversarial examples with different\nconfidence levels; and (ii) black-box transfer attacks. For (i), we find that\nthe performance of LID is very sensitive to the confidence parameter deployed\nby an attack, and the LID learned from ensembles of adversarial examples with\nvarying confidence levels surprisingly gives poor performance. For (ii), we\nfind that when adversarial examples are crafted from another DNN model, LID is\nineffective in characterizing their adversarial subspaces. These two findings\ntogether suggest the limited capability of LID in characterizing the subspaces\nof adversarial examples.",
        "title": "On the Limitation of Local Intrinsic Dimensionality for Characterizing the Subspaces of Adversarial Examples"
    },
    {
        "abs": "Generative adversarial networks (GANs) form a generative modeling approach\nknown for producing appealing samples, but they are notably difficult to train.\nOne common way to tackle this issue has been to propose new formulations of the\nGAN objective. Yet, surprisingly few studies have looked at optimization\nmethods designed for this adversarial training. In this work, we cast GAN\noptimization problems in the general variational inequality framework. Tapping\ninto the mathematical programming literature, we counter some common\nmisconceptions about the difficulties of saddle point optimization and propose\nto extend techniques designed for variational inequalities to the training of\nGANs. We apply averaging, extrapolation and a computationally cheaper variant\nthat we call extrapolation from the past to the stochastic gradient method\n(SGD) and Adam.",
        "title": "A Variational Inequality Perspective on Generative Adversarial Networks"
    },
    {
        "abs": "Neural message passing algorithms for semi-supervised classification on\ngraphs have recently achieved great success. However, for classifying a node\nthese methods only consider nodes that are a few propagation steps away and the\nsize of this utilized neighborhood is hard to extend. In this paper, we use the\nrelationship between graph convolutional networks (GCN) and PageRank to derive\nan improved propagation scheme based on personalized PageRank. We utilize this\npropagation procedure to construct a simple model, personalized propagation of\nneural predictions (PPNP), and its fast approximation, APPNP. Our model's\ntraining time is on par or faster and its number of parameters on par or lower\nthan previous models. It leverages a large, adjustable neighborhood for\nclassification and can be easily combined with any neural network. We show that\nthis model outperforms several recently proposed methods for semi-supervised\nclassification in the most thorough study done so far for GCN-like models. Our\nimplementation is available online.",
        "title": "Predict then Propagate: Graph Neural Networks meet Personalized PageRank"
    },
    {
        "abs": "We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\nthat leads to a false sense of security in defenses against adversarial\nexamples. While defenses that cause obfuscated gradients appear to defeat\niterative optimization-based attacks, we find defenses relying on this effect\ncan be circumvented. We describe characteristic behaviors of defenses\nexhibiting the effect, and for each of the three types of obfuscated gradients\nwe discover, we develop attack techniques to overcome it. In a case study,\nexamining non-certified white-box-secure defenses at ICLR 2018, we find\nobfuscated gradients are a common occurrence, with 7 of 9 defenses relying on\nobfuscated gradients. Our new attacks successfully circumvent 6 completely, and\n1 partially, in the original threat model each paper considers.",
        "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"
    },
    {
        "abs": "Methods that learn representations of nodes in a graph play a critical role\nin network analysis since they enable many downstream learning tasks. We\npropose Graph2Gauss - an approach that can efficiently learn versatile node\nembeddings on large scale (attributed) graphs that show strong performance on\ntasks such as link prediction and node classification. Unlike most approaches\nthat represent nodes as point vectors in a low-dimensional continuous space, we\nembed each node as a Gaussian distribution, allowing us to capture uncertainty\nabout the representation. Furthermore, we propose an unsupervised method that\nhandles inductive learning scenarios and is applicable to different types of\ngraphs: plain/attributed, directed/undirected. By leveraging both the network\nstructure and the associated node attributes, we are able to generalize to\nunseen nodes without additional training. To learn the embeddings we adopt a\npersonalized ranking formulation w.r.t. the node distances that exploits the\nnatural ordering of the nodes imposed by the network structure. Experiments on\nreal world networks demonstrate the high performance of our approach,\noutperforming state-of-the-art network embedding methods on several different\ntasks. Additionally, we demonstrate the benefits of modeling uncertainty - by\nanalyzing it we can estimate neighborhood diversity and detect the intrinsic\nlatent dimensionality of a graph.",
        "title": "Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking"
    },
    {
        "abs": "Convolutional Neural Networks (CNNs) have become the method of choice for\nlearning problems involving 2D planar images. However, a number of problems of\nrecent interest have created a demand for models that can analyze spherical\nimages. Examples include omnidirectional vision for drones, robots, and\nautonomous cars, molecular regression problems, and global weather and climate\nmodelling. A naive application of convolutional networks to a planar projection\nof the spherical signal is destined to fail, because the space-varying\ndistortions introduced by such a projection will make translational weight\nsharing ineffective.\n  In this paper we introduce the building blocks for constructing spherical\nCNNs. We propose a definition for the spherical cross-correlation that is both\nexpressive and rotation-equivariant. The spherical correlation satisfies a\ngeneralized Fourier theorem, which allows us to compute it efficiently using a\ngeneralized (non-commutative) Fast Fourier Transform (FFT) algorithm. We\ndemonstrate the computational efficiency, numerical accuracy, and effectiveness\nof spherical CNNs applied to 3D model recognition and atomization energy\nregression.",
        "title": "Spherical CNNs"
    },
    {
        "abs": "This paper shows how one can directly apply natural language processing (NLP)\nmethods to classification problems in cheminformatics. Connection between these\nseemingly separate fields is shown by considering standard textual\nrepresentation of compound, SMILES. The problem of activity prediction against\na target protein is considered, which is a crucial part of computer aided drug\ndesign process. Conducted experiments show that this way one can not only\noutrank state of the art results of hand crafted representations but also gets\ndirect structural insights into the way decisions are made.",
        "title": "Learning to SMILE(S)"
    },
    {
        "abs": "The inclusion of Computer Vision and Deep Learning technologies in\nAgriculture aims to increase the harvest quality, and productivity of farmers.\nDuring postharvest, the export market and quality evaluation are affected by\nassorting of fruits and vegetables. In particular, apples are susceptible to a\nwide range of defects that can occur during harvesting or/and during the\npost-harvesting period. This paper aims to help farmers with post-harvest\nhandling by exploring if recent computer vision and deep learning methods such\nas the YOLOv3 (Redmon & Farhadi (2018)) can help in detecting healthy apples\nfrom apples with defects.",
        "title": "Apple Defect Detection Using Deep Learning Based Object Detection For Better Post Harvest Handling"
    },
    {
        "abs": "We present two simple ways of reducing the number of parameters and\naccelerating the training of large Long Short-Term Memory (LSTM) networks: the\nfirst one is \"matrix factorization by design\" of LSTM matrix into the product\nof two smaller matrices, and the second one is partitioning of LSTM matrix, its\ninputs and states into the independent groups. Both approaches allow us to\ntrain large LSTM networks significantly faster to the near state-of the art\nperplexity while using significantly less RNN parameters.",
        "title": "Factorization tricks for LSTM networks"
    },
    {
        "abs": "State-of-the-art deep reading comprehension models are dominated by recurrent\nneural nets. Their sequential nature is a natural fit for language, but it also\nprecludes parallelization within an instances and often becomes the bottleneck\nfor deploying such models to latency critical scenarios. This is particularly\nproblematic for longer texts. Here we present a convolutional architecture as\nan alternative to these recurrent architectures. Using simple dilated\nconvolutional units in place of recurrent ones, we achieve results comparable\nto the state of the art on two question answering tasks, while at the same time\nachieving up to two orders of magnitude speedups for question answering.",
        "title": "Fast Reading Comprehension with ConvNets"
    },
    {
        "abs": "In this work, we analyze the reinstatement mechanism introduced by Ritter et\nal. (2018) to reveal two classes of neurons that emerge in the agent's working\nmemory (an epLSTM cell) when trained using episodic meta-RL on an episodic\nvariant of the Harlow visual fixation task. Specifically, Abstract neurons\nencode knowledge shared across tasks, while Episodic neurons carry information\nrelevant for a specific episode's task.",
        "title": "The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL"
    },
    {
        "abs": "The rate-distortion-perception function (RDPF; Blau and Michaeli, 2019) has\nemerged as a useful tool for thinking about realism and distortion of\nreconstructions in lossy compression. Unlike the rate-distortion function,\nhowever, it is unknown whether encoders and decoders exist that achieve the\nrate suggested by the RDPF. Building on results by Li and El Gamal (2018), we\nshow that the RDPF can indeed be achieved using stochastic, variable-length\ncodes. For this class of codes, we also prove that the RDPF lower-bounds the\nachievable rate",
        "title": "A coding theorem for the rate-distortion-perception function"
    },
    {
        "abs": "In this paper, we present Neural Phrase-based Machine Translation (NPMT). Our\nmethod explicitly models the phrase structures in output sequences using\nSleep-WAke Networks (SWAN), a recently proposed segmentation-based sequence\nmodeling method. To mitigate the monotonic alignment requirement of SWAN, we\nintroduce a new layer to perform (soft) local reordering of input sequences.\nDifferent from existing neural machine translation (NMT) approaches, NPMT does\nnot use attention-based decoding mechanisms. Instead, it directly outputs\nphrases in a sequential order and can decode in linear time. Our experiments\nshow that NPMT achieves superior performances on IWSLT 2014\nGerman-English/English-German and IWSLT 2015 English-Vietnamese machine\ntranslation tasks compared with strong NMT baselines. We also observe that our\nmethod produces meaningful phrases in output languages.",
        "title": "Towards Neural Phrase-based Machine Translation"
    },
    {
        "abs": "It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks (DNNs). In this paper, we make\nthe case that sparse representations of the input data are a crucial tool for\ncombating such attacks. For linear classifiers, we show that a sparsifying\nfront end is provably effective against $\\ell_{\\infty}$-bounded attacks,\nreducing output distortion due to the attack by a factor of roughly $K / N$\nwhere $N$ is the data dimension and $K$ is the sparsity level. We then extend\nthis concept to DNNs, showing that a \"locally linear\" model can be used to\ndevelop a theoretical foundation for crafting attacks and defenses.\nExperimental results for the MNIST dataset show the efficacy of the proposed\nsparsifying front end.",
        "title": "Combating Adversarial Attacks Using Sparse Representations"
    },
    {
        "abs": "We propose a new sample-efficient methodology, called Supervised Policy\nUpdate (SPU), for deep reinforcement learning. Starting with data generated by\nthe current policy, SPU formulates and solves a constrained optimization\nproblem in the non-parameterized proximal policy space. Using supervised\nregression, it then converts the optimal non-parameterized policy to a\nparameterized policy, from which it draws new samples. The methodology is\ngeneral in that it applies to both discrete and continuous action spaces, and\ncan handle a wide variety of proximity constraints for the non-parameterized\noptimization problem. We show how the Natural Policy Gradient and Trust Region\nPolicy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization\n(PPO) problem can be addressed by this methodology. The SPU implementation is\nmuch simpler than TRPO. In terms of sample efficiency, our extensive\nexperiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and\noutperforms PPO in Atari video game tasks.",
        "title": "Supervised Policy Update for Deep Reinforcement Learning"
    },
    {
        "abs": "We present a parameterized synthetic dataset called Moving Symbols to support\nthe objective study of video prediction networks. Using several instantiations\nof the dataset in which variation is explicitly controlled, we highlight issues\nin an existing state-of-the-art approach and propose the use of a performance\nmetric with greater semantic meaning to improve experimental interpretability.\nOur dataset provides canonical test cases that will help the community better\nunderstand, and eventually improve, the representations learned by such\nnetworks in the future. Code is available at\nhttps://github.com/rszeto/moving-symbols .",
        "title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models"
    },
    {
        "abs": "This work is a part of ICLR Reproducibility Challenge 2019, we try to\nreproduce the results in the conference submission PADAM: Closing The\nGeneralization Gap of Adaptive Gradient Methods In Training Deep Neural\nNetworks. Adaptive gradient methods proposed in past demonstrate a degraded\ngeneralization performance than the stochastic gradient descent (SGD) with\nmomentum. The authors try to address this problem by designing a new\noptimization algorithm that bridges the gap between the space of Adaptive\nGradient algorithms and SGD with momentum. With this method a new tunable\nhyperparameter called partially adaptive parameter p is introduced that varies\nbetween [0, 0.5]. We build the proposed optimizer and use it to mirror the\nexperiments performed by the authors. We review and comment on the empirical\nanalysis performed by the authors. Finally, we also propose a future direction\nfor further study of Padam. Our code is available at:\nhttps://github.com/yashkant/Padam-Tensorflow",
        "title": "ICLR Reproducibility Challenge Report (Padam : Closing The Generalization Gap Of Adaptive Gradient Methods in Training Deep Neural Networks)"
    },
    {
        "abs": "We present a large-scale empirical study of catastrophic forgetting (CF) in\nmodern Deep Neural Network (DNN) models that perform sequential (or:\nincremental) learning. A new experimental protocol is proposed that enforces\ntypical constraints encountered in application scenarios. As the investigation\nis empirical, we evaluate CF behavior on the hitherto largest number of visual\nclassification datasets, from each of which we construct a representative\nnumber of Sequential Learning Tasks (SLTs) in close alignment to previous works\non CF. Our results clearly indicate that there is no model that avoids CF for\nall investigated datasets and SLTs under application conditions. We conclude\nwith a discussion of potential solutions and workarounds to CF, notably for the\nEWC and IMM models.",
        "title": "A comprehensive, application-oriented study of catastrophic forgetting in DNNs"
    },
    {
        "abs": "Deep learning models for graphs have advanced the state of the art on many\ntasks. Despite their recent success, little is known about their robustness. We\ninvestigate training time attacks on graph neural networks for node\nclassification that perturb the discrete graph structure. Our core principle is\nto use meta-gradients to solve the bilevel problem underlying training-time\nattacks, essentially treating the graph as a hyperparameter to optimize. Our\nexperiments show that small graph perturbations consistently lead to a strong\ndecrease in performance for graph convolutional networks, and even transfer to\nunsupervised embeddings. Remarkably, the perturbations created by our algorithm\ncan misguide the graph neural networks such that they perform worse than a\nsimple baseline that ignores all relational information. Our attacks do not\nassume any knowledge about or access to the target classifiers.",
        "title": "Adversarial Attacks on Graph Neural Networks via Meta Learning"
    },
    {
        "abs": "Multi-domain learning (MDL) aims at obtaining a model with minimal average\nrisk across multiple domains. Our empirical motivation is automated microscopy\ndata, where cultured cells are imaged after being exposed to known and unknown\nchemical perturbations, and each dataset displays significant experimental\nbias. This paper presents a multi-domain adversarial learning approach, MuLANN,\nto leverage multiple datasets with overlapping but distinct class sets, in a\nsemi-supervised setting. Our contributions include: i) a bound on the average-\nand worst-domain risk in MDL, obtained using the H-divergence; ii) a new loss\nto accommodate semi-supervised multi-domain learning and domain adaptation;\niii) the experimental validation of the approach, improving on the state of the\nart on two standard image benchmarks, and a novel bioimage dataset, Cell.",
        "title": "Multi-Domain Adversarial Learning"
    },
    {
        "abs": "We propose a neural network for unsupervised anomaly detection with a novel\nrobust subspace recovery layer (RSR layer). This layer seeks to extract the\nunderlying subspace from a latent representation of the given data and removes\noutliers that lie away from this subspace. It is used within an autoencoder.\nThe encoder maps the data into a latent space, from which the RSR layer\nextracts the subspace. The decoder then smoothly maps back the underlying\nsubspace to a \"manifold\" close to the original inliers. Inliers and outliers\nare distinguished according to the distances between the original and mapped\npositions (small for inliers and large for outliers). Extensive numerical\nexperiments with both image and document datasets demonstrate state-of-the-art\nprecision and recall.",
        "title": "Robust Subspace Recovery Layer for Unsupervised Anomaly Detection"
    },
    {
        "abs": "Deep neural networks (DNNs) have achieved impressive predictive performance\ndue to their ability to learn complex, non-linear relationships between\nvariables. However, the inability to effectively visualize these relationships\nhas led to DNNs being characterized as black boxes and consequently limited\ntheir applications. To ameliorate this problem, we introduce the use of\nhierarchical interpretations to explain DNN predictions through our proposed\nmethod, agglomerative contextual decomposition (ACD). Given a prediction from a\ntrained DNN, ACD produces a hierarchical clustering of the input features,\nalong with the contribution of each cluster to the final prediction. This\nhierarchy is optimized to identify clusters of features that the DNN learned\nare predictive. Using examples from Stanford Sentiment Treebank and ImageNet,\nwe show that ACD is effective at diagnosing incorrect predictions and\nidentifying dataset bias. Through human experiments, we demonstrate that ACD\nenables users both to identify the more accurate of two DNNs and to better\ntrust a DNN's outputs. We also find that ACD's hierarchy is largely robust to\nadversarial perturbations, implying that it captures fundamental aspects of the\ninput and ignores spurious noise.",
        "title": "Hierarchical interpretations for neural network predictions"
    },
    {
        "abs": "In this work, we address the problem of musical timbre transfer, where the\ngoal is to manipulate the timbre of a sound sample from one instrument to match\nanother instrument while preserving other musical content, such as pitch,\nrhythm, and loudness. In principle, one could apply image-based style transfer\ntechniques to a time-frequency representation of an audio signal, but this\ndepends on having a representation that allows independent manipulation of\ntimbre as well as high-quality waveform generation. We introduce TimbreTron, a\nmethod for musical timbre transfer which applies \"image\" domain style transfer\nto a time-frequency representation of the audio signal, and then produces a\nhigh-quality waveform using a conditional WaveNet synthesizer. We show that the\nConstant Q Transform (CQT) representation is particularly well-suited to\nconvolutional architectures due to its approximate pitch equivariance. Based on\nhuman perceptual evaluations, we confirmed that TimbreTron recognizably\ntransferred the timbre while otherwise preserving the musical content, for both\nmonophonic and polyphonic samples.",
        "title": "TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer"
    },
    {
        "abs": "We propose a novel node embedding of directed graphs to statistical\nmanifolds, which is based on a global minimization of pairwise relative entropy\nand graph geodesics in a non-linear way. Each node is encoded with a\nprobability density function over a measurable space. Furthermore, we analyze\nthe connection between the geometrical properties of such embedding and their\nefficient learning procedure. Extensive experiments show that our proposed\nembedding is better in preserving the global geodesic information of graphs, as\nwell as outperforming existing embedding models on directed graphs in a variety\nof evaluation metrics, in an unsupervised setting.",
        "title": "Low-dimensional statistical manifold embedding of directed graphs"
    },
    {
        "abs": "The impressive lifelong learning in animal brains is primarily enabled by\nplastic changes in synaptic connectivity. Importantly, these changes are not\npassive, but are actively controlled by neuromodulation, which is itself under\nthe control of the brain. The resulting self-modifying abilities of the brain\nplay an important role in learning and adaptation, and are a major basis for\nbiological reinforcement learning. Here we show for the first time that\nartificial neural networks with such neuromodulated plasticity can be trained\nwith gradient descent. Extending previous work on differentiable Hebbian\nplasticity, we propose a differentiable formulation for the neuromodulation of\nplasticity. We show that neuromodulated plasticity improves the performance of\nneural networks on both reinforcement learning and supervised learning tasks.\nIn one task, neuromodulated plastic LSTMs with millions of parameters\noutperform standard LSTMs on a benchmark language modeling task (controlling\nfor the number of parameters). We conclude that differentiable neuromodulation\nof plasticity offers a powerful new framework for training neural networks.",
        "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"
    },
    {
        "abs": "Euclidean geometry has historically been the typical \"workhorse\" for machine\nlearning applications due to its power and simplicity. However, it has recently\nbeen shown that geometric spaces with constant non-zero curvature improve\nrepresentations and performance on a variety of data types and downstream\ntasks. Consequently, generative models like Variational Autoencoders (VAEs)\nhave been successfully generalized to elliptical and hyperbolic latent spaces.\nWhile these approaches work well on data with particular kinds of biases e.g.\ntree-like data for a hyperbolic VAE, there exists no generic approach unifying\nand leveraging all three models. We develop a Mixed-curvature Variational\nAutoencoder, an efficient way to train a VAE whose latent space is a product of\nconstant curvature Riemannian manifolds, where the per-component curvature is\nfixed or learnable. This generalizes the Euclidean VAE to curved latent spaces\nand recovers it when curvatures of all latent space components go to 0.",
        "title": "Mixed-curvature Variational Autoencoders"
    },
    {
        "abs": "We explore various methods for computing sentence representations from\npre-trained word embeddings without any training, i.e., using nothing but\nrandom parameterizations. Our aim is to put sentence embeddings on more solid\nfooting by 1) looking at how much modern sentence embeddings gain over random\nmethods---as it turns out, surprisingly little; and by 2) providing the field\nwith more appropriate baselines going forward---which are, as it turns out,\nquite strong. We also make important observations about proper experimental\nprotocol for sentence classification evaluation, together with recommendations\nfor future research.",
        "title": "No Training Required: Exploring Random Encoders for Sentence Classification"
    },
    {
        "abs": "Generative Adversarial Networks (GANs) are one of the most popular tools for\nlearning complex high dimensional distributions. However, generalization\nproperties of GANs have not been well understood. In this paper, we analyze the\ngeneralization of GANs in practical settings. We show that discriminators\ntrained on discrete datasets with the original GAN loss have poor\ngeneralization capability and do not approximate the theoretically optimal\ndiscriminator. We propose a zero-centered gradient penalty for improving the\ngeneralization of the discriminator by pushing it toward the optimal\ndiscriminator. The penalty guarantees the generalization and convergence of\nGANs. Experiments on synthetic and large scale datasets verify our theoretical\nanalysis.",
        "title": "Improving Generalization and Stability of Generative Adversarial Networks"
    },
    {
        "abs": "In this paper we propose to perform model ensembling in a multiclass or a\nmultilabel learning setting using Wasserstein (W.) barycenters. Optimal\ntransport metrics, such as the Wasserstein distance, allow incorporating\nsemantic side information such as word embeddings. Using W. barycenters to find\nthe consensus between models allows us to balance confidence and semantics in\nfinding the agreement between the models. We show applications of Wasserstein\nensembling in attribute-based classification, multilabel learning and image\ncaptioning generation. These results show that the W. ensembling is a viable\nalternative to the basic geometric or arithmetic mean ensembling.",
        "title": "Wasserstein Barycenter Model Ensembling"
    },
    {
        "abs": "We present a method that learns to integrate temporal information, from a\nlearned dynamics model, with ambiguous visual information, from a learned\nvision model, in the context of interacting agents. Our method is based on a\ngraph-structured variational recurrent neural network (Graph-VRNN), which is\ntrained end-to-end to infer the current state of the (partially observed)\nworld, as well as to forecast future states. We show that our method\noutperforms various baselines on two sports datasets, one based on real\nbasketball trajectories, and one generated by a soccer game engine.",
        "title": "Stochastic Prediction of Multi-Agent Interactions from Partial Observations"
    },
    {
        "abs": "Modern neural networks are over-parametrized. In particular, each rectified\nlinear hidden unit can be modified by a multiplicative factor by adjusting\ninput and output weights, without changing the rest of the network. Inspired by\nthe Sinkhorn-Knopp algorithm, we introduce a fast iterative method for\nminimizing the L2 norm of the weights, equivalently the weight decay\nregularizer. It provably converges to a unique solution. Interleaving our\nalgorithm with SGD during training improves the test accuracy. For small\nbatches, our approach offers an alternative to batch-and group-normalization on\nCIFAR-10 and ImageNet with a ResNet-18.",
        "title": "Equi-normalization of Neural Networks"
    },
    {
        "abs": "Spherical data is found in many applications. By modeling the discretized\nsphere as a graph, we can accommodate non-uniformly distributed, partial, and\nchanging samplings. Moreover, graph convolutions are computationally more\nefficient than spherical convolutions. As equivariance is desired to exploit\nrotational symmetries, we discuss how to approach rotation equivariance using\nthe graph neural network introduced in Defferrard et al. (2016). Experiments\nshow good performance on rotation-invariant learning problems. Code and\nexamples are available at https://github.com/SwissDataScienceCenter/DeepSphere",
        "title": "DeepSphere: towards an equivariant graph-based spherical CNN"
    },
    {
        "abs": "We present graph wavelet neural network (GWNN), a novel graph convolutional\nneural network (CNN), leveraging graph wavelet transform to address the\nshortcomings of previous spectral graph CNN methods that depend on graph\nFourier transform. Different from graph Fourier transform, graph wavelet\ntransform can be obtained via a fast algorithm without requiring matrix\neigendecomposition with high computational cost. Moreover, graph wavelets are\nsparse and localized in vertex domain, offering high efficiency and good\ninterpretability for graph convolution. The proposed GWNN significantly\noutperforms previous spectral graph CNNs in the task of graph-based\nsemi-supervised classification on three benchmark datasets: Cora, Citeseer and\nPubmed.",
        "title": "Graph Wavelet Neural Network"
    },
    {
        "abs": "We propose a single neural probabilistic model based on variational\nautoencoder that can be conditioned on an arbitrary subset of observed features\nand then sample the remaining features in \"one shot\". The features may be both\nreal-valued and categorical. Training of the model is performed by stochastic\nvariational Bayes. The experimental evaluation on synthetic data, as well as\nfeature imputation and image inpainting problems, shows the effectiveness of\nthe proposed approach and diversity of the generated samples.",
        "title": "Variational Autoencoder with Arbitrary Conditioning"
    },
    {
        "abs": "We present the perceptor gradients algorithm -- a novel approach to learning\nsymbolic representations based on the idea of decomposing an agent's policy\ninto i) a perceptor network extracting symbols from raw observation data and\nii) a task encoding program which maps the input symbols to output actions. We\nshow that the proposed algorithm is able to learn representations that can be\ndirectly fed into a Linear-Quadratic Regulator (LQR) or a general purpose A*\nplanner. Our experimental results confirm that the perceptor gradients\nalgorithm is able to efficiently learn transferable symbolic representations as\nwell as generate new observations according to a semantically meaningful\nspecification.",
        "title": "Learning Programmatically Structured Representations with Perceptor Gradients"
    },
    {
        "abs": "We study the robustness to symmetric label noise of GNNs training procedures.\nBy combining the nonlinear neural message-passing models (e.g. Graph\nIsomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present\na noise-tolerant approach for the graph classification task. Our experiments\nshow that test accuracy can be improved under the artificial symmetric noisy\nsetting.",
        "title": "Learning Graph Neural Networks with Noisy Labels"
    },
    {
        "abs": "The recent use of `Big Code' with state-of-the-art deep learning methods\noffers promising avenues to ease program source code writing and correction. As\na first step towards automatic code repair, we implemented a graph neural\nnetwork model that predicts token types for Javascript programs. The\npredictions achieve an accuracy above $90\\%$, which improves on previous\nsimilar work.",
        "title": "Inferring Javascript types using Graph Neural Networks"
    },
    {
        "abs": "In this paper we consider self-supervised representation learning to improve\nsample efficiency in reinforcement learning (RL). We propose a forward\nprediction objective for simultaneously learning embeddings of states and\naction sequences. These embeddings capture the structure of the environment's\ndynamics, enabling efficient policy learning. We demonstrate that our action\nembeddings alone improve the sample efficiency and peak performance of\nmodel-free RL on control from low-dimensional states. By combining state and\naction embeddings, we achieve efficient learning of high-quality policies on\ngoal-conditioned continuous control from pixel observations in only 1-2 million\nenvironment steps.",
        "title": "Dynamics-aware Embeddings"
    },
    {
        "abs": "We study the problem of learning permutation invariant representations that\ncan capture \"flexible\" notions of containment. We formalize this problem via a\nmeasure theoretic definition of multisets, and obtain a theoretically-motivated\nlearning model. We propose training this model on a novel task: predicting the\nsize of the symmetric difference (or intersection) between pairs of multisets.\nWe demonstrate that our model not only performs very well on predicting\ncontainment relations (and more effectively predicts the sizes of symmetric\ndifferences and intersections than DeepSets-based approaches with unconstrained\nobject representations), but that it also learns meaningful representations.",
        "title": "Representation Learning with Multisets"
    },
    {
        "abs": "One way to interpret trained deep neural networks (DNNs) is by inspecting\ncharacteristics that neurons in the model respond to, such as by iteratively\noptimising the model input (e.g., an image) to maximally activate specific\nneurons. However, this requires a careful selection of hyper-parameters to\ngenerate interpretable examples for each neuron of interest, and current\nmethods rely on a manual, qualitative evaluation of each setting, which is\nprohibitively slow. We introduce a new metric that uses Fr\\'echet Inception\nDistance (FID) to encourage similarity between model activations for real and\ngenerated data. This provides an efficient way to evaluate a set of generated\nexamples for each setting of hyper-parameters. We also propose a novel\nGAN-based method for generating explanations that enables an efficient search\nthrough the input space and imposes a strong prior favouring realistic outputs.\nWe apply our approach to a classification model trained to predict whether a\nmusic audio recording contains singing voice. Our results suggest that this\nproposed metric successfully selects hyper-parameters leading to interpretable\nexamples, avoiding the need for manual evaluation. Moreover, we see that\nexamples synthesised to maximise or minimise the predicted probability of\nsinging voice presence exhibit vocal or non-vocal characteristics,\nrespectively, suggesting that our approach is able to generate suitable\nexplanations for understanding concepts learned by a neural network.",
        "title": "GAN-based Generation and Automatic Selection of Explanations for Neural Networks"
    },
    {
        "abs": "We characterize the singular values of the linear transformation associated\nwith a standard 2D multi-channel convolutional layer, enabling their efficient\ncomputation. This characterization also leads to an algorithm for projecting a\nconvolutional layer onto an operator-norm ball. We show that this is an\neffective regularizer; for example, it improves the test error of a deep\nresidual network using batch normalization on CIFAR-10 from 6.2\\% to 5.3\\%.",
        "title": "The Singular Values of Convolutional Layers"
    },
    {
        "abs": "We introduce the problem of learning distributed representations of edits. By\ncombining a \"neural editor\" with an \"edit encoder\", our models learn to\nrepresent the salient information of an edit and can be used to apply edits to\nnew inputs. We experiment on natural language and source code edit data. Our\nevaluation yields promising results that suggest that our neural network models\nlearn to capture the structure and semantics of edits. We hope that this\ninteresting task and data source will inspire other researchers to work further\non this problem.",
        "title": "Learning to Represent Edits"
    },
    {
        "abs": "We propose Symplectic Recurrent Neural Networks (SRNNs) as learning\nalgorithms that capture the dynamics of physical systems from observed\ntrajectories. An SRNN models the Hamiltonian function of the system by a neural\nnetwork and furthermore leverages symplectic integration, multiple-step\ntraining and initial state optimization to address the challenging numerical\nissues associated with Hamiltonian systems. We show that SRNNs succeed reliably\non complex and noisy Hamiltonian systems. We also show how to augment the SRNN\nintegration scheme in order to handle stiff dynamical systems such as bouncing\nbilliards.",
        "title": "Symplectic Recurrent Neural Networks"
    },
    {
        "abs": "Spectral embedding is a popular technique for the representation of graph\ndata. Several regularization techniques have been proposed to improve the\nquality of the embedding with respect to downstream tasks like clustering. In\nthis paper, we explain on a simple block model the impact of the complete graph\nregularization, whereby a constant is added to all entries of the adjacency\nmatrix. Specifically, we show that the regularization forces the spectral\nembedding to focus on the largest blocks, making the representation less\nsensitive to noise or outliers. We illustrate these results on both on both\nsynthetic and real data, showing how regularization improves standard\nclustering scores.",
        "title": "Spectral embedding of regularized block models"
    },
    {
        "abs": "In this work we study locality and compositionality in the context of\nlearning representations for Zero Shot Learning (ZSL). In order to well-isolate\nthe importance of these properties in learned representations, we impose the\nadditional constraint that, differently from most recent work in ZSL, no\npre-training on different datasets (e.g. ImageNet) is performed. The results of\nour experiments show how locality, in terms of small parts of the input, and\ncompositionality, i.e. how well can the learned representations be expressed as\na function of a smaller vocabulary, are both deeply related to generalization\nand motivate the focus on more local-aware models in future research directions\nfor representation learning.",
        "title": "Locality and compositionality in zero-shot learning"
    },
    {
        "abs": "We consider training machine learning models that are fair in the sense that\ntheir performance is invariant under certain sensitive perturbations to the\ninputs. For example, the performance of a resume screening system should be\ninvariant under changes to the gender and/or ethnicity of the applicant. We\nformalize this notion of algorithmic fairness as a variant of individual\nfairness and develop a distributionally robust optimization approach to enforce\nit during training. We also demonstrate the effectiveness of the approach on\ntwo ML tasks that are susceptible to gender and racial biases.",
        "title": "Training individually fair ML models with Sensitive Subspace Robustness"
    },
    {
        "abs": "Neural message passing algorithms for semi-supervised classification on\ngraphs have recently achieved great success. However, for classifying a node\nthese methods only consider nodes that are a few propagation steps away and the\nsize of this utilized neighborhood is hard to extend. In this paper, we use the\nrelationship between graph convolutional networks (GCN) and PageRank to derive\nan improved propagation scheme based on personalized PageRank. We utilize this\npropagation procedure to construct a simple model, personalized propagation of\nneural predictions (PPNP), and its fast approximation, APPNP. Our model's\ntraining time is on par or faster and its number of parameters on par or lower\nthan previous models. It leverages a large, adjustable neighborhood for\nclassification and can be easily combined with any neural network. We show that\nthis model outperforms several recently proposed methods for semi-supervised\nclassification in the most thorough study done so far for GCN-like models. Our\nimplementation is available online.",
        "title": "Predict then Propagate: Graph Neural Networks meet Personalized PageRank"
    },
    {
        "abs": "Deep Reinforcement Learning (Deep RL) has been receiving increasingly more\nattention thanks to its encouraging performance on a variety of control tasks.\nYet, conventional regularization techniques in training neural networks (e.g.,\n$L_2$ regularization, dropout) have been largely ignored in RL methods,\npossibly because agents are typically trained and evaluated in the same\nenvironment, and because the deep RL community focuses more on high-level\nalgorithm designs. In this work, we present the first comprehensive study of\nregularization techniques with multiple policy optimization algorithms on\ncontinuous control tasks. Interestingly, we find conventional regularization\ntechniques on the policy networks can often bring large improvement, especially\non harder tasks. Our findings are shown to be robust against training\nhyperparameter variations. We also compare these techniques with the more\nwidely used entropy regularization. In addition, we study regularizing\ndifferent components and find that only regularizing the policy network is\ntypically the best. We further analyze why regularization may help\ngeneralization in RL from four perspectives - sample complexity, reward\ndistribution, weight norm, and noise robustness. We hope our study provides\nguidance for future practices in regularizing policy optimization algorithms.\nOur code is available at https://github.com/xuanlinli17/iclr2021_rlreg .",
        "title": "Regularization Matters in Policy Optimization"
    },
    {
        "abs": "We identify a class of over-parameterized deep neural networks with standard\nactivation functions and cross-entropy loss which provably have no bad local\nvalley, in the sense that from any point in parameter space there exists a\ncontinuous path on which the cross-entropy loss is non-increasing and gets\narbitrarily close to zero. This implies that these networks have no sub-optimal\nstrict local minima.",
        "title": "On the loss landscape of a class of deep neural networks with no bad local valleys"
    },
    {
        "abs": "Understanding theoretical properties of deep and locally connected nonlinear\nnetwork, such as deep convolutional neural network (DCNN), is still a hard\nproblem despite its empirical success. In this paper, we propose a novel\ntheoretical framework for such networks with ReLU nonlinearity. The framework\nexplicitly formulates data distribution, favors disentangled representations\nand is compatible with common regularization techniques such as Batch Norm. The\nframework is built upon teacher-student setting, by expanding the student\nforward/backward propagation onto the teacher's computational graph. The\nresulting model does not impose unrealistic assumptions (e.g., Gaussian inputs,\nindependence of activation, etc). Our framework could help facilitate\ntheoretical analysis of many practical issues, e.g. overfitting,\ngeneralization, disentangled representations in deep networks.",
        "title": "A theoretical framework for deep locally connected ReLU network"
    },
    {
        "abs": "Generative adversarial networks (GANs) are able to model the complex\nhighdimensional distributions of real-world data, which suggests they could be\neffective for anomaly detection. However, few works have explored the use of\nGANs for the anomaly detection task. We leverage recently developed GAN models\nfor anomaly detection, and achieve state-of-the-art performance on image and\nnetwork intrusion datasets, while being several hundred-fold faster at test\ntime than the only published GAN-based method.",
        "title": "Efficient GAN-Based Anomaly Detection"
    },
    {
        "abs": "Most state-of-the-art neural machine translation systems, despite being\ndifferent in architectural skeletons (e.g. recurrence, convolutional), share an\nindispensable feature: the Attention. However, most existing attention methods\nare token-based and ignore the importance of phrasal alignments, the key\ningredient for the success of phrase-based statistical machine translation. In\nthis paper, we propose novel phrase-based attention methods to model n-grams of\ntokens as attention entities. We incorporate our phrase-based attentions into\nthe recently proposed Transformer network, and demonstrate that our approach\nyields improvements of 1.3 BLEU for English-to-German and 0.5 BLEU for\nGerman-to-English translation tasks on WMT newstest2014 using WMT'16 training\ndata.",
        "title": "Phrase-Based Attentions"
    },
    {
        "abs": "We propose an algorithm combining calibrated prediction and generalization\nbounds from learning theory to construct confidence sets for deep neural\nnetworks with PAC guarantees---i.e., the confidence set for a given input\ncontains the true label with high probability. We demonstrate how our approach\ncan be used to construct PAC confidence sets on ResNet for ImageNet, a visual\nobject tracking model, and a dynamics model for the half-cheetah reinforcement\nlearning problem.",
        "title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction"
    },
    {
        "abs": "The rate-distortion-perception function (RDPF; Blau and Michaeli, 2019) has\nemerged as a useful tool for thinking about realism and distortion of\nreconstructions in lossy compression. Unlike the rate-distortion function,\nhowever, it is unknown whether encoders and decoders exist that achieve the\nrate suggested by the RDPF. Building on results by Li and El Gamal (2018), we\nshow that the RDPF can indeed be achieved using stochastic, variable-length\ncodes. For this class of codes, we also prove that the RDPF lower-bounds the\nachievable rate",
        "title": "A coding theorem for the rate-distortion-perception function"
    },
    {
        "abs": "We address the problem of graph classification based only on structural\ninformation. Inspired by natural language processing techniques (NLP), our\nmodel sequentially embeds information to estimate class membership\nprobabilities. Besides, we experiment with NLP-like variational regularization\ntechniques, making the model predict the next node in the sequence as it reads\nit. We experimentally show that our model achieves state-of-the-art\nclassification results on several standard molecular datasets. Finally, we\nperform a qualitative analysis and give some insights on whether the node\nprediction helps the model better classify graphs.",
        "title": "Variational Recurrent Neural Networks for Graph Classification"
    },
    {
        "abs": "Neural network pruning techniques can reduce the parameter counts of trained\nnetworks by over 90%, decreasing storage requirements and improving\ncomputational performance of inference without compromising accuracy. However,\ncontemporary experience is that the sparse architectures produced by pruning\nare difficult to train from the start, which would similarly improve training\nperformance.\n  We find that a standard pruning technique naturally uncovers subnetworks\nwhose initializations made them capable of training effectively. Based on these\nresults, we articulate the \"lottery ticket hypothesis:\" dense,\nrandomly-initialized, feed-forward networks contain subnetworks (\"winning\ntickets\") that - when trained in isolation - reach test accuracy comparable to\nthe original network in a similar number of iterations. The winning tickets we\nfind have won the initialization lottery: their connections have initial\nweights that make training particularly effective.\n  We present an algorithm to identify winning tickets and a series of\nexperiments that support the lottery ticket hypothesis and the importance of\nthese fortuitous initializations. We consistently find winning tickets that are\nless than 10-20% of the size of several fully-connected and convolutional\nfeed-forward architectures for MNIST and CIFAR10. Above this size, the winning\ntickets that we find learn faster than the original network and reach higher\ntest accuracy.",
        "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
    },
    {
        "abs": "Generative adversarial networks (GANs) form a generative modeling approach\nknown for producing appealing samples, but they are notably difficult to train.\nOne common way to tackle this issue has been to propose new formulations of the\nGAN objective. Yet, surprisingly few studies have looked at optimization\nmethods designed for this adversarial training. In this work, we cast GAN\noptimization problems in the general variational inequality framework. Tapping\ninto the mathematical programming literature, we counter some common\nmisconceptions about the difficulties of saddle point optimization and propose\nto extend techniques designed for variational inequalities to the training of\nGANs. We apply averaging, extrapolation and a computationally cheaper variant\nthat we call extrapolation from the past to the stochastic gradient method\n(SGD) and Adam.",
        "title": "A Variational Inequality Perspective on Generative Adversarial Networks"
    },
    {
        "abs": "In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning\nframework which can infer the dynamics of a physical system, given by an\nordinary differential equation (ODE), from observed state trajectories. To\nachieve better generalization with fewer training samples, SymODEN incorporates\nappropriate inductive bias by designing the associated computation graph in a\nphysics-informed manner. In particular, we enforce Hamiltonian dynamics with\ncontrol to learn the underlying dynamics in a transparent way, which can then\nbe leveraged to draw insight about relevant physical aspects of the system,\nsuch as mass and potential energy. In addition, we propose a parametrization\nwhich can enforce this Hamiltonian formalism even when the generalized\ncoordinate data is embedded in a high-dimensional space or we can only access\nvelocity data instead of generalized momentum. This framework, by offering\ninterpretable, physically-consistent models for physical systems, opens up new\npossibilities for synthesizing model-based control strategies.",
        "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control"
    },
    {
        "abs": "Graph embedding techniques have been increasingly deployed in a multitude of\ndifferent applications that involve learning on non-Euclidean data. However,\nexisting graph embedding models either fail to incorporate node attribute\ninformation during training or suffer from node attribute noise, which\ncompromises the accuracy. Moreover, very few of them scale to large graphs due\nto their high computational complexity and memory usage. In this paper we\npropose GraphZoom, a multi-level framework for improving both accuracy and\nscalability of unsupervised graph embedding algorithms. GraphZoom first\nperforms graph fusion to generate a new graph that effectively encodes the\ntopology of the original graph and the node attribute information. This fused\ngraph is then repeatedly coarsened into much smaller graphs by merging nodes\nwith high spectral similarities. GraphZoom allows any existing embedding\nmethods to be applied to the coarsened graph, before it progressively refine\nthe embeddings obtained at the coarsest level to increasingly finer graphs. We\nhave evaluated our approach on a number of popular graph datasets for both\ntransductive and inductive tasks. Our experiments show that GraphZoom can\nsubstantially increase the classification accuracy and significantly accelerate\nthe entire graph embedding process by up to 40.8x, when compared to the\nstate-of-the-art unsupervised embedding methods.",
        "title": "GraphZoom: A multi-level spectral approach for accurate and scalable graph embedding"
    },
    {
        "abs": "Distributed optimization is vital in solving large-scale machine learning\nproblems. A widely-shared feature of distributed optimization techniques is the\nrequirement that all nodes complete their assigned tasks in each computational\nepoch before the system can proceed to the next epoch. In such settings, slow\nnodes, called stragglers, can greatly slow progress. To mitigate the impact of\nstragglers, we propose an online distributed optimization method called Anytime\nMinibatch. In this approach, all nodes are given a fixed time to compute the\ngradients of as many data samples as possible. The result is a variable\nper-node minibatch size. Workers then get a fixed communication time to average\ntheir minibatch gradients via several rounds of consensus, which are then used\nto update primal variables via dual averaging. Anytime Minibatch prevents\nstragglers from holding up the system without wasting the work that stragglers\ncan complete. We present a convergence analysis and analyze the wall time\nperformance. Our numerical results show that our approach is up to 1.5 times\nfaster in Amazon EC2 and it is up to five times faster when there is greater\nvariability in compute node performance.",
        "title": "Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization"
    },
    {
        "abs": "Scaling end-to-end reinforcement learning to control real robots from vision\npresents a series of challenges, in particular in terms of sample efficiency.\nAgainst end-to-end learning, state representation learning can help learn a\ncompact, efficient and relevant representation of states that speeds up policy\nlearning, reducing the number of samples needed, and that is easier to\ninterpret. We evaluate several state representation learning methods on goal\nbased robotics tasks and propose a new unsupervised model that stacks\nrepresentations and combines strengths of several of these approaches. This\nmethod encodes all the relevant features, performs on par or better than\nend-to-end learning with better sample efficiency, and is robust to\nhyper-parameters change.",
        "title": "Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics"
    },
    {
        "abs": "A central challenge in reinforcement learning is discovering effective\npolicies for tasks where rewards are sparsely distributed. We postulate that in\nthe absence of useful reward signals, an effective exploration strategy should\nseek out {\\it decision states}. These states lie at critical junctions in the\nstate space from where the agent can transition to new, potentially unexplored\nregions. We propose to learn about decision states from prior experience. By\ntraining a goal-conditioned policy with an information bottleneck, we can\nidentify decision states by examining where the model actually leverages the\ngoal state. We find that this simple mechanism effectively identifies decision\nstates, even in partially observed settings. In effect, the model learns the\nsensory cues that correlate with potential subgoals. In new environments, this\nmodel can then identify novel subgoals for further exploration, guiding the\nagent through a sequence of potential decision states and through new regions\nof the state space.",
        "title": "InfoBot: Transfer and Exploration via the Information Bottleneck"
    },
    {
        "abs": "Multilingual machine translation, which translates multiple languages with a\nsingle model, has attracted much attention due to its efficiency of offline\ntraining and online serving. However, traditional multilingual translation\nusually yields inferior accuracy compared with the counterpart using individual\nmodels for each language pair, due to language diversity and model capacity\nlimitations. In this paper, we propose a distillation-based approach to boost\nthe accuracy of multilingual machine translation. Specifically, individual\nmodels are first trained and regarded as teachers, and then the multilingual\nmodel is trained to fit the training data and match the outputs of individual\nmodels simultaneously through knowledge distillation. Experiments on IWSLT, WMT\nand Ted talk translation datasets demonstrate the effectiveness of our method.\nParticularly, we show that one model is enough to handle multiple languages (up\nto 44 languages in our experiment), with comparable or even better accuracy\nthan individual models.",
        "title": "Multilingual Neural Machine Translation with Knowledge Distillation"
    },
    {
        "abs": "We introduce PyTorch Geometric, a library for deep learning on irregularly\nstructured input data such as graphs, point clouds and manifolds, built upon\nPyTorch. In addition to general graph data structures and processing methods,\nit contains a variety of recently published methods from the domains of\nrelational learning and 3D data processing. PyTorch Geometric achieves high\ndata throughput by leveraging sparse GPU acceleration, by providing dedicated\nCUDA kernels and by introducing efficient mini-batch handling for input\nexamples of different size. In this work, we present the library in detail and\nperform a comprehensive comparative study of the implemented methods in\nhomogeneous evaluation scenarios.",
        "title": "Fast Graph Representation Learning with PyTorch Geometric"
    },
    {
        "abs": "Although variational autoencoders (VAEs) represent a widely influential deep\ngenerative model, many aspects of the underlying energy function remain poorly\nunderstood. In particular, it is commonly believed that Gaussian\nencoder/decoder assumptions reduce the effectiveness of VAEs in generating\nrealistic samples. In this regard, we rigorously analyze the VAE objective,\ndifferentiating situations where this belief is and is not actually true. We\nthen leverage the corresponding insights to develop a simple VAE enhancement\nthat requires no additional hyperparameters or sensitive tuning.\nQuantitatively, this proposal produces crisp samples and stable FID scores that\nare actually competitive with a variety of GAN models, all while retaining\ndesirable attributes of the original VAE architecture. A shorter version of\nthis work will appear in the ICLR 2019 conference proceedings (Dai and Wipf,\n2019). The code for our model is available at https://github.com/daib13/\nTwoStageVAE.",
        "title": "Diagnosing and Enhancing VAE Models"
    },
    {
        "abs": "Adversarial training is a training scheme designed to counter adversarial\nattacks by augmenting the training dataset with adversarial examples.\nSurprisingly, several studies have observed that loss gradients from\nadversarially trained DNNs are visually more interpretable than those from\nstandard DNNs. Although this phenomenon is interesting, there are only few\nworks that have offered an explanation. In this paper, we attempted to bridge\nthis gap between adversarial robustness and gradient interpretability. To this\nend, we identified that loss gradients from adversarially trained DNNs align\nbetter with human perception because adversarial training restricts gradients\ncloser to the image manifold. We then demonstrated that adversarial training\ncauses loss gradients to be quantitatively meaningful. Finally, we showed that\nunder the adversarial training framework, there exists an empirical trade-off\nbetween test accuracy and loss gradient interpretability and proposed two\npotential approaches to resolving this trade-off.",
        "title": "Bridging Adversarial Robustness and Gradient Interpretability"
    },
    {
        "abs": "This is the proceedings of the Computer Vision for Agriculture (CV4A)\nWorkshop that was held in conjunction with the International Conference on\nLearning Representations (ICLR) 2020.\n  The Computer Vision for Agriculture (CV4A) 2020 workshop was scheduled to be\nheld in Addis Ababa, Ethiopia, on April 26th, 2020. It was held virtually that\nsame day due to the COVID-19 pandemic. The workshop was held in conjunction\nwith the International Conference on Learning Representations (ICLR) 2020.",
        "title": "Proceedings of the ICLR Workshop on Computer Vision for Agriculture (CV4A) 2020"
    },
    {
        "abs": "Proceedings of the 1st AfricaNLP Workshop held on 26th April alongside ICLR\n2020, Virtual Conference, Formerly Addis Ababa Ethiopia.",
        "title": "1st AfricaNLP Workshop Proceedings, 2020"
    },
    {
        "abs": "In this work we show preliminary results of deep multi-task learning in the\narea of computational pathology. We combine 11 tasks ranging from patch-wise\noral cancer classification, one of the most prevalent cancers in the developing\nworld, to multi-tissue nuclei instance segmentation and classification.",
        "title": "Multi-Task Learning in Histo-pathology for Widely Generalizable Model"
    },
    {
        "abs": "The principle of compositionality, which enables natural language to\nrepresent complex concepts via a structured combination of simpler ones, allows\nus to convey an open-ended set of messages using a limited vocabulary. If\ncompositionality is indeed a natural property of language, we may expect it to\nappear in communication protocols that are created by neural agents in language\ngames. In this paper, we propose an effective neural iterated learning (NIL)\nalgorithm that, when applied to interacting neural agents, facilitates the\nemergence of a more structured type of language. Indeed, these languages\nprovide learning speed advantages to neural agents during training, which can\nbe incrementally amplified via NIL. We provide a probabilistic model of NIL and\nan explanation of why the advantage of compositional language exist. Our\nexperiments confirm our analysis, and also demonstrate that the emerged\nlanguages largely improve the generalizing power of the neural agent\ncommunication.",
        "title": "Compositional Languages Emerge in a Neural Iterated Learning Model"
    },
    {
        "abs": "Text generation is ubiquitous in many NLP tasks, from summarization, to\ndialogue and machine translation. The dominant parametric approach is based on\nlocally normalized models which predict one word at a time. While these work\nremarkably well, they are plagued by exposure bias due to the greedy nature of\nthe generation process. In this work, we investigate un-normalized energy-based\nmodels (EBMs) which operate not at the token but at the sequence level. In\norder to make training tractable, we first work in the residual of a pretrained\nlocally normalized language model and second we train using noise contrastive\nestimation. Furthermore, since the EBM works at the sequence level, we can\nleverage pretrained bi-directional contextual representations, such as BERT and\nRoBERTa. Our experiments on two large language modeling datasets show that\nresidual EBMs yield lower perplexity compared to locally normalized baselines.\nMoreover, generation via importance sampling is very efficient and of higher\nquality than the baseline models according to human evaluation.",
        "title": "Residual Energy-Based Models for Text Generation"
    },
    {
        "abs": "We propose an energy-based model (EBM) of protein conformations that operates\nat atomic scale. The model is trained solely on crystallized protein data. By\ncontrast, existing approaches for scoring conformations use energy functions\nthat incorporate knowledge of physical principles and features that are the\ncomplex product of several decades of research and tuning. To evaluate the\nmodel, we benchmark on the rotamer recovery task, the problem of predicting the\nconformation of a side chain from its context within a protein structure, which\nhas been used to evaluate energy functions for protein design. The model\nachieves performance close to that of the Rosetta energy function, a\nstate-of-the-art method widely used in protein structure prediction and design.\nAn investigation of the model's outputs and hidden representations finds that\nit captures physicochemical properties relevant to protein energy.",
        "title": "Energy-based models for atomic-resolution protein conformations"
    },
    {
        "abs": "We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural\ntangent kernel and the Laplace kernel include the same set of functions, when\nboth kernels are restricted to the sphere $\\mathbb{S}^{d-1}$. Additionally, we\nprove that the exponential power kernel with a smaller power (making the kernel\nless smooth) leads to a larger RKHS, when it is restricted to the sphere\n$\\mathbb{S}^{d-1}$ and when it is defined on the entire $\\mathbb{R}^d$.",
        "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS"
    },
    {
        "abs": "We propose a novel node embedding of directed graphs to statistical\nmanifolds, which is based on a global minimization of pairwise relative entropy\nand graph geodesics in a non-linear way. Each node is encoded with a\nprobability density function over a measurable space. Furthermore, we analyze\nthe connection between the geometrical properties of such embedding and their\nefficient learning procedure. Extensive experiments show that our proposed\nembedding is better in preserving the global geodesic information of graphs, as\nwell as outperforming existing embedding models on directed graphs in a variety\nof evaluation metrics, in an unsupervised setting.",
        "title": "Low-dimensional statistical manifold embedding of directed graphs"
    },
    {
        "abs": "Euclidean geometry has historically been the typical \"workhorse\" for machine\nlearning applications due to its power and simplicity. However, it has recently\nbeen shown that geometric spaces with constant non-zero curvature improve\nrepresentations and performance on a variety of data types and downstream\ntasks. Consequently, generative models like Variational Autoencoders (VAEs)\nhave been successfully generalized to elliptical and hyperbolic latent spaces.\nWhile these approaches work well on data with particular kinds of biases e.g.\ntree-like data for a hyperbolic VAE, there exists no generic approach unifying\nand leveraging all three models. We develop a Mixed-curvature Variational\nAutoencoder, an efficient way to train a VAE whose latent space is a product of\nconstant curvature Riemannian manifolds, where the per-component curvature is\nfixed or learnable. This generalizes the Euclidean VAE to curved latent spaces\nand recovers it when curvatures of all latent space components go to 0.",
        "title": "Mixed-curvature Variational Autoencoders"
    },
    {
        "abs": "We study training of Convolutional Neural Networks (CNNs) with ReLU\nactivations and introduce exact convex optimization formulations with a\npolynomial complexity with respect to the number of data samples, the number of\nneurons, and data dimension. More specifically, we develop a convex analytic\nframework utilizing semi-infinite duality to obtain equivalent convex\noptimization problems for several two- and three-layer CNN architectures. We\nfirst prove that two-layer CNNs can be globally optimized via an $\\ell_2$ norm\nregularized convex program. We then show that multi-layer circular CNN training\nproblems with a single ReLU layer are equivalent to an $\\ell_1$ regularized\nconvex program that encourages sparsity in the spectral domain. We also extend\nthese results to three-layer CNNs with two ReLU layers. Furthermore, we present\nextensions of our approach to different pooling methods, which elucidates the\nimplicit architectural bias as convex regularizers.",
        "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time"
    },
    {
        "abs": "We propose a new metric space of ReLU activation codes equipped with a\ntruncated Hamming distance which establishes an isometry between its elements\nand polyhedral bodies in the input space which have recently been shown to be\nstrongly related to safety, robustness, and confidence. This isometry allows\nthe efficient computation of adjacency relations between the polyhedral bodies.\nExperiments on MNIST and CIFAR-10 indicate that information besides accuracy\nmight be stored in the code space.",
        "title": "ReLU Code Space: A Basis for Rating Network Quality Besides Accuracy"
    },
    {
        "abs": "This paper introduces the first dataset of satellite images labeled with\nforage quality by on-the-ground experts and provides proof of concept for\napplying computer vision methods to index-based drought insurance. We also\npresent the results of a collaborative benchmark tool used to crowdsource an\naccurate machine learning model on the dataset. Our methods significantly\noutperform the existing technology for an insurance program in Northern Kenya,\nsuggesting that a computer vision-based approach could substantially benefit\npastoralists, whose exposure to droughts is severe and worsening with climate\nchange.",
        "title": "Satellite-based Prediction of Forage Conditions for Livestock in Northern Kenya"
    },
    {
        "abs": "We propose a neural network for unsupervised anomaly detection with a novel\nrobust subspace recovery layer (RSR layer). This layer seeks to extract the\nunderlying subspace from a latent representation of the given data and removes\noutliers that lie away from this subspace. It is used within an autoencoder.\nThe encoder maps the data into a latent space, from which the RSR layer\nextracts the subspace. The decoder then smoothly maps back the underlying\nsubspace to a \"manifold\" close to the original inliers. Inliers and outliers\nare distinguished according to the distances between the original and mapped\npositions (small for inliers and large for outliers). Extensive numerical\nexperiments with both image and document datasets demonstrate state-of-the-art\nprecision and recall.",
        "title": "Robust Subspace Recovery Layer for Unsupervised Anomaly Detection"
    },
    {
        "abs": "The impressive lifelong learning in animal brains is primarily enabled by\nplastic changes in synaptic connectivity. Importantly, these changes are not\npassive, but are actively controlled by neuromodulation, which is itself under\nthe control of the brain. The resulting self-modifying abilities of the brain\nplay an important role in learning and adaptation, and are a major basis for\nbiological reinforcement learning. Here we show for the first time that\nartificial neural networks with such neuromodulated plasticity can be trained\nwith gradient descent. Extending previous work on differentiable Hebbian\nplasticity, we propose a differentiable formulation for the neuromodulation of\nplasticity. We show that neuromodulated plasticity improves the performance of\nneural networks on both reinforcement learning and supervised learning tasks.\nIn one task, neuromodulated plastic LSTMs with millions of parameters\noutperform standard LSTMs on a benchmark language modeling task (controlling\nfor the number of parameters). We conclude that differentiable neuromodulation\nof plasticity offers a powerful new framework for training neural networks.",
        "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"
    },
    {
        "abs": "The inclusion of Computer Vision and Deep Learning technologies in\nAgriculture aims to increase the harvest quality, and productivity of farmers.\nDuring postharvest, the export market and quality evaluation are affected by\nassorting of fruits and vegetables. In particular, apples are susceptible to a\nwide range of defects that can occur during harvesting or/and during the\npost-harvesting period. This paper aims to help farmers with post-harvest\nhandling by exploring if recent computer vision and deep learning methods such\nas the YOLOv3 (Redmon & Farhadi (2018)) can help in detecting healthy apples\nfrom apples with defects.",
        "title": "Apple Defect Detection Using Deep Learning Based Object Detection For Better Post Harvest Handling"
    },
    {
        "abs": "Recent advances in neural machine translation (NMT) have led to\nstate-of-the-art results for many European-based translation tasks. However,\ndespite these advances, there is has been little focus in applying these\nmethods to African languages. In this paper, we seek to address this gap by\ncreating an NMT benchmark BLEU score between English and the ten remaining\nofficial languages in South Africa.",
        "title": "Neural Machine Translation for South Africa's Official Languages"
    },
    {
        "abs": "We propose an algorithm combining calibrated prediction and generalization\nbounds from learning theory to construct confidence sets for deep neural\nnetworks with PAC guarantees---i.e., the confidence set for a given input\ncontains the true label with high probability. We demonstrate how our approach\ncan be used to construct PAC confidence sets on ResNet for ImageNet, a visual\nobject tracking model, and a dynamics model for the half-cheetah reinforcement\nlearning problem.",
        "title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction"
    },
    {
        "abs": "With the recent success and popularity of pre-trained language models (LMs)\nin natural language processing, there has been a rise in efforts to understand\ntheir inner workings. In line with such interest, we propose a novel method\nthat assists us in investigating the extent to which pre-trained LMs capture\nthe syntactic notion of constituency. Our method provides an effective way of\nextracting constituency trees from the pre-trained LMs without training. In\naddition, we report intriguing findings in the induced trees, including the\nfact that pre-trained LMs outperform other approaches in correctly demarcating\nadverb phrases in sentences.",
        "title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction"
    },
    {
        "abs": "Magnitude-based pruning is one of the simplest methods for pruning neural\nnetworks. Despite its simplicity, magnitude-based pruning and its variants\ndemonstrated remarkable performances for pruning modern architectures. Based on\nthe observation that magnitude-based pruning indeed minimizes the Frobenius\ndistortion of a linear operator corresponding to a single layer, we develop a\nsimple pruning method, coined lookahead pruning, by extending the single layer\noptimization to a multi-layer optimization. Our experimental results\ndemonstrate that the proposed method consistently outperforms magnitude-based\npruning on various networks, including VGG and ResNet, particularly in the\nhigh-sparsity regime. See https://github.com/alinlab/lookahead_pruning for\ncodes.",
        "title": "Lookahead: A Far-Sighted Alternative of Magnitude-based Pruning"
    },
    {
        "abs": "As the share of renewable energy sources in the present electric energy mix\nrises, their intermittence proves to be the biggest challenge to carbon free\nelectricity generation. To address this challenge, we propose an electricity\npricing agent, which sends price signals to the customers and contributes to\nshifting the customer demand to periods of high renewable energy generation. We\npropose an implementation of a pricing agent with a reinforcement learning\napproach where the environment is represented by the customers, the electricity\ngeneration utilities and the weather conditions.",
        "title": "Advancing Renewable Electricity Consumption With Reinforcement Learning"
    },
    {
        "abs": "We report our experiments in building a domain-specific Tigrinya-to-English\nneural machine translation system. We use transfer learning from other Ge'ez\nscript languages and report an improvement of 1.3 BLEU points over a classic\nneural baseline. We publish our development pipeline as an open-source library\nand also provide a demonstration application.",
        "title": "Tigrinya Neural Machine Translation with Transfer Learning for Humanitarian Response"
    },
    {
        "abs": "Nigerian Pidgin is arguably the most widely spoken language in Nigeria.\nVariants of this language are also spoken across West and Central Africa,\nmaking it a very important language. This work aims to establish supervised and\nunsupervised neural machine translation (NMT) baselines between English and\nNigerian Pidgin. We implement and compare NMT models with different\ntokenization methods, creating a solid foundation for future works.",
        "title": "Towards Supervised and Unsupervised Neural Machine Translation Baselines for Nigerian Pidgin"
    },
    {
        "abs": "Estimating grape yield prior to harvest is important to commercial vineyard\nproduction as it informs many vineyard and winery decisions. Currently, the\nprocess of yield estimation is time consuming and varies in its accuracy from\n75-90\\% depending on the experience of the viticulturist. This paper proposes a\nmultiple task learning (MTL) convolutional neural network (CNN) approach that\nuses images captured by inexpensive smart phones secured in a simple tripod\narrangement. The CNN models use MTL transfer from autoencoders to achieve 85\\%\naccuracy from image data captured 6 days prior to harvest.",
        "title": "Estimating Grape Yield on the Vine from Multiple Images"
    },
    {
        "abs": "Automatic change detection and disaster damage assessment are currently\nprocedures requiring a huge amount of labor and manual work by satellite\nimagery analysts. In the occurrences of natural disasters, timely change\ndetection can save lives. In this work, we report findings on problem framing,\ndata processing and training procedures which are specifically helpful for the\ntask of building damage assessment using the newly released xBD dataset. Our\ninsights lead to substantial improvement over the xBD baseline models, and we\nscore among top results on the xView2 challenge leaderboard. We release our\ncode used for the competition.",
        "title": "Building Disaster Damage Assessment in Satellite Imagery with Multi-Temporal Fusion"
    },
    {
        "abs": "Recurrent neural networks (RNNs) are non-linear dynamic systems. Previous\nwork believes that RNN may suffer from the phenomenon of chaos, where the\nsystem is sensitive to initial states and unpredictable in the long run. In\nthis paper, however, we perform a systematic empirical analysis, showing that a\nvanilla or long short term memory (LSTM) RNN does not exhibit chaotic behavior\nalong the training process in real applications such as text generation. Our\nfindings suggest that future work in this direction should address the other\nside of non-linear dynamics for RNN.",
        "title": "How Chaotic Are Recurrent Neural Networks?"
    },
    {
        "abs": "Fine-tuning a pretrained BERT model is the state of the art method for\nextractive/abstractive text summarization, in this paper we showcase how this\nfine-tuning method can be applied to the Arabic language to both construct the\nfirst documented model for abstractive Arabic text summarization and show its\nperformance in Arabic extractive summarization. Our model works with\nmultilingual BERT (as Arabic language does not have a pretrained BERT of its\nown). We show its performance in English corpus first before applying it to\nArabic corpora in both extractive and abstractive tasks.",
        "title": "BERT Fine-tuning For Arabic Text Summarization"
    },
    {
        "abs": "During cluster analysis domain experts and visual analysis are frequently\nrelied on to identify the optimal clustering structure. This process tends to\nbe adhoc, subjective and difficult to reproduce. This work shows how competency\nquestions can be used to formalise expert knowledge and application\nrequirements for context specific evaluation of a clustering application in the\nresidential energy consumption sector.",
        "title": "Using competency questions to select optimal clustering structures for residential energy consumption patterns"
    },
    {
        "abs": "Action and observation delays commonly occur in many Reinforcement Learning\napplications, such as remote control scenarios. We study the anatomy of\nrandomly delayed environments, and show that partially resampling trajectory\nfragments in hindsight allows for off-policy multi-step value estimation. We\napply this principle to derive Delay-Correcting Actor-Critic (DCAC), an\nalgorithm based on Soft Actor-Critic with significantly better performance in\nenvironments with delays. This is shown theoretically and also demonstrated\npractically on a delay-augmented version of the MuJoCo continuous control\nbenchmark.",
        "title": "Reinforcement Learning with Random Delays"
    },
    {
        "abs": "We demonstrate that differentially private machine learning has not yet\nreached its \"AlexNet moment\" on many canonical vision tasks: linear models\ntrained on handcrafted features significantly outperform end-to-end deep neural\nnetworks for moderate privacy budgets. To exceed the performance of handcrafted\nfeatures, we show that private learning requires either much more private data,\nor access to features learned on public data from a similar domain. Our work\nintroduces simple yet strong baselines for differentially private learning that\ncan inform the evaluation of future progress in this area.",
        "title": "Differentially Private Learning Needs Better Features (or Much More Data)"
    },
    {
        "abs": "In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning\nframework which can infer the dynamics of a physical system, given by an\nordinary differential equation (ODE), from observed state trajectories. To\nachieve better generalization with fewer training samples, SymODEN incorporates\nappropriate inductive bias by designing the associated computation graph in a\nphysics-informed manner. In particular, we enforce Hamiltonian dynamics with\ncontrol to learn the underlying dynamics in a transparent way, which can then\nbe leveraged to draw insight about relevant physical aspects of the system,\nsuch as mass and potential energy. In addition, we propose a parametrization\nwhich can enforce this Hamiltonian formalism even when the generalized\ncoordinate data is embedded in a high-dimensional space or we can only access\nvelocity data instead of generalized momentum. This framework, by offering\ninterpretable, physically-consistent models for physical systems, opens up new\npossibilities for synthesizing model-based control strategies.",
        "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control"
    },
    {
        "abs": "We propose Symplectic Recurrent Neural Networks (SRNNs) as learning\nalgorithms that capture the dynamics of physical systems from observed\ntrajectories. An SRNN models the Hamiltonian function of the system by a neural\nnetwork and furthermore leverages symplectic integration, multiple-step\ntraining and initial state optimization to address the challenging numerical\nissues associated with Hamiltonian systems. We show that SRNNs succeed reliably\non complex and noisy Hamiltonian systems. We also show how to augment the SRNN\nintegration scheme in order to handle stiff dynamical systems such as bouncing\nbilliards.",
        "title": "Symplectic Recurrent Neural Networks"
    },
    {
        "abs": "Anomaly detection, finding patterns that substantially deviate from those\nseen previously, is one of the fundamental problems of artificial intelligence.\nRecently, classification-based methods were shown to achieve superior results\non this task. In this work, we present a unifying view and propose an open-set\nmethod, GOAD, to relax current generalization assumptions. Furthermore, we\nextend the applicability of transformation-based methods to non-image data\nusing random affine transformations. Our method is shown to obtain\nstate-of-the-art accuracy and is applicable to broad data types. The strong\nperformance of our method is extensively validated on multiple datasets from\ndifferent domains.",
        "title": "Classification-Based Anomaly Detection for General Data"
    },
    {
        "abs": "We consider training machine learning models that are fair in the sense that\ntheir performance is invariant under certain sensitive perturbations to the\ninputs. For example, the performance of a resume screening system should be\ninvariant under changes to the gender and/or ethnicity of the applicant. We\nformalize this notion of algorithmic fairness as a variant of individual\nfairness and develop a distributionally robust optimization approach to enforce\nit during training. We also demonstrate the effectiveness of the approach on\ntwo ML tasks that are susceptible to gender and racial biases.",
        "title": "Training individually fair ML models with Sensitive Subspace Robustness"
    },
    {
        "abs": "In this paper we consider self-supervised representation learning to improve\nsample efficiency in reinforcement learning (RL). We propose a forward\nprediction objective for simultaneously learning embeddings of states and\naction sequences. These embeddings capture the structure of the environment's\ndynamics, enabling efficient policy learning. We demonstrate that our action\nembeddings alone improve the sample efficiency and peak performance of\nmodel-free RL on control from low-dimensional states. By combining state and\naction embeddings, we achieve efficient learning of high-quality policies on\ngoal-conditioned continuous control from pixel observations in only 1-2 million\nenvironment steps.",
        "title": "Dynamics-aware Embeddings"
    },
    {
        "abs": "In this paper, we cast fair machine learning as invariant machine learning.\nWe first formulate a version of individual fairness that enforces invariance on\ncertain sensitive sets. We then design a transport-based regularizer that\nenforces this version of individual fairness and develop an algorithm to\nminimize the regularizer efficiently. Our theoretical results guarantee the\nproposed approach trains certifiably fair ML models. Finally, in the\nexperimental studies we demonstrate improved fairness metrics in comparison to\nseveral recent fair training procedures on three ML tasks that are susceptible\nto algorithmic bias.",
        "title": "SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness"
    },
    {
        "abs": "Despite significant advances, continual learning models still suffer from\ncatastrophic forgetting when exposed to incrementally available data from\nnon-stationary distributions. Rehearsal approaches alleviate the problem by\nmaintaining and replaying a small episodic memory of previous samples, often\nimplemented as an array of independent memory slots. In this work, we propose\nto augment such an array with a learnable random graph that captures pairwise\nsimilarities between its samples, and use it not only to learn new tasks but\nalso to guard against forgetting. Empirical results on several benchmark\ndatasets show that our model consistently outperforms recently proposed\nbaselines for task-free continual learning.",
        "title": "Graph-Based Continual Learning"
    },
    {
        "abs": "We provide a general self-attention formulation to impose group equivariance\nto arbitrary symmetry groups. This is achieved by defining positional encodings\nthat are invariant to the action of the group considered. Since the group acts\non the positional encoding directly, group equivariant self-attention networks\n(GSA-Nets) are steerable by nature. Our experiments on vision benchmarks\ndemonstrate consistent improvements of GSA-Nets over non-equivariant\nself-attention networks.",
        "title": "Group Equivariant Stand-Alone Self-Attention For Vision"
    },
    {
        "abs": "We propose to study the problem of few shot graph classification in graph\nneural networks (GNNs) to recognize unseen classes, given limited labeled graph\nexamples. Despite several interesting GNN variants being proposed recently for\nnode and graph classification tasks, when faced with scarce labeled examples in\nthe few shot setting, these GNNs exhibit significant loss in classification\nperformance. Here, we present an approach where a probability measure is\nassigned to each graph based on the spectrum of the graphs normalized\nLaplacian. This enables us to accordingly cluster the graph base labels\nassociated with each graph into super classes, where the Lp Wasserstein\ndistance serves as our underlying distance metric. Subsequently, a super graph\nconstructed based on the super classes is then fed to our proposed GNN\nframework which exploits the latent inter class relationships made explicit by\nthe super graph to achieve better class label separation among the graphs. We\nconduct exhaustive empirical evaluations of our proposed method and show that\nit outperforms both the adaptation of state of the art graph classification\nmethods to few shot scenario and our naive baseline GNNs. Additionally, we also\nextend and study the behavior of our method to semi supervised and active\nlearning scenarios.",
        "title": "Few-Shot Learning on Graphs via Super-Classes based on Graph Spectral Measures"
    },
    {
        "abs": "In this work, we investigate the positional encoding methods used in language\npre-training (e.g., BERT) and identify several problems in the existing\nformulations. First, we show that in the absolute positional encoding, the\naddition operation applied on positional embeddings and word embeddings brings\nmixed correlations between the two heterogeneous information resources. It may\nbring unnecessary randomness in the attention and further limit the\nexpressiveness of the model. Second, we question whether treating the position\nof the symbol \\texttt{[CLS]} the same as other words is a reasonable design,\nconsidering its special role (the representation of the entire sentence) in the\ndownstream tasks. Motivated from above analysis, we propose a new positional\nencoding method called \\textbf{T}ransformer with \\textbf{U}ntied\n\\textbf{P}ositional \\textbf{E}ncoding (TUPE). In the self-attention module,\nTUPE computes the word contextual correlation and positional correlation\nseparately with different parameterizations and then adds them together. This\ndesign removes the mixed and noisy correlations over heterogeneous embeddings\nand offers more expressiveness by using different projection matrices.\nFurthermore, TUPE unties the \\texttt{[CLS]} symbol from other positions, making\nit easier to capture information from all positions. Extensive experiments and\nablation studies on GLUE benchmark demonstrate the effectiveness of the\nproposed method. Codes and models are released at\nhttps://github.com/guolinke/TUPE.",
        "title": "Rethinking Positional Encoding in Language Pre-training"
    },
    {
        "abs": "Graph embedding techniques have been increasingly deployed in a multitude of\ndifferent applications that involve learning on non-Euclidean data. However,\nexisting graph embedding models either fail to incorporate node attribute\ninformation during training or suffer from node attribute noise, which\ncompromises the accuracy. Moreover, very few of them scale to large graphs due\nto their high computational complexity and memory usage. In this paper we\npropose GraphZoom, a multi-level framework for improving both accuracy and\nscalability of unsupervised graph embedding algorithms. GraphZoom first\nperforms graph fusion to generate a new graph that effectively encodes the\ntopology of the original graph and the node attribute information. This fused\ngraph is then repeatedly coarsened into much smaller graphs by merging nodes\nwith high spectral similarities. GraphZoom allows any existing embedding\nmethods to be applied to the coarsened graph, before it progressively refine\nthe embeddings obtained at the coarsest level to increasingly finer graphs. We\nhave evaluated our approach on a number of popular graph datasets for both\ntransductive and inductive tasks. Our experiments show that GraphZoom can\nsubstantially increase the classification accuracy and significantly accelerate\nthe entire graph embedding process by up to 40.8x, when compared to the\nstate-of-the-art unsupervised embedding methods.",
        "title": "GraphZoom: A multi-level spectral approach for accurate and scalable graph embedding"
    },
    {
        "abs": "Interpretation of Deep Neural Networks (DNNs) training as an optimal control\nproblem with nonlinear dynamical systems has received considerable attention\nrecently, yet the algorithmic development remains relatively limited. In this\nwork, we make an attempt along this line by reformulating the training\nprocedure from the trajectory optimization perspective. We first show that most\nwidely-used algorithms for training DNNs can be linked to the Differential\nDynamic Programming (DDP), a celebrated second-order method rooted in the\nApproximate Dynamic Programming. In this vein, we propose a new class of\noptimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and\nconvolution networks. DDPNOpt features layer-wise feedback policies which\nimprove convergence and reduce sensitivity to hyper-parameter over existing\nmethods. It outperforms other optimal-control inspired training methods in both\nconvergence and complexity, and is competitive against state-of-the-art first\nand second order methods. We also observe DDPNOpt has surprising benefit in\npreventing gradient vanishing. Our work opens up new avenues for principled\nalgorithmic design built upon the optimal control theory.",
        "title": "DDPNOpt: Differential Dynamic Programming Neural Optimizer"
    },
    {
        "abs": "In this paper, we investigate the effects of releasing arXiv preprints of\npapers that are undergoing a double-blind review process. In particular, we ask\nthe following research question: What is the relation between de-anonymization\nof authors through arXiv preprints and acceptance of a research paper at a\n(nominally) double-blind venue? Under two conditions: papers that are released\non arXiv before the review phase and papers that are not, we examine the\ncorrelation between the reputation of their authors with the review scores and\nacceptance decisions. By analyzing a dataset of ICLR 2020 and ICLR 2019\nsubmissions (n=5050), we find statistically significant evidence of positive\ncorrelation between percentage acceptance and papers with high reputation\nreleased on arXiv. In order to understand this observed association better, we\nperform additional analyses based on self-specified confidence scores of\nreviewers and observe that less confident reviewers are more likely to assign\nhigh review scores to papers with well known authors and low review scores to\npapers with less known authors, where reputation is quantified in terms of\nnumber of Google Scholar citations. We emphasize upfront that our results are\npurely correlational and we neither can nor intend to make any causal claims. A\nblog post accompanying the paper and our scraping code will be linked in the\nproject website https://sites.google.com/view/deanon-arxiv/home",
        "title": "De-anonymization of authors through arXiv submissions during double-blind review"
    },
    {
        "abs": "Reinforcement learning (RL) has achieved impressive performance in a variety\nof online settings in which an agent's ability to query the environment for\ntransitions and rewards is effectively unlimited. However, in many practical\napplications, the situation is reversed: an agent may have access to large\namounts of undirected offline experience data, while access to the online\nenvironment is severely limited. In this work, we focus on this offline\nsetting. Our main insight is that, when presented with offline data composed of\na variety of behaviors, an effective way to leverage this data is to extract a\ncontinuous space of recurring and temporally extended primitive behaviors\nbefore using these primitives for downstream task learning. Primitives\nextracted in this way serve two purposes: they delineate the behaviors that are\nsupported by the data from those that are not, making them useful for avoiding\ndistributional shift in offline RL; and they provide a degree of temporal\nabstraction, which reduces the effective horizon yielding better learning in\ntheory, and improved offline RL in practice. In addition to benefiting offline\npolicy optimization, we show that performing offline primitive learning in this\nway can also be leveraged for improving few-shot imitation learning as well as\nexploration and transfer in online RL on a variety of benchmark domains.\nVisualizations are available at https://sites.google.com/view/opal-iclr",
        "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning"
    },
    {
        "abs": "Stochastic Gradient Descent (SGD) and its variants are mainstream methods for\ntraining deep networks in practice. SGD is known to find a flat minimum that\noften generalizes well. However, it is mathematically unclear how deep learning\ncan select a flat minimum among so many minima. To answer the question\nquantitatively, we develop a density diffusion theory (DDT) to reveal how\nminima selection quantitatively depends on the minima sharpness and the\nhyperparameters. To the best of our knowledge, we are the first to\ntheoretically and empirically prove that, benefited from the Hessian-dependent\ncovariance of stochastic gradient noise, SGD favors flat minima exponentially\nmore than sharp minima, while Gradient Descent (GD) with injected white noise\nfavors flat minima only polynomially more than sharp minima. We also reveal\nthat either a small learning rate or large-batch training requires\nexponentially many iterations to escape from minima in terms of the ratio of\nthe batch size and learning rate. Thus, large-batch training cannot search flat\nminima efficiently in a realistic computational time.",
        "title": "A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima"
    },
    {
        "abs": "Spectral embedding is a popular technique for the representation of graph\ndata. Several regularization techniques have been proposed to improve the\nquality of the embedding with respect to downstream tasks like clustering. In\nthis paper, we explain on a simple block model the impact of the complete graph\nregularization, whereby a constant is added to all entries of the adjacency\nmatrix. Specifically, we show that the regularization forces the spectral\nembedding to focus on the largest blocks, making the representation less\nsensitive to noise or outliers. We illustrate these results on both on both\nsynthetic and real data, showing how regularization improves standard\nclustering scores.",
        "title": "Spectral embedding of regularized block models"
    },
    {
        "abs": "In this work we study locality and compositionality in the context of\nlearning representations for Zero Shot Learning (ZSL). In order to well-isolate\nthe importance of these properties in learned representations, we impose the\nadditional constraint that, differently from most recent work in ZSL, no\npre-training on different datasets (e.g. ImageNet) is performed. The results of\nour experiments show how locality, in terms of small parts of the input, and\ncompositionality, i.e. how well can the learned representations be expressed as\na function of a smaller vocabulary, are both deeply related to generalization\nand motivate the focus on more local-aware models in future research directions\nfor representation learning.",
        "title": "Locality and compositionality in zero-shot learning"
    },
    {
        "abs": "We study the problem of learning permutation invariant representations that\ncan capture \"flexible\" notions of containment. We formalize this problem via a\nmeasure theoretic definition of multisets, and obtain a theoretically-motivated\nlearning model. We propose training this model on a novel task: predicting the\nsize of the symmetric difference (or intersection) between pairs of multisets.\nWe demonstrate that our model not only performs very well on predicting\ncontainment relations (and more effectively predicts the sizes of symmetric\ndifferences and intersections than DeepSets-based approaches with unconstrained\nobject representations), but that it also learns meaningful representations.",
        "title": "Representation Learning with Multisets"
    },
    {
        "abs": "Deep Reinforcement Learning (Deep RL) has been receiving increasingly more\nattention thanks to its encouraging performance on a variety of control tasks.\nYet, conventional regularization techniques in training neural networks (e.g.,\n$L_2$ regularization, dropout) have been largely ignored in RL methods,\npossibly because agents are typically trained and evaluated in the same\nenvironment, and because the deep RL community focuses more on high-level\nalgorithm designs. In this work, we present the first comprehensive study of\nregularization techniques with multiple policy optimization algorithms on\ncontinuous control tasks. Interestingly, we find conventional regularization\ntechniques on the policy networks can often bring large improvement, especially\non harder tasks. Our findings are shown to be robust against training\nhyperparameter variations. We also compare these techniques with the more\nwidely used entropy regularization. In addition, we study regularizing\ndifferent components and find that only regularizing the policy network is\ntypically the best. We further analyze why regularization may help\ngeneralization in RL from four perspectives - sample complexity, reward\ndistribution, weight norm, and noise robustness. We hope our study provides\nguidance for future practices in regularizing policy optimization algorithms.\nOur code is available at https://github.com/xuanlinli17/iclr2021_rlreg .",
        "title": "Regularization Matters in Policy Optimization"
    },
    {
        "abs": "The Receptive Field (RF) size has been one of the most important factors for\nOne Dimensional Convolutional Neural Networks (1D-CNNs) on time series\nclassification tasks. Large efforts have been taken to choose the appropriate\nsize because it has a huge influence on the performance and differs\nsignificantly for each dataset. In this paper, we propose an Omni-Scale block\n(OS-block) for 1D-CNNs, where the kernel sizes are decided by a simple and\nuniversal rule. Particularly, it is a set of kernel sizes that can efficiently\ncover the best RF size across different datasets via consisting of multiple\nprime numbers according to the length of the time series. The experiment result\nshows that models with the OS-block can achieve a similar performance as models\nwith the searched optimal RF size and due to the strong optimal RF size capture\nability, simple 1D-CNN models with OS-block achieves the state-of-the-art\nperformance on four time series benchmarks, including both univariate and\nmultivariate data from multiple domains. Comprehensive analysis and discussions\nshed light on why the OS-block can capture optimal RF sizes across different\ndatasets. Code available [https://github.com/Wensi-Tang/OS-CNN]",
        "title": "Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification"
    },
    {
        "abs": "Distributed optimization is vital in solving large-scale machine learning\nproblems. A widely-shared feature of distributed optimization techniques is the\nrequirement that all nodes complete their assigned tasks in each computational\nepoch before the system can proceed to the next epoch. In such settings, slow\nnodes, called stragglers, can greatly slow progress. To mitigate the impact of\nstragglers, we propose an online distributed optimization method called Anytime\nMinibatch. In this approach, all nodes are given a fixed time to compute the\ngradients of as many data samples as possible. The result is a variable\nper-node minibatch size. Workers then get a fixed communication time to average\ntheir minibatch gradients via several rounds of consensus, which are then used\nto update primal variables via dual averaging. Anytime Minibatch prevents\nstragglers from holding up the system without wasting the work that stragglers\ncan complete. We present a convergence analysis and analyze the wall time\nperformance. Our numerical results show that our approach is up to 1.5 times\nfaster in Amazon EC2 and it is up to five times faster when there is greater\nvariability in compute node performance.",
        "title": "Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization"
    },
    {
        "abs": "Welcome to WeaSuL 2021, the First Workshop on Weakly Supervised Learning,\nco-located with ICLR 2021. In this workshop, we want to advance theory, methods\nand tools for allowing experts to express prior coded knowledge for automatic\ndata annotations that can be used to train arbitrary deep neural networks for\nprediction. The ICLR 2021 Workshop on Weak Supervision aims at advancing\nmethods that help modern machine-learning methods to generalize from knowledge\nprovided by experts, in interaction with observable (unlabeled) data. In total,\n15 papers were accepted. All the accepted contributions are listed in these\nProceedings.",
        "title": "Proceedings of the First Workshop on Weakly Supervised Learning (WeaSuL)"
    },
    {
        "abs": "Generative modeling has been used frequently in synthetic data generation.\nFairness and privacy are two big concerns for synthetic data. Although Recent\nGAN [\\cite{goodfellow2014generative}] based methods show good results in\npreserving privacy, the generated data may be more biased. At the same time,\nthese methods require high computation resources. In this work, we design a\nfast, fair, flexible and private data generation method. We show the\neffectiveness of our method theoretically and empirically. We show that models\ntrained on data generated by the proposed method can perform well (in inference\nstage) on real application scenarios.",
        "title": "FFPDG: Fast, Fair and Private Data Generation"
    },
    {
        "abs": "Learning from a limited number of samples is challenging since the learned\nmodel can easily become overfitted based on the biased distribution formed by\nonly a few training examples. In this paper, we calibrate the distribution of\nthese few-sample classes by transferring statistics from the classes with\nsufficient examples, then an adequate number of examples can be sampled from\nthe calibrated distribution to expand the inputs to the classifier. We assume\nevery dimension in the feature representation follows a Gaussian distribution\nso that the mean and the variance of the distribution can borrow from that of\nsimilar classes whose statistics are better estimated with an adequate number\nof samples. Our method can be built on top of off-the-shelf pretrained feature\nextractors and classification models without extra parameters. We show that a\nsimple logistic regression classifier trained using the features sampled from\nour calibrated distribution can outperform the state-of-the-art accuracy on two\ndatasets (~5% improvement on miniImageNet compared to the next best). The\nvisualization of these generated features demonstrates that our calibrated\ndistribution is an accurate estimation.",
        "title": "Free Lunch for Few-shot Learning: Distribution Calibration"
    },
    {
        "abs": "Hopfield networks (HNs) and Restricted Boltzmann Machines (RBMs) are two\nimportant models at the interface of statistical physics, machine learning, and\nneuroscience. Recently, there has been interest in the relationship between HNs\nand RBMs, due to their similarity under the statistical mechanics formalism. An\nexact mapping between HNs and RBMs has been previously noted for the special\ncase of orthogonal (uncorrelated) encoded patterns. We present here an exact\nmapping in the case of correlated pattern HNs, which are more broadly\napplicable to existing datasets. Specifically, we show that any HN with $N$\nbinary variables and $p<N$ arbitrary binary patterns can be transformed into an\nRBM with $N$ binary visible variables and $p$ gaussian hidden variables. We\noutline the conditions under which the reverse mapping exists, and conduct\nexperiments on the MNIST dataset which suggest the mapping provides a useful\ninitialization to the RBM weights. We discuss extensions, the potential\nimportance of this correspondence for the training of RBMs, and for\nunderstanding the performance of deep architectures which utilize RBMs.",
        "title": "On the mapping between Hopfield networks and Restricted Boltzmann Machines"
    },
    {
        "abs": "Graph neural networks (GNNs) are a powerful inductive bias for modelling\nalgorithmic reasoning procedures and data structures. Their prowess was mainly\ndemonstrated on tasks featuring Markovian dynamics, where querying any\nassociated data structure depends only on its latest state. For many tasks of\ninterest, however, it may be highly beneficial to support efficient data\nstructure queries dependent on previous states. This requires tracking the data\nstructure's evolution through time, placing significant pressure on the GNN's\nlatent representations. We introduce Persistent Message Passing (PMP), a\nmechanism which endows GNNs with capability of querying past state by\nexplicitly persisting it: rather than overwriting node representations, it\ncreates new nodes whenever required. PMP generalises out-of-distribution to\nmore than 2x larger test inputs on dynamic temporal range queries,\nsignificantly outperforming GNNs which overwrite states.",
        "title": "Persistent Message Passing"
    },
    {
        "abs": "A deep equilibrium model uses implicit layers, which are implicitly defined\nthrough an equilibrium point of an infinite sequence of computation. It avoids\nany explicit computation of the infinite sequence by finding an equilibrium\npoint directly via root-finding and by computing gradients via implicit\ndifferentiation. In this paper, we analyze the gradient dynamics of deep\nequilibrium models with nonlinearity only on weight matrices and non-convex\nobjective functions of weights for regression and classification. Despite\nnon-convexity, convergence to global optimum at a linear rate is guaranteed\nwithout any assumption on the width of the models, allowing the width to be\nsmaller than the output dimension and the number of data points. Moreover, we\nprove a relation between the gradient dynamics of the deep implicit layer and\nthe dynamics of trust region Newton method of a shallow explicit layer. This\nmathematically proven relation along with our numerical observation suggests\nthe importance of understanding implicit bias of implicit layers and an open\nproblem on the topic. Our proofs deal with implicit layers, weight tying and\nnonlinearity on weights, and differ from those in the related literature.",
        "title": "On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers"
    },
    {
        "abs": "The ability to learn continually without forgetting the past tasks is a\ndesired attribute for artificial learning systems. Existing approaches to\nenable such learning in artificial neural networks usually rely on network\ngrowth, importance based weight update or replay of old data from the memory.\nIn contrast, we propose a novel approach where a neural network learns new\ntasks by taking gradient steps in the orthogonal direction to the gradient\nsubspaces deemed important for the past tasks. We find the bases of these\nsubspaces by analyzing network representations (activations) after learning\neach task with Singular Value Decomposition (SVD) in a single shot manner and\nstore them in the memory as Gradient Projection Memory (GPM). With qualitative\nand quantitative analyses, we show that such orthogonal gradient descent\ninduces minimum to no interference with the past tasks, thereby mitigates\nforgetting. We evaluate our algorithm on diverse image classification datasets\nwith short and long sequences of tasks and report better or on-par performance\ncompared to the state-of-the-art approaches.",
        "title": "Gradient Projection Memory for Continual Learning"
    },
    {
        "abs": "In high-dimensional state spaces, the usefulness of Reinforcement Learning\n(RL) is limited by the problem of exploration. This issue has been addressed\nusing potential-based reward shaping (PB-RS) previously. In the present work,\nwe introduce Final-Volume-Preserving Reward Shaping (FV-RS). FV-RS relaxes the\nstrict optimality guarantees of PB-RS to a guarantee of preserved long-term\nbehavior. Being less restrictive, FV-RS allows for reward shaping functions\nthat are even better suited for improving the sample efficiency of RL\nalgorithms. In particular, we consider settings in which the agent has access\nto an approximate plan. Here, we use examples of simulated robotic manipulation\ntasks to demonstrate that plan-based FV-RS can indeed significantly improve the\nsample efficiency of RL over plan-based PB-RS.",
        "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks"
    },
    {
        "abs": "Many machine learning strategies designed to automate mathematical tasks\nleverage neural networks to search large combinatorial spaces of mathematical\nsymbols. In contrast to traditional evolutionary approaches, using a neural\nnetwork at the core of the search allows learning higher-level symbolic\npatterns, providing an informed direction to guide the search. When no labeled\ndata is available, such networks can still be trained using reinforcement\nlearning. However, we demonstrate that this approach can suffer from an early\ncommitment phenomenon and from initialization bias, both of which limit\nexploration. We present two exploration methods to tackle these issues,\nbuilding upon ideas of entropy regularization and distribution initialization.\nWe show that these techniques can improve the performance, increase sample\nefficiency, and lower the complexity of solutions for the task of symbolic\nregression.",
        "title": "Improving exploration in policy gradient search: Application to symbolic optimization"
    },
    {
        "abs": "We study training of Convolutional Neural Networks (CNNs) with ReLU\nactivations and introduce exact convex optimization formulations with a\npolynomial complexity with respect to the number of data samples, the number of\nneurons, and data dimension. More specifically, we develop a convex analytic\nframework utilizing semi-infinite duality to obtain equivalent convex\noptimization problems for several two- and three-layer CNN architectures. We\nfirst prove that two-layer CNNs can be globally optimized via an $\\ell_2$ norm\nregularized convex program. We then show that multi-layer circular CNN training\nproblems with a single ReLU layer are equivalent to an $\\ell_1$ regularized\nconvex program that encourages sparsity in the spectral domain. We also extend\nthese results to three-layer CNNs with two ReLU layers. Furthermore, we present\nextensions of our approach to different pooling methods, which elucidates the\nimplicit architectural bias as convex regularizers.",
        "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time"
    },
    {
        "abs": "We consider the problem of finding the best memoryless stochastic policy for\nan infinite-horizon partially observable Markov decision process (POMDP) with\nfinite state and action spaces with respect to either the discounted or mean\nreward criterion. We show that the (discounted) state-action frequencies and\nthe expected cumulative reward are rational functions of the policy, whereby\nthe degree is determined by the degree of partial observability. We then\ndescribe the optimization problem as a linear optimization problem in the space\nof feasible state-action frequencies subject to polynomial constraints that we\ncharacterize explicitly. This allows us to address the combinatorial and\ngeometric complexity of the optimization problem using recent tools from\npolynomial optimization. In particular, we estimate the number of critical\npoints and use the polynomial programming description of reward maximization to\nsolve a navigation problem in a grid world.",
        "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs"
    },
    {
        "abs": "Stochastic encoders have been used in rate-distortion theory and neural\ncompression because they can be easier to handle. However, in performance\ncomparisons with deterministic encoders they often do worse, suggesting that\nnoise in the encoding process may generally be a bad idea. It is poorly\nunderstood if and when stochastic encoders do better than deterministic\nencoders. In this paper we provide one illustrative example which shows that\nstochastic encoders can significantly outperform the best deterministic\nencoders. Our toy example suggests that stochastic encoders may be particularly\nuseful in the regime of \"perfect perceptual quality\".",
        "title": "On the advantages of stochastic encoders"
    },
    {
        "abs": "We consider the problem of learned transform compression where we learn both,\nthe transform as well as the probability distribution over the discrete codes.\nWe utilize a soft relaxation of the quantization operation to allow for\nback-propagation of gradients and employ vector (rather than scalar)\nquantization of the latent codes. Furthermore, we apply similar relaxation in\nthe code probability assignments enabling direct optimization of the code\nentropy. To the best of our knowledge, this approach is completely novel. We\nconduct a set of proof-of concept experiments confirming the potency of our\napproaches.",
        "title": "Learned transform compression with optimized entropy encoding"
    },
    {
        "abs": "The dynamics of physical systems is often constrained to lower dimensional\nsub-spaces due to the presence of conserved quantities. Here we propose a\nmethod to learn and exploit such symmetry constraints building upon Hamiltonian\nNeural Networks. By enforcing cyclic coordinates with appropriate loss\nfunctions, we find that we can achieve improved accuracy on simple classical\ndynamics tasks. By fitting analytic formulae to the latent variables in our\nnetwork we recover that our networks are utilizing conserved quantities such as\n(angular) momentum.",
        "title": "Improving Simulations with Symmetry Control Neural Networks"
    },
    {
        "abs": "In this work, we study the behavior of standard models for community\ndetection under spectral manipulations. Through various ablation experiments,\nwe evaluate the impact of bandpass filtering on the performance of a GCN: we\nempirically show that most of the necessary and used information for nodes\nclassification is contained in the low-frequency domain, and thus contrary to\nimages, high frequencies are less crucial to community detection. In\nparticular, it is sometimes possible to obtain accuracies at a state-of-the-art\nlevel with simple classifiers that rely only on a few low frequencies.",
        "title": "Low-Rank Projections of GCNs Laplacian"
    },
    {
        "abs": "We propose a new framework of synthesizing data using deep generative models\nin a differentially private manner. Within our framework, sensitive data are\nsanitized with rigorous privacy guarantees in a one-shot fashion, such that\ntraining deep generative models is possible without re-using the original data.\nHence, no extra privacy costs or model constraints are incurred, in contrast to\npopular approaches such as Differentially Private Stochastic Gradient Descent\n(DP-SGD), which, among other issues, causes degradation in privacy guarantees\nas the training iteration increases. We demonstrate a realization of our\nframework by making use of the characteristic function and an adversarial\nre-weighting objective, which are of independent interest as well. Our proposal\nhas theoretical guarantees of performance, and empirical evaluations on\nmultiple datasets show that our approach outperforms other methods at\nreasonable levels of privacy.",
        "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning"
    },
    {
        "abs": "Self-supervised visual representation learning aims to learn useful\nrepresentations without relying on human annotations. Joint embedding approach\nbases on maximizing the agreement between embedding vectors from different\nviews of the same image. Various methods have been proposed to solve the\ncollapsing problem where all embedding vectors collapse to a trivial constant\nsolution. Among these methods, contrastive learning prevents collapse via\nnegative sample pairs. It has been shown that non-contrastive methods suffer\nfrom a lesser collapse problem of a different nature: dimensional collapse,\nwhereby the embedding vectors end up spanning a lower-dimensional subspace\ninstead of the entire available embedding space. Here, we show that dimensional\ncollapse also happens in contrastive learning. In this paper, we shed light on\nthe dynamics at play in contrastive learning that leads to dimensional\ncollapse. Inspired by our theory, we propose a novel contrastive learning\nmethod, called DirectCLR, which directly optimizes the representation space\nwithout relying on an explicit trainable projector. Experiments show that\nDirectCLR outperforms SimCLR with a trainable linear projector on ImageNet.",
        "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning"
    },
    {
        "abs": "We provide a general self-attention formulation to impose group equivariance\nto arbitrary symmetry groups. This is achieved by defining positional encodings\nthat are invariant to the action of the group considered. Since the group acts\non the positional encoding directly, group equivariant self-attention networks\n(GSA-Nets) are steerable by nature. Our experiments on vision benchmarks\ndemonstrate consistent improvements of GSA-Nets over non-equivariant\nself-attention networks.",
        "title": "Group Equivariant Stand-Alone Self-Attention For Vision"
    },
    {
        "abs": "We propose the task of disambiguating symbolic expressions in informal STEM\ndocuments in the form of LaTeX files - that is, determining their precise\nsemantics and abstract syntax tree - as a neural machine translation task. We\ndiscuss the distinct challenges involved and present a dataset with roughly\n33,000 entries. We evaluated several baseline models on this dataset, which\nfailed to yield even syntactically valid LaTeX before overfitting.\nConsequently, we describe a methodology using a transformer language model\npre-trained on sources obtained from arxiv.org, which yields promising results\ndespite the small size of the dataset. We evaluate our model using a plurality\nof dedicated techniques, taking the syntax and semantics of symbolic\nexpressions into account.",
        "title": "Disambiguating Symbolic Expressions in Informal Documents"
    },
    {
        "abs": "Training classifiers under fairness constraints such as group fairness,\nregularizes the disparities of predictions between the groups. Nevertheless,\neven though the constraints are satisfied during training, they might not\ngeneralize at evaluation time. To improve the generalizability of fair\nclassifiers, we propose fair mixup, a new data augmentation strategy for\nimposing the fairness constraint. In particular, we show that fairness can be\nachieved by regularizing the models on paths of interpolated samples between\nthe groups. We use mixup, a powerful data augmentation strategy to generate\nthese interpolates. We analyze fair mixup and empirically show that it ensures\na better generalization for both accuracy and fairness measurement in tabular,\nvision, and language benchmarks.",
        "title": "Fair Mixup: Fairness via Interpolation"
    },
    {
        "abs": "While autoregressive models excel at image compression, their sample quality\nis often lacking. Although not realistic, generated images often have high\nlikelihood according to the model, resembling the case of adversarial examples.\nInspired by a successful adversarial defense method, we incorporate randomized\nsmoothing into autoregressive generative modeling. We first model a smoothed\nversion of the data distribution, and then reverse the smoothing process to\nrecover the original data distribution. This procedure drastically improves the\nsample quality of existing autoregressive models on several synthetic and\nreal-world image datasets while obtaining competitive likelihoods on synthetic\ndatasets.",
        "title": "Improved Autoregressive Modeling with Distribution Smoothing"
    },
    {
        "abs": "We propose a simple method by which to choose sample weights for problems\nwith highly imbalanced or skewed traits. Rather than naively discretizing\nregression labels to find binned weights, we take a more principled approach --\nwe derive sample weights from the transfer function between an estimated source\nand specified target distributions. Our method outperforms both unweighted and\ndiscretely-weighted models on both regression and classification tasks. We also\nopen-source our implementation of this method\n(https://github.com/Daniel-Wu/Continuous-Weight-Balancing) to the scientific\ncommunity.",
        "title": "Continuous Weight Balancing"
    },
    {
        "abs": "In this work, we analyze the reinstatement mechanism introduced by Ritter et\nal. (2018) to reveal two classes of neurons that emerge in the agent's working\nmemory (an epLSTM cell) when trained using episodic meta-RL on an episodic\nvariant of the Harlow visual fixation task. Specifically, Abstract neurons\nencode knowledge shared across tasks, while Episodic neurons carry information\nrelevant for a specific episode's task.",
        "title": "The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL"
    },
    {
        "abs": "Deep Neural Networks are known to be vulnerable to small, adversarially\ncrafted, perturbations. The current most effective defense methods against\nthese adversarial attacks are variants of adversarial training. In this paper,\nwe introduce a radically different defense trained only on clean images: a\nsparse coding based frontend which significantly attenuates adversarial attacks\nbefore they reach the classifier. We evaluate our defense on CIFAR-10 dataset\nunder a wide range of attack types (including Linf , L2, and L1 bounded\nattacks), demonstrating its promise as a general-purpose approach for defense.",
        "title": "Sparse Coding Frontend for Robust Neural Networks"
    },
    {
        "abs": "The rate-distortion-perception function (RDPF; Blau and Michaeli, 2019) has\nemerged as a useful tool for thinking about realism and distortion of\nreconstructions in lossy compression. Unlike the rate-distortion function,\nhowever, it is unknown whether encoders and decoders exist that achieve the\nrate suggested by the RDPF. Building on results by Li and El Gamal (2018), we\nshow that the RDPF can indeed be achieved using stochastic, variable-length\ncodes. For this class of codes, we also prove that the RDPF lower-bounds the\nachievable rate",
        "title": "A coding theorem for the rate-distortion-perception function"
    },
    {
        "abs": "Most graph neural network architectures work by message-passing node vector\nembeddings over the adjacency matrix, and it is assumed that they capture graph\ntopology by doing that. We design two synthetic tasks, focusing purely on\ntopological problems -- triangle detection and clique distance -- on which\ngraph neural networks perform surprisingly badly, failing to detect those\n\"bermuda\" triangles. Datasets and their generation scripts are publicly\navailable on github.com/FujitsuLaboratories/bermudatriangles and\ndataset.labs.fujitsu.com.",
        "title": "Bermuda Triangles: GNNs Fail to Detect Simple Topological Structures"
    },
    {
        "abs": "Privacy and security-related concerns are growing as machine learning reaches\ndiverse application domains. The data holders want to train with private data\nwhile exploiting accelerators, such as GPUs, that are hosted in the cloud.\nHowever, Cloud systems are vulnerable to attackers that compromise the privacy\nof data and integrity of computations. This work presents DarKnight, a\nframework for large DNN training while protecting input privacy and computation\nintegrity. DarKnight relies on cooperative execution between trusted execution\nenvironments (TEE) and accelerators, where the TEE provides privacy and\nintegrity verification, while accelerators perform the computation heavy linear\nalgebraic operations.",
        "title": "Privacy and Integrity Preserving Training Using Trusted Hardware"
    },
    {
        "abs": "We generalize the Hamiltonian Monte Carlo algorithm with a stack of neural\nnetwork layers and evaluate its ability to sample from different topologies in\na two dimensional lattice gauge theory. We demonstrate that our model is able\nto successfully mix between modes of different topologies, significantly\nreducing the computational cost required to generated independent gauge field\nconfigurations. Our implementation is available at\nhttps://github.com/saforem2/l2hmc-qcd .",
        "title": "Deep Learning Hamiltonian Monte Carlo"
    },
    {
        "abs": "Concept bottleneck models map from raw inputs to concepts, and then from\nconcepts to targets. Such models aim to incorporate pre-specified, high-level\nconcepts into the learning procedure, and have been motivated to meet three\ndesiderata: interpretability, predictability, and intervenability. However, we\nfind that concept bottleneck models struggle to meet these goals. Using post\nhoc interpretability methods, we demonstrate that concepts do not correspond to\nanything semantically meaningful in input space, thus calling into question the\nusefulness of concept bottleneck models in their current form.",
        "title": "Do Concept Bottleneck Models Learn as Intended?"
    },
    {
        "abs": "In this paper, we propose a new data poisoning attack and apply it to deep\nreinforcement learning agents. Our attack centers on what we call\nin-distribution triggers, which are triggers native to the data distributions\nthe model will be trained on and deployed in. We outline a simple procedure for\nembedding these, and other, triggers in deep reinforcement learning agents\nfollowing a multi-task learning paradigm, and demonstrate in three common\nreinforcement learning environments. We believe that this work has important\nimplications for the security of deep learning models.",
        "title": "Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers"
    },
    {
        "abs": "In this paper, we present a novel neuroevolutionary method to identify the\narchitecture and hyperparameters of convolutional autoencoders. Remarkably, we\nused a hypervolume indicator in the context of neural architecture search for\nautoencoders, for the first time to our current knowledge. Results show that\nimages were compressed by a factor of more than 10, while still retaining\nenough information to achieve image classification for the majority of the\ntasks. Thus, this new approach can be used to speed up the AutoML pipeline for\nimage compression.",
        "title": "MONCAE: Multi-Objective Neuroevolution of Convolutional Autoencoders"
    },
    {
        "abs": "Model-based Reinforcement Learning estimates the true environment through a\nworld model in order to approximate the optimal policy. This family of\nalgorithms usually benefits from better sample efficiency than their model-free\ncounterparts. We investigate whether controllers learned in such a way are\nrobust and able to generalize under small perturbations of the environment. Our\nwork is inspired by the PILCO algorithm, a method for probabilistic policy\nsearch. We show that enforcing a lower bound to the likelihood noise in the\nGaussian Process dynamics model regularizes the policy updates and yields more\nrobust controllers. We demonstrate the empirical benefits of our method in a\nsimulation benchmark.",
        "title": "Learning Robust Controllers Via Probabilistic Model-Based Policy Search"
    },
    {
        "abs": "The inputs and/or outputs of some neural nets are weight matrices of other\nneural nets. Indirect encodings or end-to-end compression of weight matrices\ncould help to scale such approaches. Our goal is to open a discussion on this\ntopic, starting with recurrent neural networks for character-level language\nmodelling whose weight matrices are encoded by the discrete cosine transform.\nOur fast weight version thereof uses a recurrent neural network to parameterise\nthe compressed weights. We present experimental results on the enwik8 dataset.",
        "title": "Training and Generating Neural Networks in Compressed Weight Space"
    },
    {
        "abs": "This paper presents the computational challenge on differential geometry and\ntopology that happened within the ICLR 2021 workshop \"Geometric and Topological\nRepresentation Learning\". The competition asked participants to provide\ncreative contributions to the fields of computational geometry and topology\nthrough the open-source repositories Geomstats and Giotto-TDA. The challenge\nattracted 16 teams in its two month duration. This paper describes the design\nof the challenge and summarizes its main findings.",
        "title": "ICLR 2021 Challenge for Computational Geometry & Topology: Design and Results"
    },
    {
        "abs": "Training time budget and size of the dataset are among the factors affecting\nthe performance of a Deep Neural Network (DNN). This paper shows that Neural\nArchitecture Search (NAS), Hyper Parameters Optimization (HPO), and Data\nAugmentation help DNNs perform much better while these two factors are limited.\nHowever, searching for an optimal architecture and the best hyperparameter\nvalues besides a good combination of data augmentation techniques under low\nresources requires many experiments. We present our approach to achieving such\na goal in three steps: reducing training epoch time by compressing the model\nwhile maintaining the performance compared to the original model, preventing\nmodel overfitting when the dataset is small, and performing the hyperparameter\ntuning. We used NOMAD, which is a blackbox optimization software based on a\nderivative-free algorithm to do NAS and HPO. Our work achieved an accuracy of\n86.0 % on a tiny subset of Mini-ImageNet at the ICLR 2021 Hardware Aware\nEfficient Training (HAET) Challenge and won second place in the competition.\nThe competition results can be found at haet2021.github.io/challenge and our\nsource code can be found at github.com/DouniaLakhmiri/ICLR\\_HAET2021.",
        "title": "Efficient Training Under Limited Resources"
    },
    {
        "abs": "In this paper, we cast fair machine learning as invariant machine learning.\nWe first formulate a version of individual fairness that enforces invariance on\ncertain sensitive sets. We then design a transport-based regularizer that\nenforces this version of individual fairness and develop an algorithm to\nminimize the regularizer efficiently. Our theoretical results guarantee the\nproposed approach trains certifiably fair ML models. Finally, in the\nexperimental studies we demonstrate improved fairness metrics in comparison to\nseveral recent fair training procedures on three ML tasks that are susceptible\nto algorithmic bias.",
        "title": "SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness"
    },
    {
        "abs": "Despite significant advances, continual learning models still suffer from\ncatastrophic forgetting when exposed to incrementally available data from\nnon-stationary distributions. Rehearsal approaches alleviate the problem by\nmaintaining and replaying a small episodic memory of previous samples, often\nimplemented as an array of independent memory slots. In this work, we propose\nto augment such an array with a learnable random graph that captures pairwise\nsimilarities between its samples, and use it not only to learn new tasks but\nalso to guard against forgetting. Empirical results on several benchmark\ndatasets show that our model consistently outperforms recently proposed\nbaselines for task-free continual learning.",
        "title": "Graph-Based Continual Learning"
    },
    {
        "abs": "We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural\ntangent kernel and the Laplace kernel include the same set of functions, when\nboth kernels are restricted to the sphere $\\mathbb{S}^{d-1}$. Additionally, we\nprove that the exponential power kernel with a smaller power (making the kernel\nless smooth) leads to a larger RKHS, when it is restricted to the sphere\n$\\mathbb{S}^{d-1}$ and when it is defined on the entire $\\mathbb{R}^d$.",
        "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS"
    },
    {
        "abs": "Action and observation delays commonly occur in many Reinforcement Learning\napplications, such as remote control scenarios. We study the anatomy of\nrandomly delayed environments, and show that partially resampling trajectory\nfragments in hindsight allows for off-policy multi-step value estimation. We\napply this principle to derive Delay-Correcting Actor-Critic (DCAC), an\nalgorithm based on Soft Actor-Critic with significantly better performance in\nenvironments with delays. This is shown theoretically and also demonstrated\npractically on a delay-augmented version of the MuJoCo continuous control\nbenchmark.",
        "title": "Reinforcement Learning with Random Delays"
    },
    {
        "abs": "We demonstrate that differentially private machine learning has not yet\nreached its \"AlexNet moment\" on many canonical vision tasks: linear models\ntrained on handcrafted features significantly outperform end-to-end deep neural\nnetworks for moderate privacy budgets. To exceed the performance of handcrafted\nfeatures, we show that private learning requires either much more private data,\nor access to features learned on public data from a similar domain. Our work\nintroduces simple yet strong baselines for differentially private learning that\ncan inform the evaluation of future progress in this area.",
        "title": "Differentially Private Learning Needs Better Features (or Much More Data)"
    },
    {
        "abs": "We develop an algorithm to train individually fair learning-to-rank (LTR)\nmodels. The proposed approach ensures items from minority groups appear\nalongside similar items from majority groups. This notion of fair ranking is\nbased on the definition of individual fairness from supervised learning and is\nmore nuanced than prior fair LTR approaches that simply ensure the ranking\nmodel provides underrepresented items with a basic level of exposure. The crux\nof our method is an optimal transport-based regularizer that enforces\nindividual fairness and an efficient algorithm for optimizing the regularizer.\nWe show that our approach leads to certifiably individually fair LTR models and\ndemonstrate the efficacy of our method on ranking tasks subject to demographic\nbiases.",
        "title": "Individually Fair Ranking"
    },
    {
        "abs": "We consider the task of enforcing individual fairness in gradient boosting.\nGradient boosting is a popular method for machine learning from tabular data,\nwhich arise often in applications where algorithmic fairness is a concern. At a\nhigh level, our approach is a functional gradient descent on a\n(distributionally) robust loss function that encodes our intuition of\nalgorithmic fairness for the ML task at hand. Unlike prior approaches to\nindividual fairness that only work with smooth ML models, our approach also\nworks with non-smooth models such as decision trees. We show that our algorithm\nconverges globally and generalizes. We also demonstrate the efficacy of our\nalgorithm on three ML problems susceptible to algorithmic bias.",
        "title": "Individually Fair Gradient Boosting"
    },
    {
        "abs": "The amount of data, manpower and capital required to understand, evaluate and\nagree on a group of symptoms for the elementary prognosis of pandemic diseases\nis enormous. In this paper, we present FedPandemic, a novel noise\nimplementation algorithm integrated with cross-device Federated learning for\nElementary symptom prognosis during a pandemic, taking COVID-19 as a case\nstudy. Our results display consistency and enhance robustness in recovering the\ncommon symptoms displayed by the disease, paving a faster and cheaper path\ntowards symptom retrieval while also preserving the privacy of patient's\nsymptoms via Federated learning.",
        "title": "FedPandemic: A Cross-Device Federated Learning Approach Towards Elementary Prognosis of Diseases During a Pandemic"
    },
    {
        "abs": "Ontologies comprising of concepts, their attributes, and relationships are\nused in many knowledge based AI systems. While there have been efforts towards\npopulating domain specific ontologies, we examine the role of document\nstructure in learning ontological relationships between concepts in any\ndocument corpus. Inspired by ideas from hypernym discovery and explainability,\nour method performs about 15 points more accurate than a stand-alone R-GCN\nmodel for this task.",
        "title": "Document Structure aware Relational Graph Convolutional Networks for Ontology Population"
    },
    {
        "abs": "Imitation learning algorithms learn a policy from demonstrations of expert\nbehavior. We show that, for deterministic experts, imitation learning can be\ndone by reduction to reinforcement learning with a stationary reward. Our\ntheoretical analysis both certifies the recovery of expert reward and bounds\nthe total variation distance between the expert and the imitation learner,\nshowing a link to adversarial imitation learning. We conduct experiments which\nconfirm that our reduction works well in practice for continuous control tasks.",
        "title": "Imitation Learning by Reinforcement Learning"
    },
    {
        "abs": "Black-box optimization formulations for biological sequence design have drawn\nrecent attention due to their promising potential impact on the pharmaceutical\nindustry. In this work, we propose to unify two seemingly distinct worlds:\nlikelihood-free inference and black-box optimization, under one probabilistic\nframework. In tandem, we provide a recipe for constructing various sequence\ndesign methods based on this framework. We show how previous optimization\napproaches can be \"reinvented\" in our framework, and further propose new\nprobabilistic black-box optimization algorithms. Extensive experiments on\nsequence design application illustrate the benefits of the proposed\nmethodology.",
        "title": "Unifying Likelihood-free Inference with Black-box Optimization and Beyond"
    },
    {
        "abs": "Deep Reinforcement Learning (Deep RL) has been receiving increasingly more\nattention thanks to its encouraging performance on a variety of control tasks.\nYet, conventional regularization techniques in training neural networks (e.g.,\n$L_2$ regularization, dropout) have been largely ignored in RL methods,\npossibly because agents are typically trained and evaluated in the same\nenvironment, and because the deep RL community focuses more on high-level\nalgorithm designs. In this work, we present the first comprehensive study of\nregularization techniques with multiple policy optimization algorithms on\ncontinuous control tasks. Interestingly, we find conventional regularization\ntechniques on the policy networks can often bring large improvement, especially\non harder tasks. Our findings are shown to be robust against training\nhyperparameter variations. We also compare these techniques with the more\nwidely used entropy regularization. In addition, we study regularizing\ndifferent components and find that only regularizing the policy network is\ntypically the best. We further analyze why regularization may help\ngeneralization in RL from four perspectives - sample complexity, reward\ndistribution, weight norm, and noise robustness. We hope our study provides\nguidance for future practices in regularizing policy optimization algorithms.\nOur code is available at https://github.com/xuanlinli17/iclr2021_rlreg .",
        "title": "Regularization Matters in Policy Optimization"
    },
    {
        "abs": "Although neural module networks have an architectural bias towards\ncompositionality, they require gold standard layouts to generalize\nsystematically in practice. When instead learning layouts and modules jointly,\ncompositionality does not arise automatically and an explicit pressure is\nnecessary for the emergence of layouts exhibiting the right structure. We\npropose to address this problem using iterated learning, a cognitive science\ntheory of the emergence of compositional languages in nature that has primarily\nbeen applied to simple referential games in machine learning. Considering the\nlayouts of module networks as samples from an emergent language, we use\niterated learning to encourage the development of structure within this\nlanguage. We show that the resulting layouts support systematic generalization\nin neural agents solving the more complex task of visual question-answering.\nOur regularized iterated learning method can outperform baselines without\niterated learning on SHAPES-SyGeT (SHAPES Systematic Generalization Test), a\nnew split of the SHAPES dataset we introduce to evaluate systematic\ngeneralization, and on CLOSURE, an extension of CLEVR also designed to test\nsystematic generalization. We demonstrate superior performance in recovering\nground-truth compositional program structure with limited supervision on both\nSHAPES-SyGeT and CLEVR.",
        "title": "Iterated learning for emergent systematicity in VQA"
    },
    {
        "abs": "Knowledge Distillation (KD) is a widely used technique to transfer knowledge\nfrom pre-trained teacher models to (usually more lightweight) student models.\nHowever, in certain situations, this technique is more of a curse than a\nblessing. For instance, KD poses a potential risk of exposing intellectual\nproperties (IPs): even if a trained machine learning model is released in\n'black boxes' (e.g., as executable software or APIs without open-sourcing\ncode), it can still be replicated by KD through imitating input-output\nbehaviors. To prevent this unwanted effect of KD, this paper introduces and\ninvestigates a concept called Nasty Teacher: a specially trained teacher\nnetwork that yields nearly the same performance as a normal one, but would\nsignificantly degrade the performance of student models learned by imitating\nit. We propose a simple yet effective algorithm to build the nasty teacher,\ncalled self-undermining knowledge distillation. Specifically, we aim to\nmaximize the difference between the output of the nasty teacher and a normal\npre-trained network. Extensive experiments on several datasets demonstrate that\nour method is effective on both standard KD and data-free KD, providing the\ndesirable KD-immunity to model owners for the first time. We hope our\npreliminary study can draw more awareness and interest in this new practical\nproblem of both social and legal importance.",
        "title": "Undistillable: Making A Nasty Teacher That CANNOT teach students"
    },
    {
        "abs": "To interpret uncertainty estimates from differentiable probabilistic models,\nrecent work has proposed generating Counterfactual Latent Uncertainty\nExplanations (CLUEs). However, for a single input, such approaches could output\na variety of explanations due to the lack of constraints placed on the\nexplanation. Here we augment the original CLUE approach, to provide what we\ncall $\\delta$-CLUE. CLUE indicates $\\it{one}$ way to change an input, while\nremaining on the data manifold, such that the model becomes more confident\nabout its prediction. We instead return a $\\it{set}$ of plausible CLUEs:\nmultiple, diverse inputs that are within a $\\delta$ ball of the original input\nin latent space, all yielding confident predictions.",
        "title": "\u03b4-CLUE: Diverse Sets of Explanations for Uncertainty Estimates"
    }
]