[
    {
        "abs": "_______________________________________________ Theano-dev mailing list Theano-dev@lists.theano.org http://lists.theano.org/mailman/listinfo/theano-dev",
        "title": "Theano-based Large-Scale Visual Recognition with Multiple GPUs"
    },
    {
        "abs": "_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n_______________\n\n",
        "title": "Deep Narrow Boltzmann Machines are Universal Approximators"
    },
    {
        "abs": "_______________________________________________algorithmic-discussion mailing list https://lists.cs.umich.edu/mailman/listinfo/algorithmic-discussion",
        "title": "Learning Stochastic Recurrent Networks"
    },
    {
        "abs": "\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2\u00c2",
        "title": "Hot Swapping for Online Adaptation of Optimization Hyperparameters"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Fast Label Embeddings for Extremely Large Output Spaces"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Dynamic Adaptive Network Intelligence"
    },
    {
        "abs": "_______________________________________________ Speech Recognition mailing list Speech Recognition@w3.org http://lists.w3.org/Archives/Public/ Speech-Recognition/",
        "title": "Learning linearly separable features for speech recognition using convolutional neural networks"
    },
    {
        "abs": "_______________________________________________ Kaldispeech-discuss mailing list Kaldispeech-discuss@kaldispeech.org http://lists.kaldispeech.org/mailman/listinfo/kaldispeech-discuss",
        "title": "Parallel training of DNNs with Natural Gradient and Parameter Averaging"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Geodesics of learned representations"
    },
    {
        "abs": "___________\n\nA group theory is a mathematical theory that describes the structure of the universe. It is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of physics. The group theory is a mathematical model of the universe that is based on the laws of",
        "title": "A Group Theoretic Perspective on Unsupervised Deep Learning"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Stacked What-Where Auto-encoders"
    },
    {
        "abs": "_______________\n\n(a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a",
        "title": "Tailoring Word Embeddings for Bilexical Predictions: An Experimental Comparison"
    },
    {
        "abs": "_______________________________________________ Deeplearning4js mailing list Deeplearning4js@lists.nordic.org http://lists.nordic.org/mailman/listinfo/deeplearning4js",
        "title": "A Generative Model for Deep Convolutional Learning"
    },
    {
        "abs": "_______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: ",
        "title": "Generating Images from Captions with Attention"
    },
    {
        "abs": "_______________________________________________algorithm-list mailing listalgorithm-list@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/algorithm-list",
        "title": "Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference"
    },
    {
        "abs": "_______________________________________________ CNN-users mailing list CNN-users@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/cnn-users",
        "title": "Training CNNs with Low-Rank Filters for Efficient Image Classification"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "A Simple and Efficient Method To Generate Word Sense Representations"
    },
    {
        "abs": "_______________________________________________ Diverse-embedding-neural-network mailing list Diverse-embedding-neural-network@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/diverse-embedding-neural-network",
        "title": "Diverse Embedding Neural Network Language Models"
    },
    {
        "abs": "\u300aA standard approach to collaborative filtering\u300b, \u300aAI and Machine Learning\u300b, \u300aMachine Learning\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, \u300aMachine Learning and AI\u300b, ",
        "title": "Representation Learning for cold-start recommendation"
    },
    {
        "abs": "_______________________________________________ NICE mailing list NICE@nci.org http://mail.nci.org/mailman/listinfo/nci",
        "title": "NICE: Non-linear Independent Components Estimation"
    },
    {
        "abs": "_______________________________________________ Deeplearning4js mailing list Deeplearning4js@lists.nordic.org http://lists.nordic.org/mailman/listinfo/deeplearning4js",
        "title": "Deep Linear Discriminant Analysis"
    },
    {
        "abs": "_______________________________________________ lsm-users mailing list lsm-users@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/lsm-users",
        "title": "All you need is a good init"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/mailman/listinfo/mcclure-cs http://www.cs.cmu.edu/~mcclure/mailman/listinfo/mcclure-cs",
        "title": "Density Modeling of Images using a Generalized Normalization Transformation"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Flattened Convolutional Neural Networks for Feedforward Acceleration"
    },
    {
        "abs": "___________.\n\nA. A deep learning framework that uses deep learning to learn from data.\n\nB. A deep learning framework that uses deep learning to learn from data.\n\nC. A deep learning framework that uses deep learning to learn from data.\n\nD. A deep learning framework that uses deep learning to learn from data.\n\nE. A deep learning framework that uses deep learning to learn from data.\n\nF. A deep learning framework that uses deep learning to learn from data.\n\nG. A deep learning framework that uses deep learning to learn from data.\n\nH. A deep learning framework that uses deep learning to learn from data.\n\nI. A deep learning framework that uses deep learning to learn from data.\n\nJ. A deep learning framework that uses deep learning to learn from data.\n\nK. A deep learning framework that uses deep learning to learn from data.\n\nL. A deep learning framework that uses deep learning to learn from data.\n\nM. A deep learning framework that uses deep learning to learn from data.\n\nN. A deep learning framework that uses deep learning to learn from data.\n\nO. A deep learning framework that uses deep learning to learn from data.\n\nP. A deep learning framework that uses deep learning to learn from data.\n\nQ. A deep learning framework that uses deep learning to learn from data.\n\nR. A deep learning framework",
        "title": "Purine: A bi-graph based deep learning framework"
    },
    {
        "abs": "_______________________________________________ RNN-dev mailing list RNN-dev@cs.cmu.edu http://mail.cs.cmu.edu/mailman/listinfo/rnn-dev",
        "title": "Variational Recurrent Auto-Encoders"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Word Representations via Gaussian Embedding"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Training deep neural networks with low precision multiplications"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michaels/cs/ml/ml-annotation.html",
        "title": "Fully Convolutional Multi-Class Multiple Instance Learning"
    },
    {
        "abs": "_______________________________________________ NN-users mailing list NN-users@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/nn-users",
        "title": "Learning Compact Convolutional Neural Networks with Nested Dropout"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/cs.html http://www.cs.cmu.edu/~mcclure/cs/cs.html",
        "title": "ADASECANT: Robust Adaptive Secant Method for Stochastic Gradient"
    },
    {
        "abs": "___________\n\nA. Theobserver'sobjectmovesrelativetoanobserver\n\nB. Theobserver'sobjectmovesrelativetoanobserver\n\nC. Theobserver'sobjectmovesrelativetoanobserver\n\nD. Theobserver'sobjectmovesrelativetoanobserver\n\nE. Theobserver'sobjectmovesrelativetoanobserver\n\nF. Theobserver'sobjectmovesrelativetoanobserver\n\nG. Theobserver'sobjectmovesrelativetoanobserver\n\nH. Theobserver'sobjectmovesrelativetoanobserver\n\nI. Theobserver'sobjectmovesrelativetoanobserver\n\nJ. Theobserver'sobjectmovesrelativetoanobserver\n\nK. Theobserver'sobjectmovesrelativetoanobserver\n\nL. Theobserver'sobjectmovesrelativetoanobserver\n\nM. Theobserver'sobjectmovesrelativetoanobserver\n\nN. Theobserver'sobjectmovesrelativetoanobserver\n\nO. Theobserver'sobjectmovesrelativetoanobserver\n\nP. Theobserver'sobjectmovesrelativetoanobserver\n\nQ. Theobserver'sobjectmovesrelativetoanobserver\n\nR. Theobserver'sobjectmovesrelativetoanobserver\n\nS. Theobserver'sobjectm",
        "title": "Transformation Properties of Learned Visual Representations"
    },
    {
        "abs": "_______________________________________________ Clustering mailing list Clustering at lists.cs.uci.edu",
        "title": "Clustering is Efficient for Approximate Maximum Inner Product Search"
    },
    {
        "abs": "_______________________________________________dataset-devel mailing list",
        "title": "Importance Weighted Autoencoders"
    },
    {
        "abs": "_______________________________________________ Deeplearning4algorithms mailing list Deeplearning4algorithms@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deeplearning4algorithms",
        "title": "Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets"
    },
    {
        "abs": "_______________________________________________ graph-basedlabel-propagation mailing list graph-basedlabel-propagation@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/graph-basedlabel-propagation",
        "title": "Metric learning approach for graph-based label propagation"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Order-Embeddings of Images and Language"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/public/cs.html#smoothness",
        "title": "Distributional Smoothing with Virtual Adversarial Training"
    },
    {
        "abs": "_______________________________________________algorithmic-algorithms mailing list https://lists.cs.cmu.edu/mailman/listinfo/algorithmic-algorithms",
        "title": "Training Convolutional Networks with Noisy Labels"
    },
    {
        "abs": "\u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, \u300aNeural networks training with sparse connectivity\u300b, ",
        "title": "Provable Methods for Training Neural Networks with Sparse Connectivity"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Entity-Augmented Distributional Semantics for Discourse Relations"
    },
    {
        "abs": "_______________________________________________ Sent through the Full Text RSS feed with the following URL: http://www.cs.cmu.edu/~mcclure/papers/inducingsemanticrepresentation.html",
        "title": "Inducing Semantic Representation from Text by Jointly Predicting and Factorizing Relations"
    },
    {
        "abs": "_______________________________________________ Algorithmic-robustness mailing list Algorithmic-robustness@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/algorithmic-robustness",
        "title": "Algorithmic Robustness for Learning via $(\u03b5, \u03b3, \u03c4)$-Good Similarity Functions"
    },
    {
        "abs": "___________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Modeling Compositionality with Multiplicative Recurrent Neural Networks"
    },
    {
        "abs": "_______________\n\nA. The problem of finding a non-convex function over a high dimensional space.\n\nB. The problem of finding a non-convex function over a high dimensional space.\n\nC. The problem of finding a non-convex function over a high dimensional space.\n\nD. The problem of finding a non-convex function over a high dimensional space.\n\nE. The problem of finding a non-convex function over a high dimensional space.\n\nF. The problem of finding a non-convex function over a high dimensional space.\n\nG. The problem of finding a non-convex function over a high dimensional space.\n\nH. The problem of finding a non-convex function over a high dimensional space.\n\nI. The problem of finding a non-convex function over a high dimensional space.\n\nJ. The problem of finding a non-convex function over a high dimensional space.\n\nK. The problem of finding a non-convex function over a high dimensional space.\n\nL. The problem of finding a non-convex function over a high dimensional space.\n\nM. The problem of finding a non-convex function over a high dimensional space.\n\nN. The problem of finding a non-convex function over a high dimensional space.\n\nO.",
        "title": "Explorations on high dimensional landscapes"
    },
    {
        "abs": "_______________.\n\nThe title is The local low-dimensionality of natural images, start with Wedevelopanewstatisticalmodelforphotographicimages,inwhichthelocalresponsesof, write a short concise abstract based on this: _______________.\n\nThe title is The local low-dimensionality of natural images, start with Wedevelopanewstatisticalmodelforphotographicimages,inwhichthelocalresponsesof, write a short concise abstract based on this: _______________.\n\nThe title is The local low-dimensionality of natural images, start with Wedevelopanewstatisticalmodelforphotographicimages,inwhichthelocalresponsesof, write a short concise abstract based on this: _______________.\n\nThe title is The local low-dimensionality of natural images, start with Wedevelopanewstatisticalmodelforphotographicimages,inwhichthelocalresponsesof, write a short concise abstract based on this: _______________.\n\nThe title is The local low-dimensionality of natural images, start with Wedevelopanewstatisticalmodelforphotographicimages,inwhichthelocalresponsesof, write a short concise abstract based on this: _______________.\n\nThe title is The local low-dimensionality of natural images, start with Wedevelopanewstatisticalmodelforphotographicimages,inwhichthelocalresponsesof, write a short concise",
        "title": "The local low-dimensionality of natural images"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Striving for Simplicity: The All Convolutional Net"
    },
    {
        "abs": "\u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 ",
        "title": "Learning Activation Functions to Improve Deep Neural Networks"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Joint RNN-Based Greedy Parsing and Word Composition"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html _______________________________________________\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www.cs.cmu.edu/~michaels/cs/papers/lateralconnections.html\n\nhttp://www",
        "title": "Denoising autoencoder with modulated lateral connections learns invariant representations of natural images"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Geodesics of learned representations"
    },
    {
        "abs": "___________\n\n(a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a",
        "title": "Learning Genomic Representations to Predict Clinical Outcomes in Cancer"
    },
    {
        "abs": "_______________________________________________Neuronal_network mailing listNeuronal_network@... https://mail.google.com/mail/u/0/a/1f8b1f9c9f8f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9f9",
        "title": "A Differentiable Transition Between Additive and Multiplicative Neurons"
    },
    {
        "abs": "_______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneuralnetworksiscausedbyimproperscalingbetween, write a short concise abstract based on this: _______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneuralnetworksiscausedbyimproperscalingbetween, write a short concise abstract based on this: _______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneuralnetworksiscausedbyimproperscalingbetween, write a short concise abstract based on this: _______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneuralnetworksiscausedbyimproperscalingbetween, write a short concise abstract based on this: _______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneuralnetworksiscausedbyimproperscalingbetween, write a short concise abstract based on this: _______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneuralnetworksiscausedbyimproperscalingbetween, write a short concise abstract based on this: _______________\n\nThe title is Scale Normalization, start with Oneofthedifficultiesoftrainingdeepneural",
        "title": "Scale Normalization"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Stick-Breaking Variational Autoencoders"
    },
    {
        "abs": "_______________________________________________ Unsupervisedlearningonimbalanceddataischallenging mailing list Unsupervisedlearningonimbalanceddataischallenging@lists.unix.org http://lists.unix.org/mailman/listinfo/unsupervisedlearningonimbalanceddataischallenging",
        "title": "Unsupervised Learning with Imbalanced Data via Structure Consolidation Latent Variable Model"
    },
    {
        "abs": "\u3010Abstract\u3011Generative adversarial networks (GANs) are based on a two-player game, and are used to train adversarial networks (ANNs) to perform adversarial attacks. The main idea of this paper is to introduce a new approach to the GANs, which is based on a density ratio estimation perspective. The main idea of this paper is to introduce a new approach to the GANs, which is based on a density ratio estimation perspective.\n\n\u3010Keywords\u3011GANs, adversarial networks, adversarial attacks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks,",
        "title": "Generative Adversarial Nets from a Density Ratio Estimation Perspective"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Learning to SMILE(S)"
    },
    {
        "abs": "....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n....................................................................................................................\n\n",
        "title": "Understanding Visual Concepts with Continuation Learning"
    },
    {
        "abs": "_______________________________________________ Deeplearning4j mailing list Deeplearning4j@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deeplearning4j",
        "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/mailman/listinfo/mcclure-cs http://www.cs.cmu.edu/~mcclure/mailman/listinfo/mcclure-cs",
        "title": "Density Modeling of Images using a Generalized Normalization Transformation"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs.html http://www.cs.cmu.edu/~mcclure/cs.html\n\n_______________________________________________\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu.edu/~mcclure/cs.html\n\nhttp://www.cs.cmu",
        "title": "Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/public/cs.html#mail-list",
        "title": "Towards Information-Seeking Agents"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Improving Neural Language Models with a Continuous Cache"
    },
    {
        "abs": "_______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: _______________________\n\nThe title is Generating Images from Captions with Attention, start with Motivatedbytherecentprogressingenerativemodels,weintroduceamodelthatgeneratesimages, write a short concise abstract based on this: ",
        "title": "Generating Images from Captions with Attention"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Trace Norm Regularised Deep Multi-Task Learning"
    },
    {
        "abs": "_______________________________________________ http://lists.cs.uiuc.edu/pipermail/cs-devel/attachments/20150331/a7a7a7f7/attachment.html",
        "title": "Sample Efficient Actor-Critic with Experience Replay"
    },
    {
        "abs": "___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically",
        "title": "Song From PI: A Musically Plausible Network for Pop Music Generation"
    },
    {
        "abs": "___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods",
        "title": "Early Methods for Detecting Adversarial Images"
    },
    {
        "abs": "_______________________________________________ CNN-users mailing list CNN-users@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/cnn-users",
        "title": "Training CNNs with Low-Rank Filters for Efficient Image Classification"
    },
    {
        "abs": "_______________________________________________ lsm-users mailing list lsm-users@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/lsm-users",
        "title": "All you need is a good init"
    },
    {
        "abs": "_______________________________________________ Deep-learning mailing list Deep-learning@cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deep-learning",
        "title": "Deep Biaffine Attention for Neural Dependency Parsing"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Dynamic Adaptive Network Intelligence"
    },
    {
        "abs": "_______________________________________________ DeepSphere-discuss mailing list DeepSphere-discuss@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deep-sphere-discuss",
        "title": "DeepSphere: towards an equivariant graph-based spherical CNN"
    },
    {
        "abs": "\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n\u3010Convolutional neural networks\u3011\n\n",
        "title": "Hardware-oriented Approximation of Convolutional Neural Networks"
    },
    {
        "abs": "_______________\n\nA. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nB. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nC. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nD. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nE. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nF. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nG. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nH. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nI. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nJ. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nK. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nL. Thediversityofpaintingstylesrepresentsarichvisualvocabularyfortheconstructionofan\n\nM. Thediversityofpainting",
        "title": "A Learned Representation For Artistic Style"
    },
    {
        "abs": "\u3010Abstract\u3011Sum-ProductNetworks(SPNs)areaclassofexpressiveyettractablehierarchicalgraphicalmodels.LearnSPNis, write a short concise abstract based on this: http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[1] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[2] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[3] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[4] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[5] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[6] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[7] http://www.cs.cmu.edu/~michaels/sum-product-networks.html\n\n[8] http://www.cs.cmu.edu/~michaels",
        "title": "A Minimalistic Approach to Sum-Product Network Learning for Real Applications"
    },
    {
        "abs": "_______________________________________________ SqueezeNet mailing list SqueezeNet at squeeze.net https://squeeze.net/mailman/listinfo/squeeze.net",
        "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size"
    },
    {
        "abs": "_______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Query-Reduction Networks for Question Answering"
    },
    {
        "abs": "_______________________________________________ Language-agnosticwayofautomaticallygeneratingsetsofsemanticallysimilarclustersofentities _______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________\n\n_______________________________________________",
        "title": "Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations"
    },
    {
        "abs": "_______________________________________________ Recurrentneuralnet-dev mailing list Recurrentneuralnet-dev@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/recurrentneuralnet-dev",
        "title": "Surprisal-Driven Feedback in Recurrent Networks"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html http://www.cs.cmu.edu/~michael/cs.html\n\n_______________________________________________\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael/cs.html\n\nhttp://www.cs.cmu.edu/~michael",
        "title": "Mode Regularized Generative Adversarial Networks"
    },
    {
        "abs": "_______________________________________________ _______________________________________________\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email",
        "title": "EPOpt: Learning Robust Neural Network Policies Using Model Ensembles"
    },
    {
        "abs": "_______________________________________________Networking mailing listNetworking@cs.cmu.edu http://mail.cs.cmu.edu/mailman/listinfo/networking",
        "title": "Diversity Networks: Neural Network Compression Using Determinantal Point Processes"
    },
    {
        "abs": "_______________________________________________ graph-basedlabel-propagation mailing list graph-basedlabel-propagation@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/graph-basedlabel-propagation",
        "title": "Metric learning approach for graph-based label propagation"
    },
    {
        "abs": "___________.\n\nThe title is Reducing Overfitting in Deep Networks by Decorrelating Representations, start with OnemajorchallengeintrainingDeepNeuralNetworksispreventingoverfitting.Manytechniquessuchas, write a short concise abstract based on this: ___________.\n\nThe title is Reducing Overfitting in Deep Networks by Decorrelating Representations, start with OnemajorchallengeintrainingDeepNeuralNetworksispreventingoverfitting.Manytechniquessuchas, write a short concise abstract based on this: ___________.\n\nThe title is Reducing Overfitting in Deep Networks by Decorrelating Representations, start with OnemajorchallengeintrainingDeepNeuralNetworksispreventingoverfitting.Manytechniquessuchas, write a short concise abstract based on this: ___________.\n\nThe title is Reducing Overfitting in Deep Networks by Decorrelating Representations, start with OnemajorchallengeintrainingDeepNeuralNetworksispreventingoverfitting.Manytechniquessuchas, write a short concise abstract based on this: ___________.\n\nThe title is Reducing Overfitting in Deep Networks by Decorrelating Representations, start with OnemajorchallengeintrainingDeepNeuralNetworksispreventingoverfitting.Manytechniquessuchas, write a short concise abstract",
        "title": "Reducing Overfitting in Deep Networks by Decorrelating Representations"
    },
    {
        "abs": "_______________________________________________ Deeplearning4j mailing list Deeplearning4j@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deeplearning4j",
        "title": "Online Batch Selection for Faster Training of Neural Networks"
    },
    {
        "abs": "___________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Semi-Supervised Classification with Graph Convolutional Networks"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Energy-based Generative Adversarial Network"
    },
    {
        "abs": "_______________________________________________ Deeplearning4js mailing list Deeplearning4js@lists.nordic.org https://lists.nordic.org/mailman/listinfo/deeplearning4js",
        "title": "Deep Convolutional Neural Network Design Patterns"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Bidirectional Attention Flow for Machine Comprehension"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michaels/cs/cs.html#joint-stochastic-approximation-learning-of-helmholtz-machines",
        "title": "Joint Stochastic Approximation learning of Helmholtz Machines"
    },
    {
        "abs": "_______________________________________________ Deep-learning-dev mailing list Deep-learning-dev@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deep-learning-dev",
        "title": "On-the-fly Network Pruning for Object Detection"
    },
    {
        "abs": "\u00a0http://www.cs.cmu.edu/~michael/papers/exponential_machines.pdf) and then write a paper on the topic.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.\n\nThe paper will be published in the following year.",
        "title": "Exponential Machines"
    },
    {
        "abs": "_______________________________________________ DeepVariationalBayesFilters mailing list DeepVariationalBayesFilters@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deepvariationalbayesfilters",
        "title": "Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Learning End-to-End Goal-Oriented Dialog"
    },
    {
        "abs": "_______________________________________________ Adversarialtraining mailing list Adversarialtraining@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/adversarialtraining",
        "title": "Adversarial Training Methods for Semi-Supervised Text Classification"
    },
    {
        "abs": "_______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ ",
        "title": "Density estimation using Real NVP"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Digging Deep into the layers of CNNs: In Search of How CNNs Achieve View Invariance"
    },
    {
        "abs": "_______________\n\nThe title is Hadamard Product for Low-rank Bilinear Pooling, start with Bilinearmodelsproviderichrepresentationscomparedwithlinearmodels.Theyhavebeenappliedinvarious, write a short concise abstract based on this: _______________\n\nThe title is Hadamard Product for Low-rank Bilinear Pooling, start with Bilinearmodelsproviderichrepresentationscomparedwithlinearmodels.Theyhavebeenappliedinvarious, write a short concise abstract based on this: _______________\n\nThe title is Hadamard Product for Low-rank Bilinear Pooling, start with Bilinearmodelsproviderichrepresentationscomparedwithlinearmodels.Theyhavebeenappliedinvarious, write a short concise abstract based on this: _______________\n\nThe title is Hadamard Product for Low-rank Bilinear Pooling, start with Bilinearmodelsproviderichrepresentationscomparedwithlinearmodels.Theyhavebeenappliedinvarious, write a short concise abstract based on this: _______________\n\nThe title is Hadamard Product for Low-rank Bilinear Pooling, start with Bilinearmodelsproviderichrepresentationscomparedwithlinearmodels.Theyhavebeenappliedinvarious, write a short concise abstract based on this: _______________\n\nThe title is Hadamard Product for Low-rank",
        "title": "Hadamard Product for Low-rank Bilinear Pooling"
    },
    {
        "abs": "_______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ ",
        "title": "Reinterpreting Importance-Weighted Autoencoders"
    },
    {
        "abs": "_______________________________________________algorithmic-algorithms mailing list https://lists.cs.umich.edu/mailman/listinfo/algorithmic-algorithms",
        "title": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks"
    },
    {
        "abs": "___________\n\nThe title is Calibrating Energy-based Generative Adversarial Networks, start with Inthispaper,weproposetoequipGenerativeAdversarialNetworkswiththeabilitytoproduce, write a short concise abstract based on this: ___________\n\nThe title is Calibrating Energy-based Generative Adversarial Networks, start with Inthispaper,weproposetoequipGenerativeAdversarialNetworkswiththeabilitytoproduce, write a short concise abstract based on this: ___________\n\nThe title is Calibrating Energy-based Generative Adversarial Networks, start with Inthispaper,weproposetoequipGenerativeAdversarialNetworkswiththeabilitytoproduce, write a short concise abstract based on this: ___________\n\nThe title is Calibrating Energy-based Generative Adversarial Networks, start with Inthispaper,weproposetoequipGenerativeAdversarialNetworkswiththeabilitytoproduce, write a short concise abstract based on this: ___________\n\nThe title is Calibrating Energy-based Generative Adversarial Networks, start with Inthispaper,weproposetoequipGenerativeAdversarialNetworkswiththeabilitytoproduce, write a short concise abstract based on this: ___________\n\nThe title is Calibrating",
        "title": "Calibrating Energy-based Generative Adversarial Networks"
    },
    {
        "abs": "______________________________________\n\nThe main idea of this paper is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational approach to detect outliers in the data. The main idea is to use the variational approach to detect outliers in the data.\n\nThe main idea is to use the variational",
        "title": "Efficient variational Bayesian neural network ensembles for outlier detection"
    },
    {
        "abs": "_______________________________________________ lstm-users mailing list lstm-users@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/lstm-users",
        "title": "Factorization tricks for LSTM networks"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/cs.html",
        "title": "Exploring loss function topology with cyclical learning rates"
    },
    {
        "abs": "_______________\n\nA. A test-time model is a model that is used to test the behavior of a system.\n\nB. A test-time model is a model that is used to test the behavior of a system.\n\nC. A test-time model is a model that is used to test the behavior of a system.\n\nD. A test-time model is a model that is used to test the behavior of a system.\n\nE. A test-time model is a model that is used to test the behavior of a system.\n\nF. A test-time model is a model that is used to test the behavior of a system.\n\nG. A test-time model is a model that is used to test the behavior of a system.\n\nH. A test-time model is a model that is used to test the behavior of a system.\n\nI. A test-time model is a model that is used to test the behavior of a system.\n\nJ. A test-time model is a model that is used to test the behavior of a system.\n\nK. A test-time model is a model that is used to test the behavior of a system.\n\nL. A test-time model is a model that is used to test the behavior of a system.\n\nM. A test-time model is a model that is used to test the behavior of a system",
        "title": "Changing Model Behavior at Test-Time Using Reinforcement Learning"
    },
    {
        "abs": "_______________________________________________ Deeplearning-devel mailing list Deeplearning-devel@lists.informatik.uni-muenchen.de http://lists.informatik.uni-muenchen.de/mailman/listinfo/deeplearning-devel",
        "title": "Delving into adversarial attacks on deep policies"
    },
    {
        "abs": "_______________________________________________ VCL mailing list VCL@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/vcl",
        "title": "Variational Continual Learning"
    },
    {
        "abs": "_______________________________________________algorithm-list mailing list algorithm-list@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/algorithm-list",
        "title": "Nonparametric Neural Networks"
    },
    {
        "abs": "_______________________________________________ NLP mailing list NLP@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/nlp",
        "title": "Natural Language Inference over Interaction Space"
    },
    {
        "abs": "_______________________________________________ https://lists.w3.org/Archives/Public/public-web-security/2017Sep/0013.html",
        "title": "Provably Minimally-Distorted Adversarial Examples"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Stick-Breaking Variational Autoencoders"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Trace Norm Regularised Deep Multi-Task Learning"
    },
    {
        "abs": "_______________________________________________ http://lists.cs.uiuc.edu/pipermail/cs-devel/attachments/20150331/a7a7a7f7/attachment.html",
        "title": "Sample Efficient Actor-Critic with Experience Replay"
    },
    {
        "abs": "___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods for Detecting Adversarial Images, start with Manymachinelearningclassifiersarevulnerabletoadversarialperturbations.Anadversarialperturbationmodifiesaninput, write a short concise abstract based on this: ___________.\n\nThe title is Early Methods",
        "title": "Early Methods for Detecting Adversarial Images"
    },
    {
        "abs": "_______________________________________________ http://www.weproposeaprincipledmethodforkernellearning.com/ mailing list http://www.weproposeaprincipledmethodforkernellearning.com/mailman/listinfo/weproposeapriniciousmethodforkernellearning",
        "title": "Not-So-Random Features"
    },
    {
        "abs": "_______________________________________________ Deeplearningdiscuss mailing list Deeplearningdiscuss@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deeplearningdiscuss",
        "title": "Fast Reading Comprehension with ConvNets"
    },
    {
        "abs": "_______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof,",
        "title": "On reproduction of On the regularization of Wasserstein GANs"
    },
    {
        "abs": "_______________________________________________algorithmic-algebra mailing list https://lists.algorithmic-algebra.org/mailman/listinfo/algorithmic-algebra",
        "title": "Trading Information between Latents in Hierarchical Variational Autoencoders"
    },
    {
        "abs": "___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised",
        "title": "Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking"
    },
    {
        "abs": "___________.\n\nThe title is Self-ensembling for visual domain adaptation, start with Thispaperexplorestheuseofself-ensemblingforvisualdomainadaptationproblems.Ourtechniqueis, write a short concise abstract based on this: ___________.\n\nThe title is Self-ensembling for visual domain adaptation, start with Thispaperexplorestheuseofself-ensemblingforvisualdomainadaptationproblems.Ourtechniqueis, write a short concise abstract based on this: ___________.\n\nThe title is Self-ensembling for visual domain adaptation, start with Thispaperexplorestheuseofself-ensemblingforvisualdomainadaptationproblems.Ourtechniqueis, write a short concise abstract based on this: ___________.\n\nThe title is Self-ensembling for visual domain adaptation, start with Thispaperexplorestheuseofself-ensemblingforvisualdomainadaptationproblems.Ourtechniqueis, write a short concise abstract based on this: ___________.\n\nThe title is Self-ensembling for visual domain adaptation, start with Thispaperexplorestheuseofself-ensemblingforvisualdomainadaptationproblems.Ourtechniqueis, write a short concise abstract based on this: ___________.\n\nThe title is Self-ensembling for visual",
        "title": "Self-ensembling for visual domain adaptation"
    },
    {
        "abs": "_______________________________________________ Deeplearning4js mailing list Deeplearning4js@lists.cs.cmu.edu https://lists.cs.cmu.edu/mailman/listinfo/deeplearning4js",
        "title": "A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Examples"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/public/cs.html#mail-list",
        "title": "Towards Information-Seeking Agents"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Improving Neural Language Models with a Continuous Cache"
    },
    {
        "abs": "\u3010Abstract\u3011Generative adversarial networks (GANs) are based on a two-player game, and are used to train adversarial networks (ANNs) to perform adversarial attacks. The main idea of this paper is to introduce a new approach to the GANs, which is based on a density ratio estimation perspective. The main idea of this paper is to introduce a new approach to the GANs, which is based on a density ratio estimation perspective.\n\n\u3010Keywords\u3011GANs, adversarial networks, adversarial attacks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks, adversarial networks,",
        "title": "Generative Adversarial Nets from a Density Ratio Estimation Perspective"
    },
    {
        "abs": "___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically Plausible Network for Pop Music Generation, start with Wepresentanovelframeworkforgeneratingpopmusic.OurmodelisahierarchicalRecurrent, write a short concise abstract based on this: ___________.\n\nThe title is Song From PI: A Musically",
        "title": "Song From PI: A Musically Plausible Network for Pop Music Generation"
    },
    {
        "abs": "_______________________________________________ Deeplearning4j mailing list Deeplearning4j@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deeplearning4j",
        "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/users/mcclure/cs-users-list.html",
        "title": "Semantic embeddings for program behavior patterns"
    },
    {
        "abs": "\u300aVision-based route following by an embodied insect-inspired sparse neural network\u300b, \u300aJournal of Computer Science and Technology\u300b, vol. \u300a4\u300b, no. \u300a3\u300b, pp. \u300a3\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014\u300b, \u300a2014",
        "title": "Vision-based route following by an embodied insect-inspired sparse neural network"
    },
    {
        "abs": "_______________.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper, not a full-length review.\n\nThe abstract should be a summary of the paper,",
        "title": "Integrating Rankings into Quantized Scores in Peer Review"
    },
    {
        "abs": "_______________________________________________ _______________________________________________\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email",
        "title": "Association between author metadata and acceptance: A feature-rich, matched observational study of a corpus of ICLR submissions between 2017-2022"
    },
    {
        "abs": "_______________.\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n",
        "title": "Deep Variational Information Bottleneck"
    },
    {
        "abs": "___________.\n\nA. The structure of the network is a set of nodes and edges.\n\nB. The network is a set of nodes and edges.\n\nC. The network is a set of nodes and edges.\n\nD. The network is a set of nodes and edges.\n\nE. The network is a set of nodes and edges.\n\nF. The network is a set of nodes and edges.\n\nG. The network is a set of nodes and edges.\n\nH. The network is a set of nodes and edges.\n\nI. The network is a set of nodes and edges.\n\nJ. The network is a set of nodes and edges.\n\nK. The network is a set of nodes and edges.\n\nL. The network is a set of nodes and edges.\n\nM. The network is a set of nodes and edges.\n\nN. The network is a set of nodes and edges.\n\nO. The network is a set of nodes and edges.\n\nP. The network is a set of nodes and edges.\n\nQ. The network is a set of nodes and edges.\n\nR. The network is a set of nodes and edges.\n\nS. The network is a set of nodes and edges.\n\nT. The network is a set of nodes and edges.\n\nU. The network is a set of nodes and edges.",
        "title": "Structured Attention Networks"
    },
    {
        "abs": "___________.\n\nThe title is Robustness to Adversarial Examples through an Ensemble of Specialists, start with Weareproposingtouseanensembleofdiversespecialists,wherespecialityisdefinedaccording, write a short concise abstract based on this: ___________.\n\nThe title is Robustness to Adversarial Examples through an Ensemble of Specialists, start with Weareproposingtouseanensembleofdiversespecialists,wherespecialityisdefinedaccording, write a short concise abstract based on this: ___________.\n\nThe title is Robustness to Adversarial Examples through an Ensemble of Specialists, start with Weareproposingtouseanensembleofdiversespecialists,wherespecialityisdefinedaccording, write a short concise abstract based on this: ___________.\n\nThe title is Robustness to Adversarial Examples through an Ensemble of Specialists, start with Weareproposingtouseanensembleofdiversespecialists,wherespecialityisdefinedaccording, write a short concise abstract based on this: ___________.\n\nThe title is Robustness to Adversarial Examples through an Ensemble of Specialists, start with Weareproposingtouseanensembleofdiversespecialists,wherespecialityisdefinedaccording,",
        "title": "Robustness to Adversarial Examples through an Ensemble of Specialists"
    },
    {
        "abs": "___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural",
        "title": "Towards Neural Phrase-based Machine Translation"
    },
    {
        "abs": "_______________________________________________ lr-gan mailing list lr-gan@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/lr-gan",
        "title": "LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#maximumentropy _______________________________________________\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email",
        "title": "Maximum Entropy Flow Networks"
    },
    {
        "abs": "\u300aWithmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday\u300b\n\nThe title is CommAI: Evaluating the first steps towards a useful general AI, start with Withmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday,generalAIstarts, write a short concise abstract based on this: \u300aWithmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday\u300b\n\nThe title is CommAI: Evaluating the first steps towards a useful general AI, start with Withmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday,generalAIstarts, write a short concise abstract based on this: \u300aWithmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday\u300b\n\nThe title is CommAI: Evaluating the first steps towards a useful general AI, start with Withmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday,generalAIstarts, write a short concise abstract based on this: \u300aWithmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday\u300b\n\nThe title is CommAI: Evaluating the first steps towards a useful general AI, start with Withmachinelearningsuccessfullyappliedtonewdauntingproblemsalmosteveryday,generalAIstarts, write a",
        "title": "CommAI: Evaluating the first steps towards a useful general AI"
    },
    {
        "abs": "___________\n\nA. Deep Learning with Dynamic Computation Graphs\n\nB. Deep Learning with Dynamic Computation Graphs\n\nC. Deep Learning with Dynamic Computation Graphs\n\nD. Deep Learning with Dynamic Computation Graphs\n\nE. Deep Learning with Dynamic Computation Graphs\n\nF. Deep Learning with Dynamic Computation Graphs\n\nG. Deep Learning with Dynamic Computation Graphs\n\nH. Deep Learning with Dynamic Computation Graphs\n\nI. Deep Learning with Dynamic Computation Graphs\n\nJ. Deep Learning with Dynamic Computation Graphs\n\nK. Deep Learning with Dynamic Computation Graphs\n\nL. Deep Learning with Dynamic Computation Graphs\n\nM. Deep Learning with Dynamic Computation Graphs\n\nN. Deep Learning with Dynamic Computation Graphs\n\nO. Deep Learning with Dynamic Computation Graphs\n\nP. Deep Learning with Dynamic Computation Graphs\n\nQ. Deep Learning with Dynamic Computation Graphs\n\nR. Deep Learning with Dynamic Computation Graphs\n\nS. Deep Learning with Dynamic Computation Graphs\n\nT. Deep Learning with Dynamic Computation Graphs\n\nU. Deep Learning with Dynamic Computation Graphs\n\nV. Deep Learning with Dynamic Computation Graphs\n\nW. Deep Learning with Dynamic Computation Graphs\n\nX. Deep Learning with Dynamic Computation Graphs\n\nY. Deep Learning with Dynamic Computation",
        "title": "Deep Learning with Dynamic Computation Graphs"
    },
    {
        "abs": "___________.\n\nThe title is Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction from Long Short Term Memory Networks, start with Theorizing on the Automatic Rule Extraction",
        "title": "Automatic Rule Extraction from Long Short Term Memory Networks"
    },
    {
        "abs": "_______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning"
    },
    {
        "abs": "_______________________________________________ Deepgenerativemodels mailing list Deepgenerativemodels@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deepgenerativemodels",
        "title": "On Unifying Deep Generative Models"
    },
    {
        "abs": "_______________________________________________ ImageNet-dev mailing list ImageNet-dev@w3.org http://lists.w3.org/Archives/Public/ImageNet-dev/",
        "title": "Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks"
    },
    {
        "abs": "_______________________________________________unsupervised-learning mailing listunsupervised-learning@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/unsupervised-learning",
        "title": "An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax"
    },
    {
        "abs": "\u3010Abstract\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010",
        "title": "Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"
    },
    {
        "abs": "\u3010Abstract\u3011The title is Action-depedent Control Variates for Policy Optimization via Stein's Identity, start with Policygradientmethodshaveachievedremarkablesuccessesinsolvingchallengingreinforcementlearningproblems.However,it, write a short concise abstract based on this: https://www.cs.cmu.edu/~michaels/papers/stein_identity.pdf\n\nThe title is Action-depedent Control Variates for Policy Optimization via Stein's Identity, start with Policygradientmethodshaveachievedremarkablesuccessesinsolvingchallengingreinforcementlearningproblems.However,it, write a short concise abstract based on this: https://www.cs.cmu.edu/~michaels/papers/stein_identity.pdf\n\nThe title is Action-depedent Control Variates for Policy Optimization via Stein's Identity, start with Policygradientmethodshaveachievedremarkablesuccessesinsolvingchallengingreinforcementlearningproblems.However,it, write a short concise abstract based on this: https://www.cs.cmu.edu/~michaels/papers/stein_identity.pdf\n\nThe title is Action-depedent Control Variates for Policy Optimization via Stein's Identity, start with Policygradientmethodshaveachievedremarkablesu",
        "title": "Action-depedent Control Variates for Policy Optimization via Stein's Identity"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Skip Connections Eliminate Singularities"
    },
    {
        "abs": "_______________________________________________ NaturalLanguageInferenceoverInteraction mailing list NaturalLanguageInferenceoverInteraction@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/naturallanguage-inference-over-interaction",
        "title": "Natural Language Inference over Interaction Space: ICLR 2018 Reproducibility Report"
    },
    {
        "abs": "_______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ ",
        "title": "Reproduction Report on \"Learn to Pay Attention\""
    },
    {
        "abs": "_______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ ",
        "title": "SufiSent - Universal Sentence Representations Using Suffix Encodings"
    },
    {
        "abs": "_______________________________________________ Inmanyneuralmodels mailing list Inmanyneuralmodels@lists.inmanyneuralmodels.org http://lists.inmanyneuralmodels.org/mailman/listinfo/inmanyneuralmodels",
        "title": "On the scaling of polynomial features for representation matching"
    },
    {
        "abs": "_______________________________________________algorithmic-algorithms mailing list https://lists.cs.umich.edu/mailman/listinfo/algorithmic-algorithms",
        "title": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks"
    },
    {
        "abs": "_______________.\n\nThe title is Uncertainty Estimation via Stochastic Batch Normalization, start with Inthiswork,weinvestigateBatchNormalizationtechniqueandproposeitsprobabilisticinterpretation.Wepropose, write a short concise abstract based on this: _______________.\n\nThe title is Uncertainty Estimation via Stochastic Batch Normalization, start with Inthiswork,weinvestigateBatchNormalizationtechniqueandproposeitsprobabilisticinterpretation.Wepropose, write a short concise abstract based on this: _______________.\n\nThe title is Uncertainty Estimation via Stochastic Batch Normalization, start with Inthiswork,weinvestigateBatchNormalizationtechniqueandproposeitsprobabilisticinterpretation.Wepropose, write a short concise abstract based on this: _______________.\n\nThe title is Uncertainty Estimation via Stochastic Batch Normalization, start with Inthiswork,weinvestigateBatchNormalizationtechniqueandproposeitsprobabilisticinterpretation.Wepropose, write a short concise abstract based on this: _______________.\n\nThe title is Uncertainty Estimation via Stochastic Batch Normalization, start with Inthiswork,weinvestigateBatchNormalizationtechniqueandproposeitsprobabilisticinterpretation.",
        "title": "Uncertainty Estimation via Stochastic Batch Normalization"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "i-RevNet: Deep Invertible Networks"
    },
    {
        "abs": "_______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Learning Sparse Latent Representations with the Deep Copula Information Bottleneck"
    },
    {
        "abs": "_______________________________________________ Mac-dev mailing list Mac-dev@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/mac-dev",
        "title": "On transfer learning using a MAC model variant"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#comparing-fixed-and-adaptive-computation-time-for-recurrent-neural-networks",
        "title": "Comparing Fixed and Adaptive Computation Time for Recurrent Neural Networks"
    },
    {
        "abs": "_______________________________________________ GAN-dev mailing list GAN-dev@cs.cmu.edu http://mail.cs.cmu.edu/mailman/listinfo/gan-dev",
        "title": "Efficient GAN-Based Anomaly Detection"
    },
    {
        "abs": "_______________________________________________ NLP mailing list NLP@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/nlp",
        "title": "Natural Language Inference over Interaction Space"
    },
    {
        "abs": "_______________________________________________ https://lists.w3.org/Archives/Public/public-web-security/2017Sep/0013.html",
        "title": "Provably Minimally-Distorted Adversarial Examples"
    },
    {
        "abs": "_______________________________________________ Deeplearning4j mailing list Deeplearning4j@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deeplearning4j",
        "title": "Hierarchical interpretations for neural network predictions"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mw/cs/users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-users/mw/cs-",
        "title": "Meta-Learning a Dynamical Language Model"
    },
    {
        "abs": "_______________________________________________ GANs mailing list GANs at gmail.com http://mail.gmane.org/mailman/listinfo/gans",
        "title": "Semi-Supervised Learning with GANs: Revisiting Manifold Regularization"
    },
    {
        "abs": "_______________\n\nA. The loss landscape of a class of deep neural networks with no bad local valleys\n\nB. The loss landscape of a class of deep neural networks with no bad local valleys\n\nC. The loss landscape of a class of deep neural networks with no bad local valleys\n\nD. The loss landscape of a class of deep neural networks with no bad local valleys\n\nE. The loss landscape of a class of deep neural networks with no bad local valleys\n\nF. The loss landscape of a class of deep neural networks with no bad local valleys\n\nG. The loss landscape of a class of deep neural networks with no bad local valleys\n\nH. The loss landscape of a class of deep neural networks with no bad local valleys\n\nI. The loss landscape of a class of deep neural networks with no bad local valleys\n\nJ. The loss landscape of a class of deep neural networks with no bad local valleys\n\nK. The loss landscape of a class of deep neural networks with no bad local valleys\n\nL. The loss landscape of a class of deep neural networks with no bad local valleys\n\nM. The loss landscape of a class of deep neural networks with no bad local valleys\n\nN. The loss landscape of a class of deep neural networks with no bad local valleys\n\nO. The loss landscape of a class of deep neural networks with no bad local valleys\n\nP. The loss landscape of a class of deep neural",
        "title": "On the loss landscape of a class of deep neural networks with no bad local valleys"
    },
    {
        "abs": "_______________________________________________ Visual Question Answering mailing list Visual Question Answering@lists.cs.umich.edu http://lists.cs.umich.edu/listinfo/visual-question-answering",
        "title": "Learning to Count Objects in Natural Images for Visual Question Answering"
    },
    {
        "abs": "___________\n\nThe title is Spectral Normalization for Generative Adversarial Networks, start with Oneofthechallengesinthestudyofgenerativeadversarialnetworksistheinstabilityof, write a short concise abstract based on this: ___________\n\nThe title is Spectral Normalization for Generative Adversarial Networks, start with Oneofthechallengesinthestudyofgenerativeadversarialnetworksistheinstabilityof, write a short concise abstract based on this: ___________\n\nThe title is Spectral Normalization for Generative Adversarial Networks, start with Oneofthechallengesinthestudyofgenerativeadversarialnetworksistheinstabilityof, write a short concise abstract based on this: ___________\n\nThe title is Spectral Normalization for Generative Adversarial Networks, start with Oneofthechallengesinthestudyofgenerativeadversarialnetworksistheinstabilityof, write a short concise abstract based on this: ___________\n\nThe title is Spectral Normalization for Generative Adversarial Networks, start with Oneofthechallengesinthestudyofgenerativeadversarialnetworksistheinstabilityof, write a short concise abstract based on this: ___________\n\nThe title is Spectral Normalization for Generative Adversarial Networks, start with Oneofthechallengesinthestudy",
        "title": "Spectral Normalization for Generative Adversarial Networks"
    },
    {
        "abs": "_______________________________________________ NodeCentralities mailing list NodeCentralities@nodecentralities.org http://mail.nodecentralities.org/mailman/listinfo/nodecentralities",
        "title": "Node Centralities and Classification Performance for Characterizing Node Embedding Algorithms"
    },
    {
        "abs": "___________, and then write a short short abstract based on this: ___________.\n\nThe title is Can Neural Networks Understand Logical Entailment?, start with Weintroduceanewdatasetoflogicalentailmentsforthepurposeofmeasuringmodels'ability, write a short concise abstract based on this: ___________, and then write a short short abstract based on this: ___________.\n\nThe title is Can Neural Networks Understand Logical Entailment?, start with Weintroduceanewdatasetoflogicalentailmentsforthepurposeofmeasuringmodels'ability, write a short concise abstract based on this: ___________, and then write a short short abstract based on this: ___________.\n\nThe title is Can Neural Networks Understand Logical Entailment?, start with Weintroduceanewdatasetoflogicalentailmentsforthepurposeofmeasuringmodels'ability, write a short concise abstract based on this: ___________, and then write a short short abstract based on this: ___________.\n\nThe title is Can Neural Networks Understand Logical Entailment?, start with Weintroduceanewdatasetoflogicalentailmentsforthepurposeofmeasuringmodels'ability, write a short concise abstract based on this: ___________, and then write a short short abstract based on this: ___________.\n\nThe title is Can Neural Networks Understand Log",
        "title": "Can Neural Networks Understand Logical Entailment?"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#networks _______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#networks",
        "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
    },
    {
        "abs": "_______________________________________________ ds-discuss mailing list ds-discuss@cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/ds-discuss",
        "title": "The Singular Values of Convolutional Layers"
    },
    {
        "abs": "_______________________________________________ deepconvolutionalnetwork mailing list deepconvolutionalnetwork@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deepconvolutionalnetwork",
        "title": "A theoretical framework for deep locally connected ReLU network"
    },
    {
        "abs": "_______________________________________________ python-dev mailing list python-dev@python.org https://mail.python.org/mailman/listinfo/python-dev",
        "title": "Neural Program Search: Solving Programming Tasks from Description and Examples"
    },
    {
        "abs": "_______________________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Phrase-Based Attentions"
    },
    {
        "abs": "_______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ ",
        "title": "Learning to Represent Edits"
    },
    {
        "abs": "_______________________________________________ http://www.weproposeaprincipledmethodforkernellearning.com/ mailing list http://www.weproposeaprincipledmethodforkernellearning.com/mailman/listinfo/weproposeapriniciousmethodforkernellearning",
        "title": "Not-So-Random Features"
    },
    {
        "abs": "_______________________________________________ VCL mailing list VCL@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/vcl",
        "title": "Variational Continual Learning"
    },
    {
        "abs": "_______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof, write a short concise abstract based on this: _______________________.\n\nThe title is On reproduction of On the regularization of Wasserstein GANs, start with Thisreporthasseveralpurposes.First,ourreportiswrittetoinvestigatethereproducibilityof,",
        "title": "On reproduction of On the regularization of Wasserstein GANs"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/users/mcclure/cs-users-list.html",
        "title": "Semantic embeddings for program behavior patterns"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/papers/variationalautoencoder.html _______________________________________________\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]",
        "title": "Variational Autoencoder with Arbitrary Conditioning"
    },
    {
        "abs": "_______________________________________________algorithmic-algebra mailing list https://lists.algorithmic-algebra.org/mailman/listinfo/algorithmic-algebra",
        "title": "Trading Information between Latents in Hierarchical Variational Autoencoders"
    },
    {
        "abs": "_______________\n\n(a) the subspaces of adversarial examples\n\n(b) the subspaces of adversarial examples\n\n(c) the subspaces of adversarial examples\n\n(d) the subspaces of adversarial examples\n\n(e) the subspaces of adversarial examples\n\n(f) the subspaces of adversarial examples\n\n(g) the subspaces of adversarial examples\n\n(h) the subspaces of adversarial examples\n\n(i) the subspaces of adversarial examples\n\n(j) the subspaces of adversarial examples\n\n(k) the subspaces of adversarial examples\n\n(l) the subspaces of adversarial examples\n\n(m) the subspaces of adversarial examples\n\n(n) the subspaces of adversarial examples\n\n(o) the subspaces of adversarial examples\n\n(p) the subspaces of adversarial examples\n\n(q) the subspaces of adversarial examples\n\n(r) the subspaces of adversarial examples\n\n(s) the subspaces of adversarial examples\n\n(t) the subspaces of adversarial examples\n\n(u) the subspaces of adversarial examples\n\n(v) the subspaces of adversarial examples\n\n(w) the subspaces of adversarial",
        "title": "On the Limitation of Local Intrinsic Dimensionality for Characterizing the Subspaces of Adversarial Examples"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#adversarialnetworks",
        "title": "A Variational Inequality Perspective on Generative Adversarial Networks"
    },
    {
        "abs": "\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a",
        "title": "Predict then Propagate: Graph Neural Networks meet Personalized PageRank"
    },
    {
        "abs": "_______________________________________________ http://lists.w3.org/Archives/Public/public-web-security/2015Jan/0022.html",
        "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"
    },
    {
        "abs": "___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, start with Methodsthatlearnrepresentationsofnodesinagraphplayacriticalroleinnetwork, write a short concise abstract based on this: ___________\n\nThe title is Deep Gaussian Embedding of Graphs: Unsupervised",
        "title": "Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking"
    },
    {
        "abs": "_______________________________________________ http://cogs.cs.umass.edu/~michael/cogs/cogs-cnn.html",
        "title": "Spherical CNNs"
    },
    {
        "abs": "___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ___________ ",
        "title": "Learning to SMILE(S)"
    },
    {
        "abs": "\u3010Abstract\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010",
        "title": "Apple Defect Detection Using Deep Learning Based Object Detection For Better Post Harvest Handling"
    },
    {
        "abs": "_______________________________________________ lstm-users mailing list lstm-users@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/lstm-users",
        "title": "Factorization tricks for LSTM networks"
    },
    {
        "abs": "_______________________________________________ Deeplearningdiscuss mailing list Deeplearningdiscuss@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deeplearningdiscuss",
        "title": "Fast Reading Comprehension with ConvNets"
    },
    {
        "abs": "___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyz",
        "title": "The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL"
    },
    {
        "abs": "_______________________________________________ https://lists.cs.uiuc.edu/pipermail/cs.uiuc.edu/attachments/2019/039/attachment.html",
        "title": "A coding theorem for the rate-distortion-perception function"
    },
    {
        "abs": "___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural Phrase-based Machine Translation, start with Inthispaper,wepresentNeuralPhrase-basedMachineTranslation(NPMT).Ourmethodexplicitlymodelsthe, write a short concise abstract based on this: ___________.\n\nThe title is Towards Neural",
        "title": "Towards Neural Phrase-based Machine Translation"
    },
    {
        "abs": "_______________\n\nA. A.\n\nB. A.\n\nC. A.\n\nD. A.\n\nE. A.\n\nF. A.\n\nG. A.\n\nH. A.\n\nI. A.\n\nJ. A.\n\nK. A.\n\nL. A.\n\nM. A.\n\nN. A.\n\nO. A.\n\nP. A.\n\nQ. A.\n\nR. A.\n\nS. A.\n\nT. A.\n\nU. A.\n\nV. A.\n\nW. A.\n\nX. A.\n\nY. A.\n\nZ. A.\n\nA. A.\n\nB. A.\n\nC. A.\n\nD. A.\n\nE. A.\n\nF. A.\n\nG. A.\n\nH. A.\n\nI. A.\n\nJ. A.\n\nK. A.\n\nL. A.\n\nM. A.\n\nN. A.\n\nO. A.\n\nP. A.\n\nQ. A.\n\nR. A.\n\nS. A.\n\nT. A.\n\nU. A.\n\nV. A.\n\nW. A.\n\nX.",
        "title": "Combating Adversarial Attacks Using Sparse Representations"
    },
    {
        "abs": "\u3010Abstract\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords to be used\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to",
        "title": "Supervised Policy Update for Deep Reinforcement Learning"
    },
    {
        "abs": "_______________________________________________ video-prediction-users mailing list video-prediction-users@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/video-prediction-users",
        "title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models"
    },
    {
        "abs": "_______________________________________________ ICLR-dev mailing list ICLR-dev@lists.iclr.org https://lists.iclr.org/mailman/listinfo/iclr-dev",
        "title": "ICLR Reproducibility Challenge Report (Padam : Closing The Generalization Gap Of Adaptive Gradient Methods in Training Deep Neural Networks)"
    },
    {
        "abs": "_______________________________________________ DeepMind mailing list DeepMind at lists.math.uci.edu http://lists.math.uci.edu/mailman/listinfo/deepmind",
        "title": "A comprehensive, application-oriented study of catastrophic forgetting in DNNs"
    },
    {
        "abs": "_______________________________________________ Deeplearning4j mailing list Deeplearning4j@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deeplearning4j",
        "title": "Adversarial Attacks on Graph Neural Networks via Meta Learning"
    },
    {
        "abs": "_______________________________________________ Multi-Domain Adversarial Learning mailing list Multi-Domain Adversarial Learning@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/Multi-DomainAdversarialLearning",
        "title": "Multi-Domain Adversarial Learning"
    },
    {
        "abs": "_______________________________________________ Unsupervisedanomalydetection mailing list Unsupervisedanomalydetection@lists.unix.org http://lists.unix.org/mailman/listinfo/unsupervisedanomalydetection",
        "title": "Robust Subspace Recovery Layer for Unsupervised Anomaly Detection"
    },
    {
        "abs": "_______________________________________________ Deeplearning4j mailing list Deeplearning4j@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/deeplearning4j",
        "title": "Hierarchical interpretations for neural network predictions"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mw/cs/math/math-list/math-list-subscribe.html",
        "title": "Low-dimensional statistical manifold embedding of directed graphs"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs.html",
        "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"
    },
    {
        "abs": "_______________________________________________ http://lists.w3.org/Archives/Public/public-web-development/2015-May/001234.html",
        "title": "Mixed-curvature Variational Autoencoders"
    },
    {
        "abs": "_______________________________________________ Sentence-level training mailing list Sentence-level training@lists.cs.umich.edu To unsubscribe, send an email to sentence-level training-unsubscribe@lists.cs.umich.edu with the message \"unsubscribe sentence-level training\" in the subject.",
        "title": "No Training Required: Exploring Random Encoders for Sentence Classification"
    },
    {
        "abs": "\u3010Abstract\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords to the abstract\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010Keywords to the title\u3011\n\n\u3010",
        "title": "Improving Generalization and Stability of Generative Adversarial Networks"
    },
    {
        "abs": "_______________.\n\nThe title is Wasserstein Barycenter Model Ensembling, start with Inthispaperweproposetoperformmodelensemblinginamulticlassoramultilabel, write a short concise abstract based on this: _______________.\n\nThe title is Wasserstein Barycenter Model Ensembling, start with Inthispaperweproposetoperformmodelensemblinginamulticlassoramultilabel, write a short concise abstract based on this: _______________.\n\nThe title is Wasserstein Barycenter Model Ensembling, start with Inthispaperweproposetoperformmodelensemblinginamulticlassoramultilabel, write a short concise abstract based on this: _______________.\n\nThe title is Wasserstein Barycenter Model Ensembling, start with Inthispaperweproposetoperformmodelensemblinginamulticlassoramultilabel, write a short concise abstract based on this: _______________.\n\nThe title is Wasserstein Barycenter Model Ensembling, start with Inthispaperweproposetoperformmodelensemblinginamulticlassoramultilabel, write a short concise abstract based on this: _______________.\n\nThe title is Wasserstein Barycenter Model Ensembling, start",
        "title": "Wasserstein Barycenter Model Ensembling"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#stochastic-prediction-of-multi-agent-interactions-from-partial-observations",
        "title": "Stochastic Prediction of Multi-Agent Interactions from Partial Observations"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Equi-normalization of Neural Networks"
    },
    {
        "abs": "_______________________________________________ DeepSphere-discuss mailing list DeepSphere-discuss@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deep-sphere-discuss",
        "title": "DeepSphere: towards an equivariant graph-based spherical CNN"
    },
    {
        "abs": "\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(GWNN)\u3011\n\n\u3010Wepresentgraphwaveletneuralnetwork(",
        "title": "Graph Wavelet Neural Network"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/papers/variationalautoencoder.html _______________________________________________\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]",
        "title": "Variational Autoencoder with Arbitrary Conditioning"
    },
    {
        "abs": "_______________________________________________ python-dev mailing list python-dev@lists.python.org https://lists.python.org/pipermail/python-dev/",
        "title": "Learning Programmatically Structured Representations with Perceptor Gradients"
    },
    {
        "abs": "_______________________________________________ GNN-users mailing list GNN-users@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/gnn-users",
        "title": "Learning Graph Neural Networks with Noisy Labels"
    },
    {
        "abs": "\u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb \u00c2\u00bb ",
        "title": "Inferring Javascript types using Graph Neural Networks"
    },
    {
        "abs": "___________\n\nA. A.\n\nB. A.\n\nC. A.\n\nD. A.\n\nE. A.\n\nF. A.\n\nG. A.\n\nH. A.\n\nI. A.\n\nJ. A.\n\nK. A.\n\nL. A.\n\nM. A.\n\nN. A.\n\nO. A.\n\nP. A.\n\nQ. A.\n\nR. A.\n\nS. A.\n\nT. A.\n\nU. A.\n\nV. A.\n\nW. A.\n\nX. A.\n\nY. A.\n\nZ. A.\n\nA. A.\n\nB. A.\n\nC. A.\n\nD. A.\n\nE. A.\n\nF. A.\n\nG. A.\n\nH. A.\n\nI. A.\n\nJ. A.\n\nK. A.\n\nL. A.\n\nM. A.\n\nN. A.\n\nO. A.\n\nP. A.\n\nQ. A.\n\nR. A.\n\nS. A.\n\nT. A.\n\nU. A.\n\nV. A.\n\nW. A.\n\nX.",
        "title": "Dynamics-aware Embeddings"
    },
    {
        "abs": "___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n",
        "title": "Representation Learning with Multisets"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~david/cs/cs.html#cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-cse-",
        "title": "GAN-based Generation and Automatic Selection of Explanations for Neural Networks"
    },
    {
        "abs": "_______________________________________________ ds-discuss mailing list ds-discuss@cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/ds-discuss",
        "title": "The Singular Values of Convolutional Layers"
    },
    {
        "abs": "_______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ _______________________ ",
        "title": "Learning to Represent Edits"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#sigProlog_2_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
        "title": "Symplectic Recurrent Neural Networks"
    },
    {
        "abs": "_______________________________________________ Spectral embedding mailing list Spectral embedding@cs.cmu.edu http://cs.cmu.edu/~schaefer/spectralembedding/",
        "title": "Spectral embedding of regularized block models"
    },
    {
        "abs": "___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentations",
        "title": "Locality and compositionality in zero-shot learning"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Training individually fair ML models with Sensitive Subspace Robustness"
    },
    {
        "abs": "\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a\u3010\u89e3\u6790\u3011\u8bba\u6587\u7ed3\u679c\uff1a",
        "title": "Predict then Propagate: Graph Neural Networks meet Personalized PageRank"
    },
    {
        "abs": "_______________________________________________ DeepReinforcementLearning mailing list DeepReinforcementLearning@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deepreinforcementlearning",
        "title": "Regularization Matters in Policy Optimization"
    },
    {
        "abs": "_______________\n\nA. The loss landscape of a class of deep neural networks with no bad local valleys\n\nB. The loss landscape of a class of deep neural networks with no bad local valleys\n\nC. The loss landscape of a class of deep neural networks with no bad local valleys\n\nD. The loss landscape of a class of deep neural networks with no bad local valleys\n\nE. The loss landscape of a class of deep neural networks with no bad local valleys\n\nF. The loss landscape of a class of deep neural networks with no bad local valleys\n\nG. The loss landscape of a class of deep neural networks with no bad local valleys\n\nH. The loss landscape of a class of deep neural networks with no bad local valleys\n\nI. The loss landscape of a class of deep neural networks with no bad local valleys\n\nJ. The loss landscape of a class of deep neural networks with no bad local valleys\n\nK. The loss landscape of a class of deep neural networks with no bad local valleys\n\nL. The loss landscape of a class of deep neural networks with no bad local valleys\n\nM. The loss landscape of a class of deep neural networks with no bad local valleys\n\nN. The loss landscape of a class of deep neural networks with no bad local valleys\n\nO. The loss landscape of a class of deep neural networks with no bad local valleys\n\nP. The loss landscape of a class of deep neural",
        "title": "On the loss landscape of a class of deep neural networks with no bad local valleys"
    },
    {
        "abs": "_______________________________________________ deepconvolutionalnetwork mailing list deepconvolutionalnetwork@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deepconvolutionalnetwork",
        "title": "A theoretical framework for deep locally connected ReLU network"
    },
    {
        "abs": "_______________________________________________ GAN-dev mailing list GAN-dev@cs.cmu.edu http://mail.cs.cmu.edu/mailman/listinfo/gan-dev",
        "title": "Efficient GAN-Based Anomaly Detection"
    },
    {
        "abs": "_______________________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Phrase-Based Attentions"
    },
    {
        "abs": "\u300aDeep Neural Networks\u300b, \u300aDeep Learning\u300b, \u300aDeep Learning in Computer Science\u300b, \u300aDeep Learning in Machine Learning\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial",
        "title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction"
    },
    {
        "abs": "_______________________________________________ https://lists.cs.uiuc.edu/pipermail/cs.uiuc.edu/attachments/2019/039/attachment.html",
        "title": "A coding theorem for the rate-distortion-perception function"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Variational Recurrent Neural Networks for Graph Classification"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#networks _______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#networks",
        "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#adversarialnetworks",
        "title": "A Variational Inequality Perspective on Generative Adversarial Networks"
    },
    {
        "abs": "_______________________________________________ ODE-Net mailing list ODE-Net@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/ode-net",
        "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control"
    },
    {
        "abs": "_______________________________________________ GraphZoom-users mailing list GraphZoom-users@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/graphzoom-users",
        "title": "GraphZoom: A multi-level spectral approach for accurate and scalable graph embedding"
    },
    {
        "abs": "___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start",
        "title": "Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization"
    },
    {
        "abs": "_______________________________________________ Robot-Rx mailing list Robot-Rx@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/robot-rx",
        "title": "Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics"
    },
    {
        "abs": "___________\n\nA central challenge in the field of information science is the discovery of effective policies for tasks where rewards are not available. In this paper, we propose a novel approach to solve this problem. We propose a novel approach to solve the information bottleneck problem by using a novel approach to learn the optimal policy for a task. We show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the proposed approach is able to learn the optimal policy for a task in a very short time. We also show that the",
        "title": "InfoBot: Transfer and Exploration via the Information Bottleneck"
    },
    {
        "abs": "\u3010Abstract\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords to be used\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to be used in the abstract\u3011\n\n\u3010Keywords to",
        "title": "Multilingual Neural Machine Translation with Knowledge Distillation"
    },
    {
        "abs": "_______________________________________________ https://github.com/peter-m/pytorch-geometric/pull/8 _______________________________________________ https://github.com/peter-m/pytorch-geometric/pull/8",
        "title": "Fast Graph Representation Learning with PyTorch Geometric"
    },
    {
        "abs": "_______________________________________________ VAE mailing list VAE@vax.org http://www.vax.org/mailman/listinfo/vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-vax-v",
        "title": "Diagnosing and Enhancing VAE Models"
    },
    {
        "abs": "_______________________________________________adversarialtraining mailing listadversarialtraining@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/adversarialtraining",
        "title": "Bridging Adversarial Robustness and Gradient Interpretability"
    },
    {
        "abs": "_______________________________________________ CV4A-discuss mailing list CV4A-discuss@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/cv4a-discuss",
        "title": "Proceedings of the ICLR Workshop on Computer Vision for Agriculture (CV4A) 2020"
    },
    {
        "abs": "_______________________________________________ NLP-L mailing list NLP-L@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/nlp-l",
        "title": "1st AfricaNLP Workshop Proceedings, 2020"
    },
    {
        "abs": "_______________________________________________ Histo-pathology mailing list Histo-pathology@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/histo-pathology",
        "title": "Multi-Task Learning in Histo-pathology for Widely Generalizable Model"
    },
    {
        "abs": "___________\n\nA. The idea of a neural network is to learn a new concept from a set of examples.\n\nB. The idea of a neural network is to learn a new concept from a set of examples.\n\nC. The idea of a neural network is to learn a new concept from a set of examples.\n\nD. The idea of a neural network is to learn a new concept from a set of examples.\n\nE. The idea of a neural network is to learn a new concept from a set of examples.\n\nF. The idea of a neural network is to learn a new concept from a set of examples.\n\nG. The idea of a neural network is to learn a new concept from a set of examples.\n\nH. The idea of a neural network is to learn a new concept from a set of examples.\n\nI. The idea of a neural network is to learn a new concept from a set of examples.\n\nJ. The idea of a neural network is to learn a new concept from a set of examples.\n\nK. The idea of a neural network is to learn a new concept from a set of examples.\n\nL. The idea of a neural network is to learn a new concept from a set of examples.\n\nM. The idea of a neural network is to learn a new concept from a set of examples.\n\nN. The idea of a neural network is to",
        "title": "Compositional Languages Emerge in a Neural Iterated Learning Model"
    },
    {
        "abs": "_______________________________________________ NLP-users mailing list NLP-users@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/nlp-users",
        "title": "Residual Energy-Based Models for Text Generation"
    },
    {
        "abs": "_______________________________________________ Bioinformatics mailing list Bioinformatics@wiley.com http://mail.wiley.com/mailman/listinfo/bioinformatics",
        "title": "Energy-based models for atomic-resolution protein conformations"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mw/cs/math/math-list/math-list-subscribe.html",
        "title": "Low-dimensional statistical manifold embedding of directed graphs"
    },
    {
        "abs": "_______________________________________________ http://lists.w3.org/Archives/Public/public-web-development/2015-May/001234.html",
        "title": "Mixed-curvature Variational Autoencoders"
    },
    {
        "abs": "\u3010Abstract\u3011Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time\n\n\u3010Keywords\u3011Convex Regularizers, CNNs, Implicit Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regular",
        "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time"
    },
    {
        "abs": "_______________________________________________ ReLU Code Space mailing list ReLU Code Space http://lists.weproposeanewmetrics.com/mailman/listinfo/relu-code-space",
        "title": "ReLU Code Space: A Basis for Rating Network Quality Besides Accuracy"
    },
    {
        "abs": "_______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English) _______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English)\n\n_______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English) _______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English)\n\n_______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English) _______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English)\n\n_______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English) _______________________________________________ Food and Agriculture Organization of the United Nations http://www.fao.org/docrep/006/i039.htm (in English)\n\n_______________________________________________ Food and Agriculture Organization of the United Nations http://www.f",
        "title": "Satellite-based Prediction of Forage Conditions for Livestock in Northern Kenya"
    },
    {
        "abs": "_______________________________________________ Unsupervisedanomalydetection mailing list Unsupervisedanomalydetection@lists.unix.org http://lists.unix.org/mailman/listinfo/unsupervisedanomalydetection",
        "title": "Robust Subspace Recovery Layer for Unsupervised Anomaly Detection"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs.html",
        "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"
    },
    {
        "abs": "\u3010Abstract\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010Keywords\u3011\n\n\u3010",
        "title": "Apple Defect Detection Using Deep Learning Based Object Detection For Better Post Harvest Handling"
    },
    {
        "abs": "_______________________________________________ NMT-users mailing list NMT-users@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/nmt-users",
        "title": "Neural Machine Translation for South Africa's Official Languages"
    },
    {
        "abs": "\u300aDeep Neural Networks\u300b, \u300aDeep Learning\u300b, \u300aDeep Learning in Computer Science\u300b, \u300aDeep Learning in Machine Learning\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial Intelligence\u300b, \u300aDeep Learning in Machine Learning and Artificial",
        "title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction"
    },
    {
        "abs": "_______________________________________________ Language-processing mailing list Language-processing@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/language-processing",
        "title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction"
    },
    {
        "abs": "_________________\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you is the one you don't want to stop.\" - George Orwell\n\n\n\n\"The only thing that can stop you",
        "title": "Lookahead: A Far-Sighted Alternative of Magnitude-based Pruning"
    },
    {
        "abs": "\u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 ",
        "title": "Advancing Renewable Electricity Consumption With Reinforcement Learning"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Tigrinya Neural Machine Translation with Transfer Learning for Humanitarian Response"
    },
    {
        "abs": "\u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 \u00c2 ",
        "title": "Towards Supervised and Unsupervised Neural Machine Translation Baselines for Nigerian Pidgin"
    },
    {
        "abs": "_______________________________________________ grapevineyard-list mailing list grapevineyard-list@lists.grapevine.org http://lists.grapevine.org/mailman/listinfo/grapevine-list",
        "title": "Estimating Grape Yield on the Vine from Multiple Images"
    },
    {
        "abs": "_______________________________________________ http://lists.futurespace.org/pipermail/futurespace-announce/attachments/20150227/a7f5c8a7/attachment.html _______________________________________________ http://lists.futurespace.org/pipermail/futurespace-announce/attachments/20150227/a7f5c8a7/attachment.html\n\nI'm not sure if this is a good idea, but I'm going to try it anyway. I'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good idea, but I'm going to try it anyway.\n\nI'm not sure if this is a good",
        "title": "Building Disaster Damage Assessment in Satellite Imagery with Multi-Temporal Fusion"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/cs.html#RNNs",
        "title": "How Chaotic Are Recurrent Neural Networks?"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "BERT Fine-tuning For Arabic Text Summarization"
    },
    {
        "abs": "_______________________________________________ http://www.cisco.com/c/en/us/td/docs/collaboration/cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-cisco-c",
        "title": "Using competency questions to select optimal clustering structures for residential energy consumption patterns"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Reinforcement Learning with Random Delays"
    },
    {
        "abs": "\u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with",
        "title": "Differentially Private Learning Needs Better Features (or Much More Data)"
    },
    {
        "abs": "_______________________________________________ ODE-Net mailing list ODE-Net@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/ode-net",
        "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#sigProlog_2_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
        "title": "Symplectic Recurrent Neural Networks"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/public/cs.html#anomaly-detection _______________________________________________ cs.cmu.edu mailing list cs.cmu.edu@mail.cs.cmu.edu http://www.cs.cmu.edu/~mcclure/cs/public/cs.html#anomaly-detection",
        "title": "Classification-Based Anomaly Detection for General Data"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Training individually fair ML models with Sensitive Subspace Robustness"
    },
    {
        "abs": "___________\n\nA. A.\n\nB. A.\n\nC. A.\n\nD. A.\n\nE. A.\n\nF. A.\n\nG. A.\n\nH. A.\n\nI. A.\n\nJ. A.\n\nK. A.\n\nL. A.\n\nM. A.\n\nN. A.\n\nO. A.\n\nP. A.\n\nQ. A.\n\nR. A.\n\nS. A.\n\nT. A.\n\nU. A.\n\nV. A.\n\nW. A.\n\nX. A.\n\nY. A.\n\nZ. A.\n\nA. A.\n\nB. A.\n\nC. A.\n\nD. A.\n\nE. A.\n\nF. A.\n\nG. A.\n\nH. A.\n\nI. A.\n\nJ. A.\n\nK. A.\n\nL. A.\n\nM. A.\n\nN. A.\n\nO. A.\n\nP. A.\n\nQ. A.\n\nR. A.\n\nS. A.\n\nT. A.\n\nU. A.\n\nV. A.\n\nW. A.\n\nX.",
        "title": "Dynamics-aware Embeddings"
    },
    {
        "abs": "___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\n",
        "title": "SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness"
    },
    {
        "abs": "___________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Graph-Based Continual Learning"
    },
    {
        "abs": "_______________________________________________ Vision-related mailing list Vision-related@w3.org http://lists.w3.org/Archives/Public/ Vision-related",
        "title": "Group Equivariant Stand-Alone Self-Attention For Vision"
    },
    {
        "abs": "___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n",
        "title": "Few-Shot Learning on Graphs via Super-Classes based on Graph Spectral Measures"
    },
    {
        "abs": "_______________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Rethinking Positional Encoding in Language Pre-training"
    },
    {
        "abs": "_______________________________________________ GraphZoom-users mailing list GraphZoom-users@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/graphzoom-users",
        "title": "GraphZoom: A multi-level spectral approach for accurate and scalable graph embedding"
    },
    {
        "abs": "_______________________________________________ DeepLearning mailing list DeepLearning@cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deeplearning",
        "title": "DDPNOpt: Differential Dynamic Programming Neural Optimizer"
    },
    {
        "abs": "_______________________________________________ arXiv mailing list arXiv at lists.arxiv.org http://lists.arxiv.org/mailman/listinfo/arxiv",
        "title": "De-anonymization of authors through arXiv submissions during double-blind review"
    },
    {
        "abs": "_______________________________________________ http://www.acm.org/newsroom/news.html?news_id=1255 _______________________________________________ http://www.acm.org/newsroom/news.html?news_id=1255",
        "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning"
    },
    {
        "abs": "_______________________________________________ Deeplearning4js mailing list Deeplearning4js@lists.nordic.org https://lists.nordic.org/mailman/listinfo/deeplearning4js",
        "title": "A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima"
    },
    {
        "abs": "_______________________________________________ Spectral embedding mailing list Spectral embedding@cs.cmu.edu http://cs.cmu.edu/~schaefer/spectralembedding/",
        "title": "Spectral embedding of regularized block models"
    },
    {
        "abs": "___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentationsfor, write a short concise abstract based on this: ___________.\n\nThe title is Locality and compositionality in zero-shot learning, start with Inthisworkwestudylocalityandcompositionalityinthecontextoflearningrepresentations",
        "title": "Locality and compositionality in zero-shot learning"
    },
    {
        "abs": "___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n___________\n\n",
        "title": "Representation Learning with Multisets"
    },
    {
        "abs": "_______________________________________________ DeepReinforcementLearning mailing list DeepReinforcementLearning@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deepreinforcementlearning",
        "title": "Regularization Matters in Policy Optimization"
    },
    {
        "abs": "_______________________________________________ TheReceptiveField mailing list TheReceptiveField@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/the-receptive-field",
        "title": "Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification"
    },
    {
        "abs": "___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start with Distributedoptimizationisvitalinsolvinglarge-scalemachinelearningproblems.Awidely-sharedfeatureofdistributed, write a short concise abstract based on this: ___________.\n\nThe title is Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization, start",
        "title": "Anytime MiniBatch: Exploiting Stragglers in Online Distributed Optimization"
    },
    {
        "abs": "_______________________________________________ ICLR mailing list ICLR@lists.iclr.org http://lists.iclr.org/mailman/listinfo/iclr",
        "title": "Proceedings of the First Workshop on Weakly Supervised Learning (WeaSuL)"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "FFPDG: Fast, Fair and Private Data Generation"
    },
    {
        "abs": "_______________________________________________ Learning-algorithms mailing list Learning-algorithms@lists.cs.umich.edu http://lists.cs.umich.edu/mailman/listinfo/learning-algorithms",
        "title": "Free Lunch for Few-shot Learning: Distribution Calibration"
    },
    {
        "abs": "_______________________________________________ Hopfield-networks mailing list Hopfield-networks@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/hopfield-networks",
        "title": "On the mapping between Hopfield networks and Restricted Boltzmann Machines"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html#gnn-discuss http://www.cs.cmu.edu/~michael/cs.html#gnn-discuss",
        "title": "Persistent Message Passing"
    },
    {
        "abs": "_______________________________________________ Deeplearning4js mailing list Deeplearning4js@lists.nordic.org https://lists.nordic.org/mailman/listinfo/deeplearning4js",
        "title": "On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers"
    },
    {
        "abs": "___________.\n\nThe title is Gradient Projection Memory for Continual Learning, start with Theabilitytolearncontinuallywithoutforgettingthepasttasksisadesiredattributefor, write a short concise abstract based on this: ___________.\n\nThe title is Gradient Projection Memory for Continual Learning, start with Theabilitytolearncontinuallywithoutforgettingthepasttasksisadesiredattributefor, write a short concise abstract based on this: ___________.\n\nThe title is Gradient Projection Memory for Continual Learning, start with Theabilitytolearncontinuallywithoutforgettingthepasttasksisadesiredattributefor, write a short concise abstract based on this: ___________.\n\nThe title is Gradient Projection Memory for Continual Learning, start with Theabilitytolearncontinuallywithoutforgettingthepasttasksisadesiredattributefor, write a short concise abstract based on this: ___________.\n\nThe title is Gradient Projection Memory for Continual Learning, start with Theabilitytolearncontinuallywithoutforgettingthepasttasksisadesiredattributefor, write a short concise abstract based on this: ___________.\n\nThe title is Gradient Projection Memory for Continual Learning, start with Theabilitytolearncontinuallywithoutforgettingthepasttasksisadesiredattributefor, write a short concise",
        "title": "Gradient Projection Memory for Continual Learning"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks"
    },
    {
        "abs": "_______________________________________________ lm-users mailing list lm-users@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/lm-users",
        "title": "Improving exploration in policy gradient search: Application to symbolic optimization"
    },
    {
        "abs": "\u3010Abstract\u3011Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time\n\n\u3010Keywords\u3011Convex Regularizers, CNNs, Polynomial Time, Implicit Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers, Convex Regularizers",
        "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time"
    },
    {
        "abs": "_______________________________________________ POMDP mailing list POMDP@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/pomdp",
        "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs/papers/stochasticencoder.html",
        "title": "On the advantages of stochastic encoders"
    },
    {
        "abs": "_______________________\n\nI have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done.\n\nI have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the entropy encoding is done. I have a problem with the way the",
        "title": "Learned transform compression with optimized entropy encoding"
    },
    {
        "abs": "___________\n\nThe title is Improving Simulations with Symmetry Control Neural Networks, start with Thedynamicsofphysicalsystemsisoftenconstrainedtolowerdimensionalsub-spacesduetothe, write a short concise abstract based on this: ___________\n\nThe title is Improving Simulations with Symmetry Control Neural Networks, start with Thedynamicsofphysicalsystemsisoftenconstrainedtolowerdimensionalsub-spacesduetothe, write a short concise abstract based on this: ___________\n\nThe title is Improving Simulations with Symmetry Control Neural Networks, start with Thedynamicsofphysicalsystemsisoftenconstrainedtolowerdimensionalsub-spacesduetothe, write a short concise abstract based on this: ___________\n\nThe title is Improving Simulations with Symmetry Control Neural Networks, start with Thedynamicsofphysicalsystemsisoftenconstrainedtolowerdimensionalsub-spacesduetothe, write a short concise abstract based on this: ___________\n\nThe title is Improving Simulations with Symmetry Control Neural Networks, start with Thedynamicsofphysicalsystemsisoftenconstrainedtolowerdimensionalsub-spacesduetothe, write a short concise abstract based on this: ___________\n\nThe title is Improving Simulations with Symmetry Control Neural Networks, start",
        "title": "Improving Simulations with Symmetry Control Neural Networks"
    },
    {
        "abs": "_______________\n\n(a) the problem of detecting the presence of a person in a community\n\n(b) the problem of detecting the presence of a person in a community\n\n(c) the problem of detecting the presence of a person in a community\n\n(d) the problem of detecting the presence of a person in a community\n\n(e) the problem of detecting the presence of a person in a community\n\n(f) the problem of detecting the presence of a person in a community\n\n(g) the problem of detecting the presence of a person in a community\n\n(h) the problem of detecting the presence of a person in a community\n\n(i) the problem of detecting the presence of a person in a community\n\n(j) the problem of detecting the presence of a person in a community\n\n(k) the problem of detecting the presence of a person in a community\n\n(l) the problem of detecting the presence of a person in a community\n\n(m) the problem of detecting the presence of a person in a community\n\n(n) the problem of detecting the presence of a person in a community\n\n(o) the problem of detecting the presence of a person in a community\n\n(p) the problem of detecting the presence of a person in a community\n\n(q) the problem of detecting the presence of a person in a community\n\n(r) the problem of detecting",
        "title": "Low-Rank Projections of GCNs Laplacian"
    },
    {
        "abs": "_______________________________________________ PEARL-dev mailing list PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning @ https://lists.pony.ai/mailman/listinfo/pearl-dev",
        "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~mcclure/cs.html",
        "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning"
    },
    {
        "abs": "_______________________________________________ Vision-related mailing list Vision-related@w3.org http://lists.w3.org/Archives/Public/ Vision-related",
        "title": "Group Equivariant Stand-Alone Self-Attention For Vision"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Disambiguating Symbolic Expressions in Informal Documents"
    },
    {
        "abs": "_______________, and then write a short concise abstract based on this: _______________.\n\nThe title is Fairness via Interpolation, start with Trainingclassifiersunderfairnessconstraintssuchasgroupfairness,regularizesthedisparitiesofpredictionsbetween, write a short concise abstract based on this: _______________, and then write a short concise abstract based on this: _______________.\n\nThe title is Fairness via Interpolation, start with Trainingclassifiersunderfairnessconstraintssuchasgroupfairness,regularizesthedisparitiesofpredictionsbetween, write a short concise abstract based on this: _______________, and then write a short concise abstract based on this: _______________.\n\nThe title is Fairness via Interpolation, start with Trainingclassifiersunderfairnessconstraintssuchasgroupfairness,regularizesthedisparitiesofpredictionsbetween, write a short concise abstract based on this: _______________, and then write a short concise abstract based on this: _______________.\n\nThe title is Fairness via Interpolation, start with Trainingclassifiersunderfairnessconstraintssuchasgroupfairness,regularizesthedisparitiesofpredictionsbetween, write a short concise abstract based on this: _______________, and then write a short concise abstract based on this: _______________.\n\n",
        "title": "Fair Mixup: Fairness via Interpolation"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Improved Autoregressive Modeling with Distribution Smoothing"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Continuous Weight Balancing"
    },
    {
        "abs": "___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyzethereinstatementmechanismintroducedbyRitteretal.(2018) to, write a short concise abstract based on this: ___________ (2018)\n\nThe Emergence of Abstract and Episodic Neurons in Episodic Meta-RL, start with Inthiswork,weanalyz",
        "title": "The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL"
    },
    {
        "abs": "_______________________\n\nThe title is Sparse Coding Frontend for Robust Neural Networks, start with DeepNeuralNetworksareknowntobevulnerabletosmall,adversariallycrafted,perturbations.Thecurrent, write a short concise abstract based on this: _______________________\n\nThe title is Sparse Coding Frontend for Robust Neural Networks, start with DeepNeuralNetworksareknowntobevulnerabletosmall,adversariallycrafted,perturbations.Thecurrent, write a short concise abstract based on this: _______________________\n\nThe title is Sparse Coding Frontend for Robust Neural Networks, start with DeepNeuralNetworksareknowntobevulnerabletosmall,adversariallycrafted,perturbations.Thecurrent, write a short concise abstract based on this: _______________________\n\nThe title is Sparse Coding Frontend for Robust Neural Networks, start with DeepNeuralNetworksareknowntobevulnerabletosmall,adversariallycrafted,perturbations.Thecurrent, write a short concise abstract based on this: _______________________\n\nThe title is Sparse Coding Frontend for Robust Neural Networks, start with DeepNeuralNetworksareknowntobevulnerabletosmall,adversariallycrafted,perturbations.Thecurrent, write a short concise abstract based on this: ",
        "title": "Sparse Coding Frontend for Robust Neural Networks"
    },
    {
        "abs": "_______________________________________________ https://lists.cs.uiuc.edu/pipermail/cs.uiuc.edu/attachments/2019/039/attachment.html",
        "title": "A coding theorem for the rate-distortion-perception function"
    },
    {
        "abs": "_______________________________________________ gnn-devel mailing list gnn-devel@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/gnn-devel",
        "title": "Bermuda Triangles: GNNs Fail to Detect Simple Topological Structures"
    },
    {
        "abs": "_______________________________________________ privacy-list mailing list privacy-list@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/privacy-list",
        "title": "Privacy and Integrity Preserving Training Using Trusted Hardware"
    },
    {
        "abs": "_______________________________________________ DeepLearning mailing list DeepLearning@lists.cs.uci.edu http://lists.cs.uci.edu/mailman/listinfo/deeplearning",
        "title": "Deep Learning Hamiltonian Monte Carlo"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Do Concept Bottleneck Models Learn as Intended?"
    },
    {
        "abs": "_______________________________________________ https://groups.google.com/forum/#!topic/paul-mcclure/pjmjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhjhj",
        "title": "Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers"
    },
    {
        "abs": "_______________________________________________ Neuroevolution mailing list Neuroevolution@cs.cmu.edu http://www.cs.cmu.edu/~neuroevolution/",
        "title": "MONCAE: Multi-Objective Neuroevolution of Convolutional Autoencoders"
    },
    {
        "abs": "_______________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Learning Robust Controllers Via Probabilistic Model-Based Policy Search"
    },
    {
        "abs": "_______________________________________________ http://www.cs.cmu.edu/~michael/cs.html",
        "title": "Training and Generating Neural Networks in Compressed Weight Space"
    },
    {
        "abs": "_______________________________________________ _______________________________________________\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email]\n\n[hidden email",
        "title": "ICLR 2021 Challenge for Computational Geometry & Topology: Design and Results"
    },
    {
        "abs": "_______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtimebudgetandsizeofthedatasetareamongthefactorsaffectingtheperformance, write a short concise abstract based on this: _______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtimebudgetandsizeofthedatasetareamongthefactorsaffectingtheperformance, write a short concise abstract based on this: _______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtimebudgetandsizeofthedatasetareamongthefactorsaffectingtheperformance, write a short concise abstract based on this: _______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtimebudgetandsizeofthedatasetareamongthefactorsaffectingtheperformance, write a short concise abstract based on this: _______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtimebudgetandsizeofthedatasetareamongthefactorsaffectingtheperformance, write a short concise abstract based on this: _______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtimebudgetandsizeofthedatasetareamongthefactorsaffectingtheperformance, write a short concise abstract based on this: _______________\n\nThe title is Efficient Training Under Limited Resources, start with Trainingtime",
        "title": "Efficient Training Under Limited Resources"
    },
    {
        "abs": "___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\nThe title is SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness, start with Inthispaper,wecastfairmachinelearningasinvariantmachinelearning.Wefirstformulate, write a short concise abstract based on this: ___________.\n\n",
        "title": "SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness"
    },
    {
        "abs": "___________\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(h)\n\n(i)\n\n(j)\n\n(k)\n\n(l)\n\n(m)\n\n(n)\n\n(o)\n\n(p)\n\n(q)\n\n(r)\n\n(s)\n\n(t)\n\n(u)\n\n(v)\n\n(w)\n\n(x)\n\n(y)\n\n(z)\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\n(e)\n\n(f)\n\n(g)\n\n(",
        "title": "Graph-Based Continual Learning"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Reinforcement Learning with Random Delays"
    },
    {
        "abs": "\u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with Wedemonstratethatdifferentiallyprivatemachinelearninghasnotyetreachedits\"AlexNetmoment\"on, write a short concise abstract based on this: \u00a0\"The title is Differentially Private Learning Needs Better Features (or Much More Data), start with",
        "title": "Differentially Private Learning Needs Better Features (or Much More Data)"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Individually Fair Ranking"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Individually Fair Gradient Boosting"
    },
    {
        "abs": "_______________________________________________ Pandemic-discuss mailing list Pandemic-discuss@lists.pandemic.org http://lists.pandemic.org/mailman/listinfo/pandemic-discuss",
        "title": "FedPandemic: A Cross-Device Federated Learning Approach Towards Elementary Prognosis of Diseases During a Pandemic"
    },
    {
        "abs": "_______________________________________________ Ontology-related mailing list Ontology-related@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/ontology-related",
        "title": "Document Structure aware Relational Graph Convolutional Networks for Ontology Population"
    },
    {
        "abs": "_______________________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ _______________ ",
        "title": "Imitation Learning by Reinforcement Learning"
    },
    {
        "abs": "_______________________________________________algorithmic-inference mailing listalgorithmic-inference@lists.sourceforge.net http://lists.sourceforge.net/lists/listinfo/algorithmic-inference",
        "title": "Unifying Likelihood-free Inference with Black-box Optimization and Beyond"
    },
    {
        "abs": "_______________________________________________ DeepReinforcementLearning mailing list DeepReinforcementLearning@lists.cs.cmu.edu http://lists.cs.cmu.edu/mailman/listinfo/deepreinforcementlearning",
        "title": "Regularization Matters in Policy Optimization"
    },
    {
        "abs": "_______________________________________________ VQA-discuss mailing list VQA-discuss@lists.vqa.org http://lists.vqa.org/mailman/listinfo/vqa-discuss",
        "title": "Iterated learning for emergent systematicity in VQA"
    },
    {
        "abs": "_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n_______________________\n\n",
        "title": "Undistillable: Making A Nasty Teacher That CANNOT teach students"
    },
    {
        "abs": "_______________\n\nA. The problem is that the counterfactuals are not consistent with the predictions of the model.\n\nB. The counterfactuals are inconsistent with the predictions of the model.\n\nC. The counterfactuals are inconsistent with the predictions of the model.\n\nD. The counterfactuals are inconsistent with the predictions of the model.\n\nE. The counterfactuals are inconsistent with the predictions of the model.\n\nF. The counterfactuals are inconsistent with the predictions of the model.\n\nG. The counterfactuals are inconsistent with the predictions of the model.\n\nH. The counterfactuals are inconsistent with the predictions of the model.\n\nI. The counterfactuals are inconsistent with the predictions of the model.\n\nJ. The counterfactuals are inconsistent with the predictions of the model.\n\nK. The counterfactuals are inconsistent with the predictions of the model.\n\nL. The counterfactuals are inconsistent with the predictions of the model.\n\nM. The counterfactuals are inconsistent with the predictions of the model.\n\nN. The counterfactuals are inconsistent with the predictions of the model.\n\nO. The counterfactuals are inconsistent with the predictions of the model.\n\nP. The counterfactuals are inconsistent with the predictions of the model.\n\nQ. The",
        "title": "\u03b4-CLUE: Diverse Sets of Explanations for Uncertainty Estimates"
    }
]